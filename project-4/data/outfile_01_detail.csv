,job_titles,companys,employment_type,seniority,industrys,salary,salary_terms,job_descriptions,job_requirements,links,location,gov_support
0,Senior Data Engineer (Data Science and Artificial Intelligence),Maritime and Port Authority of Singapore,Permanent,Executive,Public / Civil Service,Salary undisclosed,,"As a core team member of the MPA Data Science and Artificial Intelligence department, the data engineer primary duties are to design, build, integrate MPA’s various data science platforms and systems. Reporting to the Chief Information Officer (CIO), you will be heavily involved in shaping the department’s strategic development and future roadmap.  You will drive the establishment of MPA’s Data Science Centre of Excellence to support the building, development and scaling of next-generation data systems in MPA, including the Singapore Maritime Data Hub, MPA Big Data Platform and internal Data Lake. You will also be responsible for the end-to-end management of MPA’s Hadoop-based Big Data Platform including design, prototyping, productising, optimising and maintaining data pipelines and data sets to support data science team in conducting quantitative analysis and developing machine learning and AI applications. You would be expected to work closely with the application development teams, business users, data analysts and maritime technology community to support data sharing, system integration and application testing. You will also determine the efficacy of our current data architecture and work with the IT team to map out strategy plans to strengthen data management, data governance, data privacy and cyber security issues. We are looking for experienced hires who possess the following:  A relevant qualification  in IT, Engineering, Computing, Data Science or other related disciplines with at least 5 years of work experience in a data engineering role or similar function. Experience in developing near real-time big data infrastructure and deploying high performance production systems to support data science, machine learning and AI algorithms/applications.    Experience in enterprise data platforms and Big Data tools:-Apache Hadoop ecosystem and related tools (HDFS, MapReduce, Kafka, Spark, Hive, NiFi).-Cloud-based data platforms (Cloudera, Talend, HortonWorks, AWS, Google BigQuery, Microsoft Azure).- Enterprise database and data warehouse management (Sybase, SAP, MySQL, SQL Server, Oracle, PostgreSQL). Experience with building data or metric-driven experimentation platform e.g. to conduct A/B testing experiments. Candidates with knowledge or experience in any of the following areas would have an added advantage:- Knowledge of AI programming and applications (deep learning, natural language processing, neural networks).- Experience in software development or strong programming skills (Python, R, Java, C++).- Experience working on Talend Data Management System.- Knowledge of machine learning tools, libraries and techniques (eg. TensorFlow, Scikit-learn, Pytorch).- Familiar with data visualisation tools (Tableau, Qlik).- Familiar with API frameworks and development.- Strong communication skills with ability to articulate and present complex data insights and information for broad range of audience. ",,https://www.mycareersfuture.sg/job/senior-data-engineer-maritime-port-authority-singapore-5e04d9fe6a97ad7bd5cb86353a193535,,
1,"Data Engineer,  Information Technology Group (ITG)",Ministry of Social and Family Development,Contract,,Public / Civil Service,Salary undisclosed,,"Responsibilities You will be a member of the IT Group and will participate in the Technology Transformation to develop, innovate, enhance and manage technology related initiatives and applications in order to bring about more timely and effective capabilities to support MSF’s strategic goals.   Evaluate and recommend technology solutions, practices and trends such as viable technology platforms, data management and analytics solutions   Source for suitable solutions (any combination of solutions comprising hardware, software etc) to support MSF’s needs and assess how they can meet MSF’s needs   Lead the design and develop the Data architecture roadmap, including data modelling, metadata design and management, analytical data marts, data warehouse/lakes, Data Integration Processes, Database Resource Planning, Infrastructure Performance, Data Governance and Security Management as well as design, architecture, implementation, and documentation of scalable ETL processes, pipelines, pathways and dimensional data models.   Responsible for data profiling, data analysis, data specification, data flows mapping, business logic documentation associated with new or modified data capture requirements   Responsible for validating business and functional requirements of assigned projects. Participate and lead data requirement gathering sessions with subject matter experts, data analyst/scientists, user communities, and other IT stakeholders   Review functional specifications and detailed technical designs from vendors to ensure project requirements are addressed efficiently and design is scalable   Audit and QA data and processes to ensure data quality and integrity throughout the data ecosystem   Implement tools to support Data Governance roles and processes to accelerate adoption and Data Governance maturity   Work with Data Scientists, Researchers, Business Analysts, etc. to build scalable Data Analytics applications using advanced analytics.   Technical/Functional competencies required:    Tertiary qualifications in a related discipline, preferably in information systems, business analytics, computing science   At least 6-8 years of working experience in implementation of technology projects related to data modelling, data warehousing, data integration / ETL processes, data governance and data analytics, with good understanding of supporting technologies   Good knowledge and experience in data integration, data quality, data governance and database technologies   Relevant experience and knowledge of how people, process and technology can come together to enable advanced analytics, Data Science and data management will be an advantage   Generic Competencies required:   Comfortable working with multiple stakeholders   Ability to concurrently oversee multiple projects   Strong leadership, communication, project management and analytical skills  ",,https://www.mycareersfuture.sg/job/data-engineer-information-technology-group-ministry-social-family-development-d66d8375a165d9e8e2d0bd17215564d4,,
2,Big Data Engineer,BIOFOURMIS SINGAPORE PTE. LTD.,Permanent,Senior Executive,Engineering,"$5,200to$6,700",Monthly,"We are looking for a savvy Data Engineer to join our growing team of analytics experts. The candidate will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Responsibility:  Create and maintain optimal data pipeline architecture in AWS cloud Assemble large, complex data sets that meet business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal ETL of data from a wide variety of data sources using SQL and AWS big data technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data secure across national boundaries through multiple AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. ","Requirements~  Advanced working SQL knowledge and experience working with relational databases  Strong analytic skills related to working with unstructured datasets Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. 5+ years of experience in a Data Engineer role with degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.  ",https://www.mycareersfuture.sg/job/big-data-engineer-biofourmis-singapore-da5fe40ce8998abe2e3646825351e2ae,West,Government support available
3,Senior Data Engineer,CHASSASIA (SINGAPORE) PTE. LTD.,Full Time,Professional,Information Technology,"$6,000to$7,500",Monthly," Participated in Projects delivery SDLC - from Initial Strategic, Requirements Gathering, 	Design, Testing & Implementation. We are looking for a Data Engineer responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities include, 	 Understand business processes, applications and how data is stored and gathered. Develop and manage streaming data pipelines at enterprise scale. Build expertise on the data. Own data quality for various data flows. Design, build and manage data marts to satisfy our growing data needs. Support data marts to provide intuitive analytics for internal customers. Design and build new framework and automation tools to enable teams to consume and understand data faster. Coding across a number of languages like SQL, Python and Java to support data scientists. Interface with internal customers to understand data needs. Collaborate with multiple teams and own the solution end-to-end. Maintain infrastructure for our data pipelines.   ","Requirements BS degree in Computer Science or a related technical field. MS or PhD degree is a plus. Having at least experience of the following   2+ years of advanced Python or Java development is necessary. Scala or Kotlin experience is a plus. 2+ years of SQL (such as PostgreSQL, Oracle, AWS Redshift, or Hive) experience is required. NoSQL experience is a plus. 2+ years working with Linux OS. Knowledge of networks and cybersecurity is a plus Experience with modern MapReduce/workflow distributed systems, especially Apache Spark. Experience with Apache Kafka is a plus Experience working with infrastructure-as-code systems like AWS CloudFormation. DevOps experience is a plus Experience in custom ETL pipeline design, implementation and maintenance Experience working with visualization tools like Tableau or Apache Superset. Ability in analyzing data to identify deliverables, gaps and inconsistencies Ability in managing and communicating data mart plans to internal customers   Interpersonal:   Results-oriented, Team player, able to Multi-task and work Effectively in a fast-paced Ability to communicate with technical and non-technical stakeholders Proven working experience as senior developer in the information technology sector. Also, having experience in working with Singapore Government Agencies. Experience in Agile (SCRUM)/Waterfall methodology. Experience in Extreme programming, pair programing, TDD, BDD   ",https://www.mycareersfuture.sg/job/senior-data-engineer-chassasia-c63e7b3f80da4fcbb4c8b39eba1e3257,South,Government support available
4,Data Engineer,TWITTER ASIA PACIFIC PTE. LTD.,Full Time,Professional,Information Technology,"$9,500to$11,000",Monthly,"Who We Are: Twitter users generate many terabytes of data every day; Twitter engineers run hundreds of experiments; Twitter Data Engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content. The Data Science team at Twitter is at the intersection of all this data and strives to make it actionable to all business units around Twitter. Data Engineers work alongside Data Scientists analyze this data via observational analyses, trend analyses, modeling, and new measurement strategies. We also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions.   What You’ll Do: Twitter has very large and complex datasets. As a Twitter Data Engineer you will build datasets and make them accessible to our partner teams by writing great production code to simplify the complexity. Your work will enable Product Managers and other decision-makers across the company to bring together insights and inform our product and strategy. In every decision that you influence, you will see the product improve and be more valuable to Twitter users. We are trying to improve Twitter. To improve something, we need to be able to measure it. As a Data Engineer you will enable better measurements and ensure measurement accuracy so that we know where we are doing well and where we want to improve. As such, you will:  Design, develop, and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams. Make Twitter-scale data more discoverable and easy to use for Data Scientists and Analysts across the company. Collaborate with other engineers and Data Scientists to discover the best solutions. Support your colleagues by reviewing code and designs. Diagnose and solve issues in our existing data pipelines and envision and build their successors.  Who You Are: You want to be part of a community of the most talented, forward-thinking Data Scientists and Engineers in the industry. You are a strong Scala or Java developer. You demonstrate clear and concise communication and data-driven decision-making. You are passionate about learning or growing your expertise in some or all of the following:  Data Pipelines Data Warehousing Statistics Metrics Development ","RequirementsRequirements:  B.S. and/or M.S. in Computer Science or a related technical field, or equivalent experience 2+ years of experience in either data infrastructure or backend systems Strong understanding of SQL Broad knowledge of the data infrastructure ecosystem Experience with Hadoop or other MapReduce-based architectures Experience working with large data volumes Good understanding of one or more of the following: Scala, C++, or Java ",https://www.mycareersfuture.sg/job/data-engineer-twitter-asia-pacific-c6221099c428ae5fc4bfbfd1ff9f6301,Central,Government support available
5,Data Engineer,WORKATO PTE. LTD.,"Permanent, Full Time",Executive,"Engineering, Information Technology","$4,000to$8,000",Monthly,"Role We are seeking a talented, self-directed Data Engineer to design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for our business stakeholders. Implement data structures using best practices in data modeling and ETL/ELT processes. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.  The ideal candidate relishes working with data, enjoys the challenge of highly complex technical contexts, and, above all else, is passionate about data and analytics. He/she is an expert with data modeling, ETL design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates outsized business impact. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail) and enjoys working in a fast-paced team. The ideal candidate needs to possess exceptional technical expertise in large scale data warehouse and BI systems with hands-on knowledge on SQL, Distributed/MPP data storage, and AWS services (S3, Redshift, EMR, RDS).   Responsibilities   Design, implement, and support a platform providing ad hoc access to large datasets   Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL   Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL, and Redshift   Build robust and scalable data integration (ETL) pipelines using SQL, Python and Spark   Build and deliver high quality datasets to support business analysis and customer reporting needs   Interface with business customers, gathering requirements and delivering complete data structures     Application instructions: To apply, please fill up the application form at https://grnh.se/ed28c66f2","Requirements  Bachelor's degree in Computer Science, Computer Engineering, Business Administration, Mathematics or a related field   3+ years of industry experience as a Data Engineer or related specialty (e.g., Business Intelligence Engineer, Data Scientist)   Experience in data modeling, ETL development, and Data warehousing.   Data Warehousing Experience with Oracle, Redshift, Teradata, etc.   Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space   Experience in continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers   Experience building data products incrementally and integrating and managing datasets from multiple sources   Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets     Bonus Points   Experience leveraging Python, R or Matlab to manipulate data and set up automated processes as per business requirements   Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)   Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies   Strong ability to interact, communicate, present and influence within multiple levels of the organization   Track record of manipulating, processing, and extracting value from large datasets   Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions   Master's degree  ",https://www.mycareersfuture.sg/job/data-engineer-workato-5dd422fd941f66c1662bb2f4f31f3a87,South,Government support available
6,Data Engineer,NTUC ENTERPRISE CO-OPERATIVE LTD,Full Time,Executive,Information Technology,"$4,000to$8,000",Monthly," COMPANY DESCRIPTION  NTUC Enterprise is the holding entity and single largest shareholder of the NTUC Social Enterprises. NTUC Enterprise aims to create a greater social force to do good by harnessing the capabilities of the social enterprises to meet pressing social needs in areas like health and eldercare, childcare, daily essentials, cooked food and financial services. Serving over two million customers, NTUC Enterprise wants to enable and empower all in Singapore to live better and more meaningful lives.  RESPONSIBILITIES   As a Senior Data Engineer/ Data Engineer, you will be getting “first-hand” break to engineer data analytics platform which will include architectural design, infrastructure setup, building data pipelines, integrate with data lakes and integrating data mining models into data pipelines. Understand, brain-storm and integrate data from different internal as well as external platforms (including mobile event streams) to help organization to deliver top notch customer experience. Work closely with tech heads (CXOs, Business Leaders, Engineering Managers) and their external vendors in defining and building enterprise data exchange platforms. Design, build, support and optimize new and existing data models and ETL processes. Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. Define and manage SLA for all data processes and own data quality issues. ","Requirements Advanced degree in computer science, computer engineering, or other technical fields (or) equivalent experience. 4+ years’ experience having developed data engineering capabilities for large and complex franchises. Strong data modeling (Kimball Preferred), system/schema design, SQL and ETL/ELT implementation skills Thorough knowledge of any one modern columnar, distributed and MPP based RDBMS systems. Preferably AWS Redshift or Azure Cosmos DB. Any one pipeline orchestration tool: AWS Batch, Airflow, Jenkins, Oozie, etc. Hands-on experience in any 1 modern programming language (Java/Python preferred) Extensive experience of building platform which are “horizontally scalable”, “highly available (Three 9s or higher)” and “fully automated maintenance” on top of AWS, GCP, Azure or Ali-Cloud. “Hands-on” experience of integrating open-source Big data technologies like Hive, Presto, Spark, Apache Ignite into traditional systems. Good understanding basic DBMS and operating system concepts. Frugality is in your thought and you strongly advocate using open source technologies. You write Neat, Optimized, Well documented and Self-maintainable code. Self-motivated and proactive, willing to learn new things, deliver best solution in most tensed situation. Good communication skills, strong team player and mentorship s ",https://www.mycareersfuture.sg/job/data-engineer-ntuc-enterprise-co-operative-a118578b8fe7de0f58393562c0cdcd4e,,
7,Data Engineer,NTUC ENTERPRISE CO-OPERATIVE LTD,Full Time,Executive,Information Technology,"$4,000to$8,000",Monthly," COMPANY DESCRIPTION  NTUC Enterprise is the holding entity and single largest shareholder of the NTUC Social Enterprises. NTUC Enterprise aims to create a greater social force to do good by harnessing the capabilities of the social enterprises to meet pressing social needs in areas like health and eldercare, childcare, daily essentials, cooked food and financial services. Serving over two million customers, NTUC Enterprise wants to enable and empower all in Singapore to live better and more meaningful lives.  RESPONSIBILITIES   As a Senior Data Engineer/ Data Engineer, you will be getting “first-hand” break to engineer data analytics platform which will include architectural design, infrastructure setup, building data pipelines, integrate with data lakes and integrating data mining models into data pipelines. Understand, brain-storm and integrate data from different internal as well as external platforms (including mobile event streams) to help organization to deliver top notch customer experience. Work closely with tech heads (CXOs, Business Leaders, Engineering Managers) and their external vendors in defining and building enterprise data exchange platforms. Design, build, support and optimize new and existing data models and ETL processes. Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. Define and manage SLA for all data processes and own data quality issues. ","Requirements Advanced degree in computer science, computer engineering, or other technical fields (or) equivalent experience. 4+ years’ experience having developed data engineering capabilities for large and complex franchises. Strong data modeling (Kimball Preferred), system/schema design, SQL and ETL/ELT implementation skills Thorough knowledge of any one modern columnar, distributed and MPP based RDBMS systems. Preferably AWS Redshift or Azure Cosmos DB. Any one pipeline orchestration tool: AWS Batch, Airflow, Jenkins, Oozie, etc. Hands-on experience in any 1 modern programming language (Java/Python preferred) Extensive experience of building platform which are “horizontally scalable”, “highly available (Three 9s or higher)” and “fully automated maintenance” on top of AWS, GCP, Azure or Ali-Cloud. “Hands-on” experience of integrating open-source Big data technologies like Hive, Presto, Spark, Apache Ignite into traditional systems. Good understanding basic DBMS and operating system concepts. Frugality is in your thought and you strongly advocate using open source technologies. You write Neat, Optimized, Well documented and Self-maintainable code. Self-motivated and proactive, willing to learn new things, deliver best solution in most tensed situation. Good communication skills, strong team player and mentorship ",https://www.mycareersfuture.sg/job/data-engineer-ntuc-enterprise-co-operative-a1e1648c7fd2a8fcbd5ab23042e77a88,,
8,Data Engineer,CAPGEMINI SINGAPORE PTE. LTD.,"Permanent, Contract",Professional,Information Technology,"$5,000to$7,500",Monthly,"We are looking for Jr and Sr Data Engineers for Capgemini Singapore Activities: • Industrialize data integration, data cleansing, data analytics programs or data management processes. • Contribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox. • Liaise with the Data Scientists, Architects, software developers, and business experts to understand how data needs to be converted, loaded, processed and presented. • Help the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications). • Provide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues. • Adapt to local context and tools provided by AXA’s entity as well as local entity development standards and IT landscape. Skills:  • Technical: Strong development skills - languages will depends on the entity but mainly python and Scala, Big Data experience (Spark, Hadoop Suite) Experience in Git, continuous integration and delivery. • Awareness on Data Management practices, including Data Lifecycle Management across Core IT & Big Data ecosystems as well as Data Privacy & Security constraints. • Knowledge in Data Modelling (including third normal form, star schema, data vault modelling methods). • Focus on end user and customer centricity, Strong oral and written communication skills, Passion for learning new tools, languages and frameworks, Fast adaptation to changing requirements, Strong problem-solving skills, able to work with minimal direct guidance, self-motivated and proactive, in a collaborative model, side by side with the business, Practical, hands on approach to get results. • Experienced in Cloud services & architecture. • Discipline in writing technical & non-technical documentation.","RequirementsActivities: • Industrialize data integration, data cleansing, data analytics programs or data management processes. • Contribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox. • Liaise with the Data Scientists, Architects, software developers, and business experts to understand how data needs to be converted, loaded, processed and presented. • Help the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications). • Provide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues. • Adapt to local context and tools provided by AXA’s entity as well as local entity development standards and IT landscape. Skills:  • Technical: Strong development skills - languages will depends on the entity but mainly python and Scala, Big Data experience (Spark, Hadoop Suite) Experience in Git, continuous integration and delivery. • Awareness on Data Management practices, including Data Lifecycle Management across Core IT & Big Data ecosystems as well as Data Privacy & Security constraints. • Knowledge in Data Modelling (including third normal form, star schema, data vault modelling methods). • Focus on end user and customer centricity, Strong oral and written communication skills, Passion for learning new tools, languages and frameworks, Fast adaptation to changing requirements, Strong problem-solving skills, able to work with minimal direct guidance, self-motivated and proactive, in a collaborative model, side by side with the business, Practical, hands on approach to get results. • Experienced in Cloud services & architecture. • Discipline in writing technical & non-technical documentation.",https://www.mycareersfuture.sg/job/data-engineer-capgemini-singapore-6881270e60e57757dd030a42764e21ad,"East, Central",Government support available
9,Data Engineer,SNAPHUNT PTE. LTD.,"Permanent, Full Time","Executive, Junior Executive, Senior Executive",Information Technology,Salary undisclosed,,"The Offer  Excellent career development opportunities Work within a leading employer in the Media & Entertainment industry  The Employer Our client is Asia’s leading media organisation, engaging minds and enriching lives across multiple languages and platforms. The company's core business is publishing of newspapers, magazines and books in both print and digital editions. It also owns other digital products, online classifieds, radio stations and outdoor media.   The Job In this role, you will ensure proper data governance and quality across the Data and Analytics department and the business as a whole. Your responsibilities include, but are not limited to:  Maintaining, improving, cleaning, and manipulation of data in the business’s operational and analytic databases.  Working with Software Engineers, Data Analytics team, Data Scientists, and Data Warehouse Engineers to implement database requirements, analyze performance, and troubleshoot any existent issues. Being an expert in SQL development to provide further support to the Data and Analytics in database design, data flow and analysis activities. Being a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. Defining and building the data pipelines that will enable faster, better, data-informed decision-making within the business. Creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards Leading innovations to implement big data technologies for platforms Designing and developing scalable ETL packages and routines to populate databases from sources and create aggregates.  Overseeing large-scale data Hadoop platforms and support the fast-growing data within the business. Performing tests and validations to support the accuracy of data transformations and data verification used in machine learning models.  Preparing and presenting activity and progress reports to Senior Data Engineers. ","RequirementsThe Profile  You possess a bachelor’s degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field.  You have at least 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting. You must have experience working with MySQL databases and Redshift, strong knowledge of AWS, Data Lakes, Snowflake, ETL. You keep up with industry trends and best practices to advise senior management on new and improved data engineering strategies that lead to an overall improvement in business performance.  Please apply for this role using the following link: https://snaphunt.com/jobs/34878805",https://www.mycareersfuture.sg/job/data-engineer-snaphunt-a38b7e4fc7c00027901160934f27a098,Central,
10,Data Engineer,FRIARTUCK PTE LTD,"Permanent, Full Time","Professional, Executive, Senior Executive","Consulting , Information Technology","$6,000to$8,000",Monthly,"We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. He/She must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.","RequirementsResponsibilities  Build the infrastructure and set up routines for optimal ETL for data from wide varieties of data sources utilizing SQL Design and build normalized and denormalized database solutions using healthcare industry best practices for data warehousing for specific client requirements, using Microsoft SQL Server Database programming (stored procedures and database design) Work with internal stakeholders to understand business needs for data structure, availability, scalability and accessibility; support translation of these data business needs into technical system requirements and build greater functionality to our data systems Identify opportunities for improvements and provide ongoing optimization, monitoring and tracking of data flow/ pipeline architecture Provide data management support to users Develop technical and training manuals  Requirements  BSc degree in Computer Science or relevant field 5-7 years of experience as a database developer or database engineer In-depth understanding of data management (e.g. permissions, recovery, security and monitoring) and Relational Database Management Systems Knowledge of software development and user interface web applications Hands on experience with SQL An ability to understand front-end users' requirements and a problem-solving attitude  Benefits  Opportunity to work with senior stakeholders and lead high-value projects with large enterprise clients Opportunity to work on our cutting edge AI and optimization software Competitive salary package ",https://www.mycareersfuture.sg/job/data-engineer-friartuck-e8e662f966d095b2b32e8e377867d458,South,Government support available
11,Data Engineer,BLUE STAR INFOSTACK SOLUTIONS PTE. LTD.,Contract,Executive,Information Technology,"$5,000to$8,000",Monthly,"We require Data Engineer / Database Consultant  for our client in Singapore.   Requirement: Position: Data Engineer / Database Consultant Type of position: Initial 12 months contract and extensions Location: Robinson Road, Singapore No. of positions: 2 Start Date: ASAP   REQUIRED EXPERIENCE AND SKILLS:  Degree in Computer Science or Business related discipline. An analytical mindset with problem-solving skills. Minimum of 5 years working experience in Data Management with at least 2 years in a team lead role Project management qualification is preferred. (not mandatory)    COMPUTER PROFICIENCY:  Database programming (Oracle, SQL Server) Big Data Platform (Cloudera) ETL Tools (SSIS, Talend, SAP Data Services) Reporting Tools (Reporting Services, Crystal Reports) BI Tools (Tableau)    JOB RESPONSIBILITIES: You will support Manager – Data Management and manage development resources and outsourced vendors to deliver user enhancements with good quality. You are responsible for user requirements, recommend solutions for Data Management, solution implementation and BAU maintenance work.   PRIMARY RESPONSIBILITIES  Responsible for the day to day operations of the Data Management team: data extraction, transformation and Report generation. Ensure consistency in data, promote processes to ensure data consistency between our Application databases and Reporting database. Respond to data and reporting related queries from internal and external clients Daily task allocation, performance follow up and coaching of the Data Management Team Be commendable, lead-by example and ensure a positive attitude in the team Train and coach newcomers Participate in coordination of tasks and projects to improve/develop the current/new processes. Ensure adherence of development practice, standards and updated documentation    COMPETENCIES:  Strong interpersonal skills including mentoring, coaching, collaborating, and team building Strong advocate of standards and challenge status quo with new and emerging technology to address new business challenges. Excellent oral and written communications skills and experience interacting with both business and IT individuals at all levels including the executive level ","RequirementsREQUIRED EXPERIENCE AND SKILLS:  Degree in Computer Science or Business related discipline. An analytical mindset with problem-solving skills. Minimum of 5 years working experience in Data Management with at least 2 years in a team lead role Project management qualification is preferred. (not mandatory)    COMPUTER PROFICIENCY:  Database programming (Oracle, SQL Server) Big Data Platform (Cloudera) ETL Tools (SSIS, Talend, SAP Data Services) Reporting Tools (Reporting Services, Crystal Reports) BI Tools (Tableau) ",https://www.mycareersfuture.sg/job/data-engineer-blue-star-infostack-solutions-bc7099b889534b21f4f4319cebdbf84d,Central,Government support available
12,"Associate, Data Engineer",GIC PRIVATE LIMITED,Full Time,Middle Management,Banking and Finance,"$4,500to$9,000",Monthly,"Internal Audit Department (IAD)   Internal Audit Department (IAD) has been tasked with the mandate to foster a strong governance and control environment in GIC.  IAD provides an independent assessment of GIC’s governance, risk management and internal control environment to key stakeholders including the Board of Directors and senior management. IAD acts as a trusted business partner working closely with the GIC group of companies and investment holding entities to bring about positive changes to the control environment and culture and thereby support senior management decision making.   We are looking for a suitable candidate to join the Internal Audit Data Analytics team.   IAD has leveraged data science to achieve greater risk coverage, stronger assurance and deeper business insight. Our data science capabilities include machine learning for anomaly detection and risk identification, the use of Natural Language Processing (NLP) to analyze unstructured data, and proficiency in “Big Data” platforms for efficient analysis of vast datasets. These capabilities have allowed IAD to progress towards a systematic, continuous audit approach with multi-dimensional analysis of complete data sets. With the strategy of integrating data science as a key IAD competency, existing talent are also equipped with new skillsets around the use of data analytics, programming languages and visualization tools.   Responsibilities  Analyse heterogeneous and unstructured data, and generate actionable insights to enhance risk and control activities. Work on Big Data infrastructure such as Hadoop to efficiently search data on very large datasets. Work closely with business stakeholders to analyse large data sets, trends and results to drive data-driven operational risk decisions. Collaborate with an existing internal community of data scientists to solve complex problems and influence change. Keep abreast of market developments in data analytics and recommend adoption of best practices into GIC. ","RequirementsRequirements   Good degree in Computer Engineering, Computer Science or Information Systems. Highly proficient in Python. Around 1-3 years’ of relevant experience in data warehousing, SQL stored procedures, ETL, data pipeline building and data analysis. Strong analytical and organization skills, with the ability to collect, organise, analyse, and disseminate significant amounts of information with attention to detail and accuracy. Good team player. Motivated and driven, able to work independently on technical projects. Experience in processing data in SQL databases and big data platforms such as Hadoop. Familiarity with open sourced platforms and libraries such as Spark, Alteryx, D3.js, Hadoop, Solr, Elasticsearch Knowledge of dashboard creation and visualisation using Tableau and D3.js will be an added advantage.  Please submit your job application to the following link : https://career10.successfactors.com/sfcareer/jobreqcareer?jobId=5893&company=gicprivate&username=  ",https://www.mycareersfuture.sg/job/associate-data-engineer-gic-55a22c4264e591bcaee716bce709fb60,Central,Government support available
13,Data Engineer,SEPHORA DIGITAL SEA PTE. LTD.,Full Time,Executive,Engineering,"$5,000to$7,000",Monthly,"Sephora Southeast Asia is a highly data-driven business, with analytics expertise embedded across many business areas, and a complex suite of internally developed and external technology to drive best-in-class customer experience and personalization, return on advertising spend and conversion. We are looking to a hire a proactive, commercially savvy data engineer to make sure all our data users - be they analysts, end users or AI-driven systems, have access to the right data at the right time, and ensure its accuracy. Responsibilities  Build automated processes to pull data from various systems/platforms into our BigQuery data warehouse Ensure data is successfully updated and accurate on a daily or real-time basis; implement appropriate monitoring to stop data problems becoming business problems Design fit-for-purpose schemas, and related ETL processes, to enable analytical teams across the business to be effective Work with engineering and business teams to put the right data in the right place at the right time to enable cross-channel targeting and personalization Take ownership of data quality issues, conduct root cause analysis and coordinate with external vendors and internal teams to resolve Support analysts in productionizing customer models and scripts Take a robust yet pragmatic view of data security, ensuring our customers’ data is protected and compliant, whilst enabling agility and innovation Keeping up to date on research and development of new technologies and techniques to enhance our data warehouse ","Requirements Experience with a cloud platform like AWS/GCP/Azure is mandatory. A knowledge of Google Cloud Platform and BigQuery would be a huge plus. Hands-on expertise with a range of data environments, from legacy enterprise SQL implementations to emerging cloud technologies Experience in a business with a well established data/BI/analytics infrastructure: have a clear view of what best-in-class looks like and how to get there Proven ability to be a self-starter and take end-to-end ownership of projects Excellent communicator, can build strong relationships with both technical and commercial stakeholders ",https://www.mycareersfuture.sg/job/data-engineer-sephora-digital-sea-962255d64727236cd89114590e7c8f55,Central,Government support available
14,Senior / Data Engineer (Data Science Team),M1 LIMITED,Full Time,"Fresh/entry level, Executive, Senior Executive","Engineering, Information Technology, Others, Telecommunications","$3,500to$5,800",Monthly," Design, optimise/tune performance, maintain, monitor, diagnose, and troubleshoot the processes, data delivery, and other outputs and facets of the big data platform Prepare progress and activity reports on the platform’s status and health (e.g. SLAs, data quality) Develop ETL/architectural pipelines/packages/roadmaps for data migration/data collection across different databases and systems Analyse and create data elements/flows, dependencies and relationships, and physical/logical data models Collaborate and communicate with the data science team relating to business requirements Automate, productise, and document the parts of the data science lifecycle/workflow (e.g. training, testing, deployment) Design, develop, and deploy high performance, at-scale solutions/pipelines (e.g. batch, real-time) to process large volumes of varied data formats (e.g. structured/unstructured) Work on Agile/DevOps technologies, micro-services, and APIs Keep up with industry trends and best practices in data engineering and the telco business and share with the data science team ","Requirements Bachelor’s degree in Computer Science/Engineering, Applied Mathematics, Management Information Systems, or related field 2-3 years of relevant working experience; candidates without working experience who possess the right skills/ competencies and eager to learn are welcome to apply Strong understanding and experience working in GNU/Linux environments Previous experience in designing and developing data models, multiple data source integration, ETL pipelines, and using data wrangling tools in EDW and big data platforms Experience in designing/developing at-scale, high-throughput big data/machine learning systems and applications Knowledge of software engineering practices and the software development life cycle (e.g. coding standards, review, control, testing) Experience and knowledge in distributed data processing, streaming, and computation frameworks (e.g. Spark, Kafka, Sqoop, Flume) Experience in/with:   DevOps automation, configuration, containerisation and orchestration (e.g. Ansible, Kubernetes, Docker, Jenkins) Development using big data applications (e.g. HIVE, HBase, Impala) Object-oriented/object function scripting languages (e.g. Python, Java, C++, Scala) Relational SQL and NoSQL databases (e.g. Oracle, Postgres, Cassandra) Disaster recovery, backup, automated testing, migration, and deployment (e.g. on-prem, cloud) Utilizing web services, SOAP, REST, etc Development and collaboration tools (e.g. GIT, Jira) Managing and interacting with users and vendors   Familiarity with internet technologies and public clouds (e.g. SaaS, IaaS, PaaS, AWS, Google Cloud, Azure) Knowledge in the Telecom industry is an advantage Effective verbal and written communication with ability to write thorough and clear documentation ",https://www.mycareersfuture.sg/job/senior-data-engineer-m1-1fc844c78813223b095744286b52d2c2,West,Government support available
15,"Associate, Data Engineer, Consumer Banking, Technology and Operations (WD03017)",DBS BANK LTD.,"Permanent, Full Time",Junior Executive,Banking and Finance,"$3,750to$6,800",Monthly,"Business Function Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.  As part of this organization, you will be joining the Operations Intelligence Unit of Singapore Consumer Banking Operations: you will be working on a workforce optimization project which aims to improve data accuracy and data reliability of operations staff performance data. Your primary focus will be ensuring the smooth running of our current technical infrastructure and enabling the successful transitioning to the new one, while also taking active part in developing the new workforce optimization data and solution elements. As an ideal candidate, we are looking for a profile with an established database admin and software engineering skills who also has a well-founded interest in data mining, analytics and modelling Responsibilities   SUPPORT DAY TO DAY BAU (25%) –Database maintenance and support     Execute and manage weekly parameter update (run, resolve, co-ordinate w/other non-technical teams) Monitor dashboard uptime, supervise completion of automated scripts Triage service disruptions, take part in initial root cause identification, allocate and report resolution process   PROJECT WORK (75%)     SYSTEM DEVELOPMENT (60%): Transitioning the technical architecture from SAS db/scripts to DBS proprietary cloud platform with python-based scripting; take part in python-based application development (full development lifecycle: BR to BAU) and in script conversion from SAS to python DATA MANIPULATION (15%): Automate inclusion of new data sources: full data discovery cycle (perform data mapping, analysis, verification and data quality checks) for each new data source from team prioritization/data source identification to BAU) Develop processes and tools to monitor and analyze model performance and data accuracy in the new architecture   ","Requirements Diploma or Degree holder of Information Technology, Business, Mathematics or Statistics At least 2-4 years of experience in software development, and relational database maintenance/support, including open source technologies Able to interpret database schemas, both RDBMS and Hadoop that represent and support business processes Proficient in writing and optimizing SQL on Teradata or similar relational database Able to handle large and complex codebases Understanding of administrative tasks such as end user access to front end and maintenance of security matrix and code versioning tools such as TortoiseSVN Experience in data visualization and statistical data modelling (ie. QlikView, Power BI, Cognos, SAP Business Objects, R or Python stat packages, SPARK  R would be an advantage. Interest or experience in advanced data mining, big data tool stacks and/or Machine Learning, (Deep) Neural Networks, Game Theory, R Optimization Infrastructure packages Strong problem-solving skills and openness to consider alternative suggestions Proactive and independent work ethic Willingness to work as part of a high performing team in an individual contributor role A drive to learn and master new technologies and techniques ",https://www.mycareersfuture.sg/job/associate-data-engineer-consumer-banking-technology-operations-dbs-bank-a66f5940d9a82290a3f458944993a5ec,Central,Government support available
16,"Analyst, Data Engineer, Consumer Banking, Technology and Operations (WD03017)",DBS BANK LTD.,"Permanent, Full Time",Junior Executive,Banking and Finance,"$2,550to$4,600",Monthly,"Business Function Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.  As part of this organization, you will be joining the Operations Intelligence Unit of Singapore Consumer Banking Operations: you will be working on a workforce optimization project which aims to improve data accuracy and data reliability of operations staff performance data. Your primary focus will be ensuring the smooth running of our current technical infrastructure and enabling the successful transitioning to the new one, while also taking active part in developing the new workforce optimization data and solution elements. As an ideal candidate, we are looking for a profile with an established database admin and software engineering skills who also has a well-founded interest in data mining, analytics and modelling Responsibilities   SUPPORT DAY TO DAY BAU (25%) –Database maintenance and support 	 Execute and manage weekly parameter update (run, resolve, co-ordinate w/other non-technical teams) Monitor dashboard uptime, supervise completion of automated scripts Triage service disruptions, take part in initial root cause identification, allocate and report resolution process   PROJECT WORK (75%) 	 SYSTEM DEVELOPMENT (60%): Transitioning the technical architecture from SAS db/scripts to DBS proprietary cloud platform with python-based scripting; take part in python-based application development (full development lifecycle: BR to BAU) and in script conversion from SAS to python DATA MANIPULATION (15%): 		Automate inclusion of new data sources: full data discovery cycle (perform data mapping, analysis, verification and data quality checks) for each new data source from team prioritization/data source identification to BAU) 		Develop processes and tools to monitor and analyze model performance and data accuracy in the new architecture   ","Requirements Diploma or Degree holder of Information Technology, Business, Mathematics or Statistics At least 2-4 years of experience in software development, and relational database maintenance/support, including open source technologies Able to interpret database schemas, both RDBMS and Hadoop that represent and support business processes Proficient in writing and optimizing SQL on Teradata or similar relational database Able to handle large and complex codebases Understanding of administrative tasks such as end user access to front end and maintenance of security matrix and code versioning tools such as TortoiseSVN Experience in data visualization and statistical data modelling (ie. QlikView, Power BI, Cognos, SAP Business Objects, R or Python stat packages, SPARK  R would be an advantage. Interest or experience in advanced data mining, big data tool stacks and/or Machine Learning, (Deep) Neural Networks, Game Theory, R Optimization Infrastructure packages Strong problem-solving skills and openness to consider alternative suggestions Proactive and independent work ethic Willingness to work as part of a high performing team in an individual contributor role A drive to learn and master new technologies and techniques ",https://www.mycareersfuture.sg/job/analyst-data-engineer-consumer-banking-technology-operations-dbs-bank-56551cd93d1424408556a629355986ea,Central,Government support available
17,"VP / AVP, Senior Data Engineer, Group Consumer Banking and Big Data Analytics Technology (180003L2)",DBS BANK LTD.,"Permanent, Full Time","Middle Management, Manager",Banking and Finance,"$7,000to$14,000",Monthly," Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud.  Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics.  Analyze source data and data flows, working with structured and unstructured data. Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends Analyze and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely. Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms. Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products. Build and optimize classifiers using machine learning techniques and enhance data collection procedures that is relevant for building analytic systems. Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL. Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat. Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders. ","Requirements Experience in big data and machine learning The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles. Development experience in Java/Scala and pride in producing clean, maintainable code Practical experience in clustering high dimensionality data using a variety of approaches Real world experience in solving business problems by deploying one or more machine learning techniques Experience creating pipelines to analyze data, extracted features and updated models in production. Independence and self-reliance while being a pro-active team player with excellent communication skills. Hands-on development with key technologies including Scala, Spark, and other relevant distributed computing languages, frameworks, and libraries.  Experience with distributed databases, such as Cassandra, and the key issues affecting their performance and reliability.  Experience using high-throughput, distributed message queueing systems such as Kafka. Familiarity with operational technologies, including Docker (required), Chef, Puppet, ZooKeeper, Terraform, and Ansible (preferred).  An ability to periodically deploy systems to on-prem environments.  Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools.  Experience with Teradata SQL, Exadata SQL, T-SQL Strong experience in graph and stream processing Experience in migrating SQL from traditional RDBMS to Spark and BigData technologies Experience in building language parsers using ANTLR, query optimizers and automatic code generation In-depth knowledge of database internals and Spark SQL Catalyst engine ",https://www.mycareersfuture.sg/job/vp-avp-senior-data-engineer-group-consumer-banking-big-data-analytics-technology-dbs-bank-4bcecb29e46d4659953a716290f051ae,,
18,Data Engineer,SHOPEE SINGAPORE PRIVATE LIMITED,"Permanent, Full Time",Executive,Information Technology,"$4,400to$8,400",Monthly,"Job Description:  Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform Design and grow Shopee’s data warehouse, build reliable and smart ways to ingest data to the warehouse, and help engineer efficient data pipelines. Some examples include self-service data ingestion systems, Airflow-enabled workflows with code-as-configuration, and data validation tools Build critical data marts and applications to support products and solve specific business needs, design data models for optimal storage and retrieval, and optimize data architectures to meet critical product and business requirements. Some examples include a real-time Campaign Mart (used to serve the business with live intelligence) and Order Mart (to supply low latency seller performance system) ","RequirementsRequirements:  B. Sci. / Ms / PhD in Computer Science or a related technical field More than 3 years of working experience in software development in at least one of these languages: Java, Scala, Python, C/C++, under Linux / Unix. Scala is a plus Familiar with SQL; strong scripting ability in Bash is a plus Familiar with Hadoop, Spark, Kafka, Presto, and other big data experience is a plus Familiar designing and operating of a robust distributed system is a plus Love to use and develop open-source technologies Excited to work intimately with data Passionate, self-motivated, and takes ownership ",https://www.mycareersfuture.sg/job/data-engineer-shopee-singapore-c22b645bb61ff1dfe5114048349fa91b,South,
19,Data Engineer,BLUE STAR INFOSTACK SOLUTIONS PTE. LTD.,Contract,Executive,Information Technology,"$4,000to$4,500",Monthly,"We require Data Engineer / Datawarehousing Consultant for our client in Singapore.   Requirement: Position: Data Engineer / Datawarehousing Consultant Type of position: 12 months contract and extensions Location: Robinson Road, Singapore No. of positions: 2 Start Date: ASAP   Required Basic qualification:   Degree in computing or any related discipline Good analytical and problem-solving skills Self-motivated and proactive, willing to learn new things Good communication skills and strong team player    Preferred technical skills:  For experience candidates require at least 3 years of experience as Data Engineer Business application and system consulting For Fresh Graduate: Require IT Graduation and knowledge in Data side Database development and  data model design (Oracle/MS SQL/MySQL/PostgreSQL) ETL/ELT implementation and data integration Business intelligence and reporting tools, eg. Tableau, Qlik, etc. Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) REST/Web API development and management Programming language (SQL/Java/Python/R) Design pattern, 12-factor app principle and modern cloud architecture ","Requirements For experience candidates require at least 3 years of experience as Data Engineer Business application and system consulting For Fresh Graduate: Require IT Graduation and knowledge in Data side Database development and  data model design (Oracle/MS SQL/MySQL/PostgreSQL) ETL/ELT implementation and data integration Business intelligence and reporting tools, eg. Tableau, Qlik, etc. Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) REST/Web API development and management Programming language (SQL/Java/Python/R) Design pattern, 12-factor app principle and modern cloud architecture ",https://www.mycareersfuture.sg/job/data-engineer-blue-star-infostack-solutions-50e8e12c5cbb1f42d68a4060f5bca5e6,Central,Government support available
20,Senior Data Engineer,KELLY SERVICES (SINGAPORE) PTE. LTD.,Contract,Senior Executive,Information Technology,"$6,500to$7,500",Monthly," Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud.  Move architecture and implementation through the development pipeline, from research to deployment Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics.  Analyze source data and data flows, working with structured and unstructured data. Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends Analyze and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely. Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms. Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products. Build and optimize classifiers using machine learning techniques and enhance data collection procedures that is relevant for building analytic systems. Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL. Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat. Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders. ","Requirements Minimum qualification of Bachelor Degree  10+ years of Experience in one or more areas of big data and machine learning The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles. Development experience in Java/Scala and pride in producing clean, maintainable code Practical experience in clustering high dimensionality data using a variety of approaches Real world experience in solving business problems by deploying one or more machine learning techniques Experience creating pipelines to analyze data, extracted features and updated models in production. Independence and self-reliance while being a pro-active team player with excellent communication skills. Hands-on development with key technologies including Scala, Spark, and other relevant distributed computing languages, frameworks, and libraries.  Experience with distributed databases, such as Cassandra, and the key issues affecting their performance and reliability.  Experience using high-throughput, distributed message queueing systems such as Kafka. Familiarity with operational technologies, including Docker (required), Chef, Puppet, ZooKeeper, Terraform, and Ansible (preferred).  An ability to periodically deploy systems to on-prem environments.  Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools.  Experience with Teradata SQL, Exadata SQL, T-SQL Strong experience in graph and stream processing Experience in migrating SQL from traditional RDBMS to Spark and BigData technologies Experience in building language parsers using ANTLR, query optimizers and automatic code generation In-depth knowledge of database internals and Spark SQL Catalyst engine ",https://www.mycareersfuture.sg/job/senior-data-engineer-kelly-services-f0a5c5ee8036446152af08c1c702ceb4,East,
21,Data Engineer,STAR ASIA TRADING PTE. LTD.,Full Time,Professional,Information Technology,Salary undisclosed,,"Your responsibilities include but are not limited to:   Work with stakeholders, including Factory Operations, Executives, and Clients, to define data sets and schema, as well as to build and maintain optimal data pipeline for greater functionality in our data systems in order to drive digital automation Develop, construct, test, and maintain data architecture standards across the Organisation (i.e. creating databases optimised for performance, implementing schema changes, maintaining large-scale processing systems) Develop data set processes for mining, modelling, and production. Establishes procedures for data handling, testing methods to ensure statistical models achieve the desired outcomes. Define and discover opportunities for data acquisition, and specifying datasets that could be collected for analysis to achieve business objectives Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources in different formats Troubleshoot and recommend ways to improve data reliability, efficiency, security, and quality for predictive or prescriptive data-based decision making within the Organisation To be the Subject Matter Expert on industry trends and best practices of data governance to advise across all level of management and project teams ","RequirementsJob qualifications and requirements:    4+ years of hands-on experience in a Data Engineer function working with a range of Data environments, including data sources from rudimentary spreadsheets, systems, to emerging Cloud platforms. Attained a Graduate degree in Computer Science, Statistics, Informatics, Applied Mathematics, or other related quantitative field. Experience with studying, manipulating, processing, and extracting value from large disconnected datasets. Advanced working experience with SQL and NoSQL databases. Strong programming skills (e.g. Python, Scala, and/or Java) for data manipulation. Working knowledge of message queuing, stream processing, and highly scalable ""big data"" data stores. Strong understanding of analysing business problems, and working with Business Intelligence tools to present insights to stakeholders. Big data tools like Hadoop, Spark, Kafka, and experience in R to facilitate converting data exploration to production is a plus    Please include your notice period and expected salary in your application.",https://www.mycareersfuture.sg/job/data-engineer-star-asia-trading-14710449bba9c2bc549481ca0cd46e63,,Government support available
22,"Data Engineer, Data Governance (1 Year Contract)",AIA SINGAPORE PRIVATE LIMITED,Contract,Professional,"Banking and Finance, Information Technology","$6,000to$8,000",Monthly," Responsible for and build Data Governance capability within AIA including but not limited to: construct enterprise data inventory, configuring Data Governance toolsets, supporting data owners and stewards in their daily tasks, reporting data quality on scheduled basis. Build and maintain strong effective relationships with key internal and external stakeholders to ensure that your data platform solutions meet the expectation of key business stakeholders. Work collaboratively with your Data, Analytics and BI colleagues to deliver on your objectives and openly share knowledge amongst the organisation. Assess and understand the business requirements through liaison with the business stakeholders, Business Analysts and the Project Managers. Support the Enterprise Data and Analytics COE in terms data acquisition and structuring data fit for use on analytics projects. Pursue personal development of skills and knowledge for the effective performance of the role. Other tasks or responsibilities assigned from time to time by management. ","Requirements Bachelor degree and above in Analytics, Information Systems Management, Computer Science or related fields. 5+ years of experience in data warehouse, data analytics projects, change management process, and/or any IM (Information Management) related projects. Technical experience in data migration, data integration, data modeling, designing, building ETLs, data ingestions, and/or transformations. Experience in working with RDBMS such as DB2, Oracle, Microsoft SQL Server, PostgresSQL, Teradata, etc. Experience in data management and integration tools such as Informatica Data Integrator, Oracle Data Integrator, SAP Data Services, Ab Initio, IBM Datastage or Microsoft SSIS. Process good knowledge and experience in data quality definition, data cleansing and data treatment/profiling process using industry standard tools Informatica Axon, Informatica Enterprise Data Catalog and Informatica Data Quality is a must. Good knowledge of data warehouse and data management implementation methodology. Good knowledge of the Information Management framework, including operating model, data governance, data management, data security, data quality and data architecture. Preferably with experience in Big Data environments like Cloudera and HortonWorks. Knowledge or experience of cloud computing is advantageous. Process good knowledge and experience in data visualisation concepts using tools such as SAS Visual Analytics or WRS, Tableau, Microsoft PowerBI or Reporting Services, IBM Cognos, SAP BusinessObjects, etc. is an advantage. Ability to pick up new tools and able to be independent with minimal guidance from the project leads/managers. Excellent command of written and spoken English. ",https://www.mycareersfuture.sg/job/data-engineer-data-governance-aia-singapore-3c1e204c62ae5e831344b691bbfcd24e,Central,Government support available
23,DATA ENGINEER  /  ANALYST,HYDROINFORMATICS INSTITUTE PTE. LTD.,"Permanent, Full Time",Professional,Engineering,"$5,200to$6,200",Monthly,"H2i Pte Ltd. (www.h2i.sg) is growing its data science team and looking for data engineers/analysts to join the team. H2i is dedicated to developing advanced computational and technological solutions and apply in the water industry. A diverse set of problems are being currently tackled at H2i which provides us with a variety of data with uncertainties, and the necessity to analyze the data and formulate machine learning models. Role and Responsibilities:  Implement data wrangling, preprocessing and preparation scripts for available raw environmental data Implement statistical and machine learning algorithms for data analysis and knowledge derivation Implement data visualization solutions for post processing and communication to internal and external teams Create and maintain databases for different kinds of geo-spatiotemporal data Monitor and manage data pipelines and test production code  Salary Range: 5200 SGD to 6200 SGD per month","Requirements Masters or PhD in one of the mathematical sciences, or engineering Programming capability the data science languages – Python, R, and preferably in core languages – C, C++ Understanding and ability to code algorithms related to multivariate statistics, spatio-temporal statistics and time series analysis, and common machine learning algorithms in clustering, dimensionality reduction, neural networks etc. Familiarity with open source data visualization frameworks with D3.js is preferred Understanding of database concepts and distributed processing systems and knowledge of one of the frameworks – Hadoop, Spark, NOSQL etc. Excellent written and oral presentation skills Interest in developing environmental solutions ",https://www.mycareersfuture.sg/job/data-engineer-analyst-hydroinformatics-institute-fded84bb3fd40f9402639d0db532d8cb,,Government support available
24,Data Engineer,Company Undisclosed,"Permanent, Full Time",Professional,"Engineering, Information Technology","$8,000to$15,000",Monthly,"Forcepoint is transforming cybersecurity by focusing on what matters most: understanding people’s intent as they interact with critical data and intellectual property wherever it resides. Our uncompromising systems enable companies to empower employees with unobstructed access to confidential data while protecting intellectual property and simplifying compliance. Based in Austin, Texas, Forcepoint supports more than 20,000 organizations worldwide. For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.   Job Summary: Forcepoint is seeking a qualified full-time Senior Professional Services Data Engineer working on client site to facilitate configuration, data integration and training of our commercial-off-the-shelf cybersecurity User and Entity Behavioral Analytics (UEBA) products. This individual must be highly motivated, have great interpersonal skills, and be technically proficient. In this role you will be joining a small but rapidly growing team in Singapore. Your role will include working directly with customers to understand their goals, help shape requirements, own the design and implementation of analytic strategies, and develop robust ETL pipelines to support these analytic strategies. Additionally, you will interface with the broader Forcepoint Professional Services team to drive analytic capabilities of the platform, and overall facilitate an efficient, effective, and robust deployment of the Forcepoint UEBA platform to characterize and detect insider threats and compliance violations. The successful candidate will receive specialized training to support our technologies and is expected to become proficient in all aspects of complex software solution deployment. This position requires 5-10% domestic and international travel as needed to meet customer and project requirements.   Responsibilities Include: o Provide exceptional implementation services to new customers, including supporting data ingestion, analytic configuration, customer training, and troubleshooting o Work directly with customers to design and implement robust analytic strategies in the Forcepoint UEBA platform to address use cases in cyber security and regulatory surveillance o Partner with the UEBA Delivery team to integrate with and automate ingest for a wide variety of data sources (databases, remote servers, flat files, APIs, etc.) to ensure data is quickly and reliably available in all contexts o Prepare technical documentation to include as-built design, requirements, and Standard Operating Procedures o Interface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform o Provide technical briefings to customer leadership and Forcepoint corporate leadership as required o Coordinate tasks and activities with various groups within Forcepoint, the government or partners","Requirements•              Required Skills & Experience: o Experience writing modular and reusable code in Python o Facility in scripting and troubleshooting application errors in Linux/Unix environments o Experience with the ETL: cleaning, transforming, and ingesting large datasets o Experience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment o Possess strong analytical, verbal, and technical written communication skills o Must be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers   Nice to have: o Prior technical experience in large enterprises o Experience with Apache NiFi and high volume ETL tasks o Integration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.   Required Education: o Advanced degree in a technical field such as Computer Science or equivalent work experience",https://www.mycareersfuture.sg/job/data-engineer-2ddd98f69be84f272e2ce4cd03b3df13,,
25,Data Engineer,GRABTAXI HOLDINGS PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$8,000to$13,000",Monthly,"  Designing, evaluating, and implementing framework that can adequately handle the needs of a rapidly growing data driven company   Architecting and scaling data analytics infrastructure on AWS; finding opportunities to improve and optimize the workloads, processes to ensure that performance levels can support continuous accurate, reliable and timely delivery of key insights   Building, designing and deploying ETL pipelines   Manage continuous uptime of Data services by implementing High Availability tools and best practices   Manage the continuous testing and deployment of data pipelines, new data services and analytical reporting dashboards.   Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Partner data scientists and engineers by leading the movement cleaning and normalizing subsets of data of interest as preparatory step to prepare the rich data for deeper analysis on how to improve user experience for Grab customers around the region.  ","Requirements  3+ years of hands-on experience, preferably in data infrastructure   Experience in container management and orchestration tools like ECS, Kubernetes, and Mesos is a strong plus   A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines   Proficiency in Hadoop, Kafka and Spark databases in a large scale environment   Well versed in setting up continuous integration and deployment for big data or other projects.   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Comfortable with Linux Systems Administration  ",https://www.mycareersfuture.sg/job/data-engineer-grabtaxi-holdings-7b8bd6652aec3f6a52e216b6c033afc0,Central,Government support available
26,Data Engineer,GRABTAXI HOLDINGS PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$5,300to$8,000",Monthly,"  Designing, evaluating, and implementing framework that can adequately handle the needs of a rapidly growing data driven company   Architecting and scaling data analytics infrastructure on AWS; finding opportunities to improve and optimize the workloads, processes to ensure that performance levels can support continuous accurate, reliable and timely delivery of key insights   Building, designing and deploying ETL pipelines   Manage continuous uptime of Data services by implementing High Availability tools and best practices   Manage the continuous testing and deployment of data pipelines, new data services and analytical reporting dashboards.   Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Partner data scientists and engineers by leading the movement cleaning and normalizing subsets of data of interest as preparatory step to prepare the rich data for deeper analysis on how to improve user experience for Grab customers around the region.  ","Requirements  3+ years of hands-on experience, preferably in data infrastructure   Experience in container management and orchestration tools like ECS, Kubernetes, and Mesos is a strong plus   A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines   Proficiency in Hadoop, Kafka and Spark databases in a large scale environment   Well versed in setting up continuous integration and deployment for big data or other projects.   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Comfortable with Linux Systems Administration  ",https://www.mycareersfuture.sg/job/data-engineer-grabtaxi-holdings-b87be1cbc6cf184b4f4ae0c75411040f,Central,Government support available
27,High-Performance Data Engineer,NIOMETRICS (PTE.) LTD.,Permanent,Professional,Information Technology,"$5,500to$11,000",Monthly,"WHAT WE DO We invite you to be part of our ambitious, close-knit team creating systems for large customers who need to crunch through Tbps of data in real-time. Our approach is relentless performance-oriented software engineering vs. server sprawl in our customers' datacentres. You will use the latest high-end hardware and continuously devise ways to push the envelope of software performance. We build in-house systems if we must. We had to for indexing 1M 60-column rows/s, for aggregating high throughput event streams over hundreds of combinations of dimensions, and for pattern matching 5M patterns at 100Gb/s per 2RU. We use these to solve real customer problems. You will experiment wildly. For example we implemented network monitoring using a GPU, and we tested 4-socket machines with 2T RAM. Our current favourite platform is a 2-socket system with Platinum 8180 CPUs (112 lcores in total), 4x40Gbps NICs and 1T RAM, which we use to process 160Gbps. You will help us build a successful software platform for the long run. We invest a lot in flexibility, such as with our extensible rule engine and declarative aggregation system that empowers our analysts and helps us minimise the C code we have to write for supporting disparate use-cases. We know the devil is in the details. You will improve performance through better memory allocation systems and better data structures, all while ensuring that they are integrated with Address Sanitizer and fully tested using unit tests and end-to-end regression tests. We work end-to-end. You will implement data engineering solutions that are both efficient and secure for handling events from 500 million users, and to extract insight without leaking individual information. We want to show off. To attract the best programmers we plan to showcase our technology. You can be part of our effort to open-source interesting pieces of our technology stack.   YOUR ROLE AS HIGH-PERFORMANCE DATA ENGINEER As a High-Performance Data Engineer, you will create and maintain tools, mainly in C, for crunching large amounts of data in files or streams. You will have to think both big, in terms of overall architecture, and small, in terms of low-level optimisations, to deliver solutions that are reusable, and match the performance of the best hardware. Every capability you add directly translates to new offerings made possible. Every percent of performance improvement directly translates to large cost savings. At the same time, the correctness and reliability of your work will be the cornerstone to our customers’ trust.",RequirementsWHAT WE VALUE  Bachelor’s or Higher Degree in Computer Science or equivalent Software craftsmanship Attention to reliability and successful delivery Experience with large C code bases and high-performance C programming Familiarity with shared memory data structures and parallel algorithms Proficiency with Linux system & development tools ,https://www.mycareersfuture.sg/job/high-performance-data-engineer-niometrics-4818bc33f80e5d67a0553b6d7348130d,East,
28,Data Engineer,ZAVE TECHNOLOGY PTE. LTD.,Permanent,Junior Executive,Information Technology,"$3,000to$4,000",Monthly,"You are passionate in growing your expertise in the following areas: * Data Pipelines * Data Warehousing * Statistics * Metrics Development What you’ll do as our data engineer : *Setup the first data pipeline from production systems to data warehouse *Build first data warehouse schema *Implement Segment and Mixpanel to understand our audiences *Work with business partners to establish the right questions that need to asked and answered from our data *Laying the ground work and building the systems towards the various NLP applications :    ** Reading responses to written tasks and determining outcomes related to accounting tasks (eg, selecting an account type for a bank account transaction)    ** Working on NLP chat bots to enhance our current generation of task assistants","RequirementsThe tech stack that you will be working with: * Python and SQL * Segment and Mixpanel * Databases (eg Postgres or MySQL) Your ideal profile: * Degree in Computer Science, Information Systems, Informatics, Statistics or another quantitative field; * Strong analytic skills related to working with unstructured datasets; * Demonstrated examples of root cause analysis on internal and external data and processes that address business questions and improvements; * Proficient in English.",https://www.mycareersfuture.sg/job/data-engineer-zave-technology-78cc7202accd0543cba338ff9a785456,Central,Government support available
29,DATA ENGINEER,ZENIKA PTE. LTD.,Full Time,Professional,Information Technology,"$5,000to$7,000",Monthly,"As a Data Engineer, you will work with our customers' Big Data teams to design and develop new data architectures. You will participate in setting up and enriching datalakes based on the Hadoop ecosystem. You will implement complex data acquisition and analysis workflows to bring out untapped business opportunities. You will work with Data Scientists in a spirit of sharing skills. You have a first significant experience on a Big Data project. You want to challenge yourself on a large volume of distributed and real-time infrastructures. You like to share your skills and take your technical choices. At Zenika you will be able to: - Evolve within a passionate team always on the lookout for a new technology to crunch the data - Taste of developing POCs on the most popular Frameworks - Have dedicated time to contribute to Open-Source projects - Animate hands-on for internal and external events - Attend the best conferences (Devoxx, Hadoop Summit Europe, Berlin Buzzwords, ...) - Become a certified trainer for our partners (Confluent, DataStax, Couchbase, Lightbend, ...)  ","Requirements- Java is your mother tongue. Object-Oriented Programming is an art of which you master the secret techniques (design patterns). - You are familiar with Frameworks of tests such as JUnit, Mockito, Gatling. - JSON and REST APIs are your daily routine. - The message brokers (Apache Kafka) are not unknown to you. - You prefer to use your ""relational"" skills to team building rather than to design the storage of your data. - Stream processing is the philosophy you adopted for your data projects (Spark, Flink, Kafka Streams, ...) - You do not imagine working on an environment other than Linux (Ubuntu, CentOS) - You are sensitive to craftsmanship approaches (CleanCode, TDD).",https://www.mycareersfuture.sg/job/data-engineer-zenika-15edec0b30fd66464eafeabe29b3eac1,Central,
30,Senior Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Permanent,Senior Executive,Information Technology,"$8,300to$15,000",Monthly,"Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience. What you do will be mixed of software engineering, system architecture design, and operation:   You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running   Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.   Explore/learn new technologies that can complement or replace our current stack to improve it.  ","Requirements  Passion in big data, software engineering, and systems.   Excellent analysis and reasoning of system behaviors   8+ years hands-on experience   Uphold best practices and principle around clean code, testing, continuous integration   Strong team player and collaborator   Having high level of responsibility and resilience in dealing with issues   Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.   Familiar with Java/JVM. Python is added advantage   Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.   Having systems operational experience is a bonus, but not required.  ",https://www.mycareersfuture.sg/job/senior-level-data-engineer-traveloka-services-9708b2f3aa461757cb12be6c9df31c95,,Government support available
31,Mid - Senior Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Permanent,Executive,Information Technology,"$6,100to$10,700",Monthly,"Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience. What you do will be mixed of software engineering, system architecture design, and operation:   You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running   Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.   Explore/learn new technologies that can complement or replace our current stack to improve it.  ","Requirements  Passion in big data, software engineering, and systems.   Excellent analysis and reasoning of system behaviors   6+ years hands-on experience   Uphold best practices and principle around clean code, testing, continuous integration   Strong team player and collaborator   Having high level of responsibility and resilience in dealing with issues   Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.   Familiar with Java/JVM. Python is added advantage   Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.   Having systems operational experience is a bonus, but not required.  ",https://www.mycareersfuture.sg/job/mid-senior-level-data-engineer-traveloka-services-80251b4e45e5ed8f6319c691e6d81568,,Government support available
32,Mid Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Permanent,Executive,Information Technology,"$4,300to$7,600",Monthly,"Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience. What you do will be mixed of software engineering, system architecture design, and operation:   You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running   Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.   Explore/learn new technologies that can complement or replace our current stack to improve it.  ","Requirements  Passion in big data, software engineering, and systems.   Excellent analysis and reasoning of system behaviors   3+ years hands-on experience   Uphold best practices and principle around clean code, testing, continuous integration   Strong team player and collaborator   Having high level of responsibility and resilience in dealing with issues   Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.   Familiar with Java/JVM. Python is added advantage   Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.   Having systems operational experience is a bonus, but not required.  ",https://www.mycareersfuture.sg/job/mid-level-data-engineer-traveloka-services-10ec08dd2c1d9154c02d032d6e438e7f,,Government support available
33,Junior - Mid Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Permanent,Fresh/entry level,Information Technology,"$3,000to$6,000",Monthly,"Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience. What you do will be mixed of software engineering, system architecture design, and operation:   You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running   Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.   Explore/learn new technologies that can complement or replace our current stack to improve it.  ","Requirements  Passion in big data, software engineering, and systems.   Excellent analysis and reasoning of system behaviors   Fresh Graduate to 4 years hands-on experience   Uphold best practices and principle around clean code, testing, continuous integration   Strong team player and collaborator   Having high level of responsibility and resilience in dealing with issues   Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.   Familiar with Java/JVM. Python is added advantage   Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.   Having systems operational experience is a bonus, but not required.  ",https://www.mycareersfuture.sg/job/junior-mid-level-data-engineer-traveloka-services-8870a85841fc70677fdef3807414055f,,Government support available
34,Data Engineer,THALES SOLUTIONS ASIA PTE. LTD.,"Permanent, Full Time",Executive,Engineering,"$5,000to$7,000",Monthly," You should be able to develop, construct and test architectures for data processing in an efficient manner i.e. marrying systems together via various tools You should be able to recommend and implement ways to improve data reliability, efficiency and quality Understand the functional aspects of the delivery and able to constructively discuss with the Data Scientist(s) You should be able to ensure data architecture will support the requirements of the business You should be able to develop processes for data modelling, mining and data production You should be able to discover data for acquisition e.g. social media data ingress into architecture ","Requirements Write and review the necessary technical documentation w.r.t data engineering Minimum of 5 years software experience where you spent at least 2 years in a data-oriented environment with a focus on data engineering. Have working knowledge of one or more programming languages like Java, Python, C++, Scala Have working knowledge of leveraging SQL, No-SQL databases in data architectures e.g PostgreSQL, MySQL, MongoDB, Cassandra, Hive Have demonstrated applications of data mining, data transformation to the ETL pipeline(s) Ability to convert technical data stories into working and tested code Has Agile methodology and process understanding and experience Has DevOps tooling user skillset in using Jira/Confluence, GIT and a CICD tool Has a continuous learning mindset and learning of new programming paradigms, techniques & practices Open, strong communicator who communicates effectively across teams, locations and cultures, in-person and virtually Courage of convictions with a high degree of humility. Embraces constructive feedback and is resilient ",https://www.mycareersfuture.sg/job/data-engineer-thales-solutions-asia-a61acadd3a13cabfa28cbd6ed9839dda,Central,
35,Data Engineer,CAPGEMINI SINGAPORE PTE. LTD.,Permanent,Professional,Engineering,"$5,500to$7,500",Monthly," RDBMS: Oracle, Postgres, MSSQL, Netezza ETL and Data Integration Tools: IBM Datastage, Pentaho, Talend, Attunity Big Data: Hadoop (Hortonworks), Hive QL, Spark, Sqoop, etc Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL, PL/SQL, NoSQL BI Tools: PowerBI, Qlik    Working Experience:  3-5 years in data engineering and modelling. Experience in designing and developing dataware house solutions Hands on in managing data mapping, data quality and integrity, performance in data processing, etc Experience in insurance domain (e.g. LifeAsia system) is an advantage Experience in Agile software development    Education  Bachelor in Computer Science, Computer Engineering or equivalent    Personal Traits  Proactive with can-do attitude Independent and self-motivated Able to work under pressure to meet tight timeline Able to provide regular updates   ","Requirements RDBMS: Oracle, Postgres, MSSQL, Netezza ETL and Data Integration Tools: IBM Datastage, Pentaho, Talend, Attunity Big Data: Hadoop (Hortonworks), Hive QL, Spark, Sqoop, etc Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL, PL/SQL, NoSQL BI Tools: PowerBI, Qlik    Working Experience:  3-5 years in data engineering and modelling. Experience in designing and developing dataware house solutions Hands on in managing data mapping, data quality and integrity, performance in data processing, etc Experience in insurance domain (e.g. LifeAsia system) is an advantage Experience in Agile software development    Education  Bachelor in Computer Science, Computer Engineering or equivalent    Personal Traits  Proactive with can-do attitude Independent and self-motivated Able to work under pressure to meet tight timeline Able to provide regular updates   ",https://www.mycareersfuture.sg/job/data-engineer-capgemini-singapore-d10dfc4f7055ae16e42b97aede1dc49d,Central,Government support available
36,Senior Data Engineer,POCKETMATH PTE. LTD.,Permanent,Professional,Engineering,"$8,000to$12,000",Monthly,"You will be working on our datasets to ensure they are highly available, fast and optimized. Datasets are consumed by multiple backend components, reporting and analytics systems, ad hoc investigations, etc. This data is also consumed by our Product and Brand safety teams to improve the overall product and user experience.  This job includes developing, scaling, and maintaining big data warehousing solutions, ensuring measurement accuracy, data consistency and correctness. Driving fast and efficient decision making based on data collected from our platform that serves millions of ad impressions and processes billions of ad opportunities every day.  Job responsibilities  Develop and maintain efficient and scalable data pipelines to provide analytics to other teams. Make data a first class citizen in our platform and make it easy to discover and use. Work in tandem with other engineering and product teams to deliver end to end solutions. Quickly react to any production issues and come up with rapid fixes. ","RequirementsRequirements  BS, MS, or PhD in Computer Science or similar technical field 3+ years experience developing data pipelines, data warehousing, metrics systems, etc Familiarity with variety of databases Strong knowledge of SQL based RDBMS Familiarity with data infrastructure ecosystem Knowledge of Hadoop and/or other MadReduce-based systems Strong skills with Java or Scala for data processing  Ideal candidate  Experience working in Ad tech industry Experience with AWS (EC2, ECS, S3, Kinesis, EMR, Glue, Athena) Experience with microservices architecture Experience with high performance, low latency, real-time systems ",https://www.mycareersfuture.sg/job/senior-data-engineer-pocketmath-b212918be9ac78f109bf5a83435793c0,,Government support available
37,"VP, Senior Data Engineer Consultant, CBG and Big Data Analytics Technology, T&O (1800059H)",DBS BANK LTD.,"Permanent, Full Time",Senior Management,Banking and Finance,"$10,400to$18,700",Monthly," You will conduct technical workshops, develop and deliver small proof-of-concept projects, create tutorials and demos. These engagements will focus on solutions such as Data Processing, Data Analytics, Machine Learning, and others. As part of our Enterprise Data Platform, you will also have the opportunity to create white papers, write blogs, build data processing pipelines, develop dashboards and other reusable assets that can be utilized by our internal users. You’ll be working closely with our Solution Architects and Engineering teams. The ideal candidate will have extensive experience with design, development and operational knowledge Apache Spark, Apache Kafka, Jenkins, Python, Bash, Hadoop and other Big Data tech stack. Prior experience with pre-sales or educating activities is a big plus as you’ll be expected to conduct technical workshops. ","Requirements 3+ years of hands on experience in distributed data architectures is a must 3+ years of Core Java 8 or Scala or Python is a must Working knowledge of Spark is a must CI/CD experience (Jenkins, GitHub) is a must Prior experience as a Presales (Technical) Engineer with data experience are preferred. Working knowledge of Bash scripts is a must AWS experience is nice to have Kubernetes or Docker experience is nice to have ",https://www.mycareersfuture.sg/job/vp-senior-data-engineer-consultant-cbg-big-data-analytics-technology-to-dbs-bank-8c58379b68103b67e3a76d99d4729996,,Government support available
38,"AVP, Senior Data Engineer Consultant, CBG and Big Data Analytics Technology, T&O (1800059H)",DBS BANK LTD.,"Permanent, Full Time",Senior Management,Banking and Finance,"$6,500to$11,700",Monthly," You will conduct technical workshops, develop and deliver small proof-of-concept projects, create tutorials and demos. These engagements will focus on solutions such as Data Processing, Data Analytics, Machine Learning, and others. As part of our Enterprise Data Platform, you will also have the opportunity to create white papers, write blogs, build data processing pipelines, develop dashboards and other reusable assets that can be utilized by our internal users. You’ll be working closely with our Solution Architects and Engineering teams. The ideal candidate will have extensive experience with design, development and operational knowledge Apache Spark, Apache Kafka, Jenkins, Python, Bash, Hadoop and other Big Data tech stack. Prior experience with pre-sales or educating activities is a big plus as you’ll be expected to conduct technical workshops. ","Requirements 3+ years of hands on experience in distributed data architectures is a must 3+ years of Core Java 8 or Scala or Python is a must Working knowledge of Spark is a must CI/CD experience (Jenkins, GitHub) is a must Prior experience as a Presales (Technical) Engineer with data experience are preferred. Working knowledge of Bash scripts is a must AWS experience is nice to have Kubernetes or Docker experience is nice to have ",https://www.mycareersfuture.sg/job/avp-senior-data-engineer-consultant-cbg-big-data-analytics-technology-to-dbs-bank-1d8ad72709f3154a32cd9de7d7cf0735,,Government support available
39,Data Engineer,DATAROBOT SINGAPORE PTE. LTD.,Permanent,Professional,Information Technology,"$100,000to$160,000",Annually,"Data Engineer Singapore DataRobot is looking for an experienced software engineer to join our team working on Big Data problems.  As a team member, you will work on building a data processing framework that allows the DataRobot application to scale to new heights. The ideal candidate should have experience in distributed computing and storage architectures and be able to think at scale.","Requirements Bachelor's degree in Computer Science, Engineering, or related field 5+ years experience building large scale, highly available, distributed computing systems 1+ years experience in Scala or Java  2+ years experience working in the Hadoop stack (HDFS, Yarn, ZooKeeper, etc.) 3+ years experience in Python. Fundamental knowledge of data structures, algorithms, and complexity analysis Ability to expertly design and produce high quality, high performance code ready to ship Hands on experience with Big Data technologies (e.g. Hadoop MapReduce, Spark, Hive, Vertica, Netezza, Greenplum, Aster) Familiarity with internals of distributed data processing engines such as Spark Ability to evaluate and optimize performance and scalability in the context of big data processing and storage. Experience working in GNU/Linux environments Understanding of software design principles and best practices (test driven development, source control management) Open minded, curious, and thorough. Proficient in English ",https://www.mycareersfuture.sg/job/data-engineer-datarobot-singapore-b1f81a36ee1f58095e92b7f8df51dc55,Central,Government support available
40,Data Engineer,RAKUTEN ASIA PTE. LTD.,Full Time,Executive,Information Technology,"$4,500to$8,000",Monthly," Implement cutting-edge data infrastructure platform which is vendor unlocked and multi-tenant. Implement and manage robust ETL pipeline based on streaming. Implement easy-to-use generalized data accessing layer by leveraging the details of storage engine. Implement distributed machine learning pipeline by coordinating with data science team. Develop data driven culture for integrated partners. Propose new technologies, tools to improve whole process of data system integration. ","RequirementsMust have  Experience in at least one language for web backend application & data processing, such as Java, Python, etc. Experience in NoSQL database, such as Redis, Solr, MongoDB, etc. Experience in Linux system operation, ability to manage system level task such as monitoring and troubleshooting your deployed applications. Good communication skills, ability to work in fast pace R&D. High motivation for learning, skill up, system ownership and contribution to the team.  Must have for Senior position  3+ years of experience in developing large scale data processing platform of various unstructured data. 3+ years of experience in using various big data frameworks and NoSQL databases, such as Hadoop, Kafka, Redis, Solr, etc. Practical knowledge of web system performance tuning including OS, middleware, I/O and application.  Good to have  Experience on cloud computing service, such as AWS. Experience in handling multilingual data. Knowledge in data science domains, such as NLP, Data Mining, and Deep Learning will help your collaboration with the data scientists. ",https://www.mycareersfuture.sg/job/data-engineer-rakuten-asia-d9253502fec7b656baeaab5cc1835d7c,Central,Government support available
41,Data Engineer (1 year contract),PRUDENTIAL ASSURANCE COMPANY SINGAPORE (PTE) LIMITED,Contract,Senior Executive,"Engineering, Information Technology, Insurance","$5,000to$8,000",Monthly,"Job Description Summary In this role, you will design, develop and provide support for various data systems (based on both traditional RDBMS and big data platform) in Prudential Singapore. As part of this dynamic role, you will report to Lead System Analyst, and work closely with business units and other IT teams to deliver leading edge technology to enable digital capabilities of Prudential Singapore.  Analyse business needs in order to design, develop and deliver data solutions to meet business objectives Provide application maintenance and support for various data systems in accordance to Service Level Agreement Deliver data solutions in accordance to relevant IT policies and procedures Provide and share knowledge to other team members ","RequirementsCompetencies & Personal Traits    Independent and works well across different functions   Excellent problem analysis skill. Innovative and creative in developing solutions   Strong sense of drive and commitment to deliver on responsibilities   Strong verbal and written communication skills   Works well in a dynamic environment   Ability and willingness to be hands-on   Experience in 2 or more of the following technology:     RDBMS: Oracle, Postgres, MSSQL, Netezza ETL and Data Integration Tools:  IBM Datastage, Pentaho, Talend, Attunity BI Tools: PowerBI, Qlik Big Data: Hadoop (Hortonworks), Hive QL, Spark, Sqoop, etc Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL, PL/SQL, NoSQL      Working Experience:    2-8 years in designing and developing and support applications. Fresh graduates are welcome to apply   Experience in Agile software development    Education    Bachelor in Computer Science, Computer Engineering or equivalent   ",https://www.mycareersfuture.sg/job/data-engineer-prudential-assurance-company-singapore-4982b4b9db0341c48b09099ca8365715,Central,
42,Data Engineer,RAKUTEN ASIA PTE. LTD.,Full Time,Manager,Information Technology,"$4,500to$8,000",Monthly," Implement cutting-edge data infrastructure platform which is vendor unlocked and multi-tenant. Implement and manage robust ETL pipeline based on streaming. Implement easy-to-use generalized data accessing layer by leveraging the details of storage engine. Implement distributed machine learning pipeline by coordinating with data science team. Develop data driven culture for integrated partners. Propose new technologies, tools to improve whole process of data system integration. ","RequirementsMust have  Experience in at least one language for web backend application & data processing, such as Java, Python, etc. Experience in NoSQL database, such as Redis, Solr, MongoDB, etc. Experience in Linux system operation, ability to manage system level task such as monitoring and troubleshooting your deployed applications. Good communication skills, ability to work in fast pace R&D. High motivation for learning, skill up, system ownership and contribution to the team.  Must have for Senior position  3+ years of experience in developing large scale data processing platform of various unstructured data. 3+ years of experience in using various big data frameworks and NoSQL databases, such as Hadoop, Kafka, Redis, Solr, etc. Practical knowledge of web system performance tuning including OS, middleware, I/O and application.  Good to have  Experience on cloud computing service, such as AWS. Experience in handling multilingual data. Knowledge in data science domains, such as NLP, Data Mining, and Deep Learning will help your collaboration with the data scientists. ",https://www.mycareersfuture.sg/job/data-engineer-rakuten-asia-e5556b6edf0546b28019f1ca66cf2445,Central,Government support available
43,DATA ENGINEER,WSH EXPERTS PTE. LTD.,Full Time,Professional,"Design, Engineering, Information Technology, Others","$4,000to$6,000",Monthly," Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements Automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc Work with data and analytics experts to strive for greater functionality in our data systems. Designing data warehouse dimensional modelling ","Requirements Degree from a recognised university, preferably in Data Analytics or Computer Science domain; Must have at least two years hands-on experience as a Data Engineer; Must have knowledge of data warehouse concept (Star, snowflake or data vault) methodology and experience in designing data warehouse dimensional modelling Must have at least one year experience in Microsoft SSIS, Microsoft SSAS, Microsoft SQL Server and Python Knowledge of Azure or Microsoft MDM or .Net or C# or NoSQL or open source data analytics software will be advantageous ",https://www.mycareersfuture.sg/job/data-engineer-wsh-experts-ef93c0f21815cfce95d1313eefa393ca,,Government support available
44,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-9c999223513204829571b526116d0a8e,Central,
45,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-6151ed07ab7631ad36ba0b3b6addcfc9,Central,
46,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-f34bee56895534487ba687a5cc60ebe1,Central,
47,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-d65a0cdbc221257155e1280e9b9f8e39,Central,
48,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-5f18b458f9506576215c3fb0a7991c03,Central,
49,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Professional,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to hr@machspeed.com.sg for faster processing. Alternatively, please visit http://www.facebook.com/MachspeedHR for more jobs available, thank you. Shortlisted candidates will be contacted for interview session via phone. Thank you very much. Agency License No. 12C6200 / EA Personnel No.: R1548977",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-6e0155d876600e31d54ece9decec9cbb,Central,Government support available
50,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-9b0ecd4bea2dffefc12de8acaf63fa75,Central,
51,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-e8173565ba67540e66912abb69c1c442,Central,
52,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Professional,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to hr@machspeed.com.sg for faster processing. Alternatively, please visit http://www.facebook.com/MachspeedHR for more jobs available, thank you. Shortlisted candidates will be contacted for interview session via phone. Thank you very much. Agency License No. 12C6200 / EA Personnel No.: R1548977",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-1cbdce1d06f02b2bc1ebf61b4640cfff,Central,Government support available
53,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-ed1be252fa40dc466e6a5bbe8212e087,Central,
54,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-13f9fd09543765ba1ea4c456ec0ca041,Central,
55,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-4b43620f59ca8d687fd939242460261f,Central,
56,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-f969ee442dae7cd331dc22a2adc8c258,Central,
57,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Professional,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to hr@machspeed.com.sg for faster processing. Alternatively, please visit http://www.facebook.com/MachspeedHR for more jobs available, thank you. Shortlisted candidates will be contacted for interview session via phone. Thank you very much. Agency License No. 12C6200 / EA Personnel No.: R1548977",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-e75799ebf86919a1bdb726f2f318836d,Central,Government support available
58,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-45eccd1cbd3d291e3d9d55f68b4ceae4,Central,
59,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-bde1577d4eb6b1af35fc31755cf89c96,Central,
60,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Professional,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to hr@machspeed.com.sg for faster processing. Alternatively, please visit http://www.facebook.com/MachspeedHR for more jobs available, thank you. Shortlisted candidates will be contacted for interview session via phone. Thank you very much. Agency License No. 12C6200 / EA Personnel No.: R1548977",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-62f14b1d53f6e3e421f526f0b7c62400,Central,Government support available
61,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-294eb859a521bc74ab22f42c8009eac6,Central,
62,"Data Engineer (5 days, Orchard, $3500-4000)",MACHSPEED HUMAN RESOURCES PTE. LTD.,Permanent,Executive,Information Technology,"$3,500to$4,000",Monthly,"Data Engineer (5 days, Orchard, $3500-4000) Leading System Integrator company providing IT solutions for network, IT infrastructure, analytics, cyber security and managed services. Job Responsibilities  Design, engineer, configure and administer BI project based on given functional and technical requirements Collaborate with pre-sales, project and relevant internal teams to deliver the optimal technical solution to client's business problems Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations Review and monitor ETL tasks and performance Support testing and deployment Provide recommendations and implementation changes to optimize in the customer environment. Write and develop custom scripts as needed   ","RequirementsRequirements  Minimum Degree/Diploma in Computer Science, Engineering or IT with at least 2 years of relevant experience Hands-on experience in scripting/programming Possess knowledge in Networking and Servers(Windows and Linux) Possess CEH/ECSA/CISSP/ECSA/CompTIA Security+ certification will be an added advantage Working hours: 9am - 6pm, Mondays to Fridays Salary range: $3500 - 4000  We thank you for your interest in this position, applicants with relevant experience please send Microsoft word resume with expected salary to apply@machspeed.com.sg for faster processing, alternatively, please visit https://www.facebook.com/MachspeedHR for more jobs available, thank you. You may also call +6563362530 (Look for BingCheng) to find out more Thank you very much.         Agency License No. 12C6200 EA Registration No: R1437671",https://www.mycareersfuture.sg/job/data-engineer-machspeed-human-resources-1909e6f4ba0e948fbf473269347d7eb0,Central,
63,Field Operation Engineer - Big Data Engineer,DATHENA SCIENCE PTE. LTD.,"Full Time, Internship",Executive,Engineering,"$2,000to$5,000",Monthly,"About Dathena Science Dathena is a Swiss and Singaporean company developing data governance software based on machine learning algorithms.  Purpose  Become a trusted expert in Dathena, our client platforms & partner vendor functionality to provide effective operational guidance around these technologies. Oversee client service requests acting as a service delivery and escalation manager. Develop best practice recommendations for Dathena's operations teams based on product and vertical experience gained in the field.  Responsibilities  Appliances installation and configuration Hadoop cluster building and configuring, performance monitoring Deployment process optimisation Create reliable data pipelines Key metrics monitoring for failures prevention Communication with AI Developers and Data Science teams Communicate and present to the clients ","RequirementsSkills  Experience in building and supporting Hadoop / BigData architecture including Yarn, HDFS, Hbase, Zookeeper, Phoenix, Spark, Hive, Kafka etc. Ability to isolate and troubleshoot Hadoop service issues using a combination of system and Hadoop logs and monitoring/alerting systems. Experience with Apache Ambari. Experienced in Linux (RHEL, CentOS, Ubuntu, Debian, ...) including network and scripting (Bash, Python) Deep understanding of complete end-to-end Data-warehouse / Data Analytics solutions. Containers (Docker, OpenShift) Experience with Spark development is an added advantage Interpersonal skills  Key metrics  Customer satisfaction (customer lifetime value improvement) Partner satisfaction Issue resolution speed Contributions to the overall platform Internal communication  Working conditions As a critical link between the client and the development, you must fully embrace the team spirit of a young and innovative Start-up. Business trips are possible.",https://www.mycareersfuture.sg/job/field-operation-engineer-big-data-engineer-dathena-science-817389eb9f9b7b01508fe9331f4d526f,,Government support available
64,"VP, CAP Data Engineer, Middle Office Tech, Technology & Operations (WD02988)",DBS BANK LTD.,Full Time,Senior Management,Information Technology,"$10,400to$18,700",Monthly,"Business Function  Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.   About the role   This role requires an experienced data engineer, with knowledge of end to end credit life cycle management from credit origination to credit measurement/monitoring, to actively execute and monitor project related activities and constantly deliver quality project deliverables. The candidate shall be required to quickly understand the current operating model and define the target state operating model.  Working as part of a regional team within our Singapore office although some overseas travel will be required.   Responsibilities   On a day to day basis provide support to the project team lead within the program. The candidate will be responsible for ensuring coordination of project activities and delivering of project deliverables. The candidates may be required to work across various projects within the program. The candidate should have an understanding of a wide range of banking book products with an appreciation of counterparty credit processes.    Gather and document business and technology requirements; data analysis. Define business processes & data flows. Work with system architects to define appropriate technology solutions.  Document the necessary functional specifications for system development. Work closely with UX designer on clarifying requirements throughout the project life cycle. Act as an interface between development teams and business end users. Liaise with system developers through the system development life cycle to ensure common understanding. Assist in day to day project activities to ensure document, activities are monitored and completed on time. Support project managers to provide weekly status updates and track project schedule. Lead project streams and manage project finances when required. Manage change in requirements based on defined process Plan, Participate and Coordinate test phases prior to implementation. Develop test plans against the functional specification. Execute functional testing of the new solution. Support various stages of testing, including UAT in preparation for production go-live. Assist preparation of training materials and user guide; conduct necessary training to users. Assist product owner in the development of user guides/manuals. Assist in preparation of project review and closure documents. ","Requirements This is a hands-on role requiring a strong business analyst to engage in a fast moving and large scale credit architecture development program. Minimum of 8 years of working experience within an international banking environment of which at least 3 years in a credit related environment, with exposure of project / program management and involvement. Good understanding of banking domain (specific domain: credit process), banking book (Lending, Trade Finance and CASA) products with credit risk management. Experience in capturing business and technology requirements, systems development life cycle, writing functional specifications, writing test scripts and executing functional tests, analysis of credit risk system requirements. Experience of working with relationship managers, credit risk managers and technical specialists; and understand credit risk end-to-end management and operating model. Proven track record of participating in the delivery of credit risk technology solutions. Either vendor systems or preferably an in-house solution. Ability to plan and conduct interviews with business end users on complex topics. A motivated self-starter with ability to multitask but requires minimal supervision to meet challenging targets, embody a `whatever it takes to get the job done` attitude. Able to operate independently and make sound decisions, but a team player with collaborative attitude and enjoys working in teams. Effective problem solving and analytical skills with attention to detail while maintaining a big picture outlook. Maintain high productivity in a fast paced environment showing effective prioritization skills. Excellent written and verbal communication and interpersonal skills. Proficient in MS Office and able to produce board-level documentation. Proficiency in some form of programming and database technology, such as Java, Oracle/Mysql/Mongodb etc… Strong facilitation skills and experience facilitating workshops with large groups. Experience in various requirements models like use case models, business process models, data flow diagrams, context diagrams and sequence diagrams etc… Experience in working with agile software development methodologies. Some skills in usage of any issue/problem tracking, defect management tool and MS SharePoint is required. Experience in working with multi location teams will be an added advantage. ",https://www.mycareersfuture.sg/job/vp-cap-data-engineer-middle-office-tech-technology-operations-dbs-bank-469a8c26a836193d1121507c0a65728e,East,Government support available
65,Data Engineer,LINKSURE NETWORK HOLDING PTE. LIMITED,Permanent,Senior Executive,Information Technology,"$6,000to$10,000",Monthly,"Responsibilities:   Work with various volumes of data from different sources. Design, build, maintain and optimize the ETL processes in production from these data Manage the delivery of high impact report, dashboards and visualizations Improving the current data pipeline and implement new pipeline along with the evolution of product Collaborate with product and engineering teams to understand needs and assist with data-related issues and provide deliverables   ","RequirementsRequirements:   2+ years hands-on experience in data warehouse and ETL design Experience in designing, building and deploying production-level data pipeline using tools from Hadoop stack: HDFS, Hive, Flume, Kafka, etc. Experience in spark streaming is a plus 2+ years experience in working with relational SQL and NoSQL databases Strong programming skills in Python and Shell. Java will be a plus Experience with version control systems, Git, SVN Experience with data pipeline and workflow management tools: Azkaban, Oozie, Airflow, etc. Experience in application status monitoring (Prometheus + Grafana, Zabbix, etc.) and container technology will be a plus. Proficient in English and Mandarin (this position is required to communicate daily with colleagues in China) ",https://www.mycareersfuture.sg/job/data-engineer-linksure-network-holding-b77c32f935acfda41f1130f81cb00381,,
66,"Senior Manager, Data Engineer",LAZADA SOUTH EAST ASIA PTE. LTD.,Full Time,Manager,Information Technology,"$9,000to$13,000",Monthly,"Team Introduction Lazada is the number one online shopping & selling destination in Southeast Asia – present in Indonesia, Malaysia, the Philippines, Singapore, Thailand and Vietnam. Lazada helps more than 80,000 local and international sellers as well as 2,500 brands serve the 560 million consumers in the region through its marketplace platform, supported by a wide range of tailored marketing, data, and service solutions. Lazada offers an excellent customer experience through a wide network of logistics partners and its own first- and last-mile delivery arm. Roles & Responsibilities  Implementing working data projects based on given technical specifications Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations. Work closely with partner teams to establish the optimal technical solution to business problems Monitor & manage data pipelines, ensuring accuracy and stability ",Requirements Educational background in Computer Science / Electrical Engineering or similar Understanding of database concepts and distributed processing systems Experience with programming and understanding of basic algorithms Strong command of SQL and database concepts Preferred previous knowledge of Hadoop or NOSQL databases Excellent communication & problem solving skills  ,https://www.mycareersfuture.sg/job/senior-manager-data-engineer-lazada-south-east-asia-d10b977e8ab9f32f8692dd165d59afcc,Central,Government support available
67,"Vice President, Data Engineer",LAZADA SOUTH EAST ASIA PTE. LTD.,Full Time,Middle Management,Information Technology,"$9,000to$13,500",Monthly,"Team Introduction Lazada is the number one online shopping & selling destination in Southeast Asia – present in Indonesia, Malaysia, the Philippines, Singapore, Thailand and Vietnam. Lazada helps more than 80,000 local and international sellers as well as 2,500 brands serve the 560 million consumers in the region through its marketplace platform, supported by a wide range of tailored marketing, data, and service solutions. Lazada offers an excellent customer experience through a wide network of logistics partners and its own first- and last-mile delivery arm. Roles & Responsibilities  Implementing working data projects based on given technical specifications Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations. Work closely with partner teams to establish the optimal technical solution to business problems Monitor & manage data pipelines, ensuring accuracy and stability ",Requirements Educational background in Computer Science / Electrical Engineering or similar Understanding of database concepts and distributed processing systems Experience with programming and understanding of basic algorithms Strong command of SQL and database concepts Preferred previous knowledge of Hadoop or NOSQL databases Excellent communication & problem solving skills  ,https://www.mycareersfuture.sg/job/vice-president-data-engineer-lazada-south-east-asia-2d5ab5c401d990259d2903a2229cb6da,Central,Government support available
68,Lead Data Engineer - Business Intelligence,APPLE SOUTH ASIA PTE. LTD.,Full Time,Senior Executive,Information Technology,"$8,000to$15,000",Monthly,"Imagine what you could do here. At Apple, new ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Apple's Global Business Intelligence (GBI) team is looking for a Software Engineering Lead for Apple’s Data Warehousing, Business Intelligence and Analytics solutions. Take a leadership role to implement innovative and challenging reporting solutions for one of the world's largest databases.   GBI team builds extraordinary high performing reporting and analytics solutions. The team consists of delivery leads and development engineers. This role is responsible for the design, implementation, maintenance, and overall health of DW solutions.   We are seeking a pro-active solution-oriented individual with strong written and verbal communication skills, and have a proven track record in Data warehousing architecture, application design, software lifecycle and technical team management coupled with excellent leadership skills.   You will enjoy the benefits of working in a fast growing business where you are inspired to ""Think Different"" and where your efforts play a key role in the success of Apple's business. - Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data induction, build optimized aggregates and building reporting solutions - Provide leadership and expertise to define solutions architecture and strategies at all layers, for next generation reporting platform with high performance and scalability - Lead a portfolio of multiple projects, setting priorities with measurable objectives, monitoring and reporting on the process, progress and results - Own ultimate responsibility for the deliverables, working with support and daily operations team to ensure 7x24 operation. - Effectively communicate program status to the senior management and functional partners on a regular basis - Keep up-to-date on the newest technology solutions in market to generate innovative ideas to solve business challenges - Influence work of global multi-functional teams - Provide technical guidance, direction and problem solving to engineering team members. Drive technical excellence in software development and solution design. - Use and help chip in to standard software engineering processes, improve development methodologies over time. - Provide staffing coordination and planning to achieve timely delivery of multiple, concurrent initiatives.","Requirements We are looking for, 8+ years experience developing DW solutions 3+ years leading a technical team, including prior hands-on technical experience  Architect and design Enterprise Data warehouse and reporting solutions  Solid understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency  Translate complex business requirements into scalable technical solutions meeting Data warehousing standards  Provide solutions and recommendations on technical issues in production system  Hands on experience in 2 or more of the database technologies like Teradata, Hadoop, Oracle and Vertica  Good programming experience in at least 1 of the following programming languages C, C++, Java, Perl, Python  Experience in architecting and building robust, scalable and performant data warehousing and analytics solutions  Experience or knowledge in the following areas will definitely be a plus : New generation technologies like Spark, Scala, Kafka, Advanced Python Big Data and NoSQL - Mongo, Cassandra Data Science and Machine Learning Knowledge Cloud technology exposure BS Degree in computer science or an equivalent ",https://www.mycareersfuture.sg/job/lead-data-engineer-business-intelligence-apple-south-asia-97237952a628ec3101a70cd7dc5a5ea9,South,
69,Lead Data Engineer - Business Intelligence,APPLE SOUTH ASIA PTE. LTD.,Full Time,Senior Executive,Information Technology,"$5,000to$10,000",Monthly,"Imagine what you could do here. At Apple, new ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Apple's Global Business Intelligence (GBI) team is looking for a Software Engineering Lead for Apple’s Data Warehousing, Business Intelligence and Analytics solutions. Take a leadership role to implement innovative and challenging reporting solutions for one of the world's largest databases.   GBI team builds extraordinary high performing reporting and analytics solutions. The team consists of delivery leads and development engineers. This role is responsible for the design, implementation, maintenance, and overall health of DW solutions.   We are seeking a pro-active solution-oriented individual with strong written and verbal communication skills, and have a proven track record in Data warehousing architecture, application design, software lifecycle and technical team management coupled with excellent leadership skills.   You will enjoy the benefits of working in a fast growing business where you are inspired to ""Think Different"" and where your efforts play a key role in the success of Apple's business. - Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data induction, build optimized aggregates and building reporting solutions - Provide leadership and expertise to define solutions architecture and strategies at all layers, for next generation reporting platform with high performance and scalability - Lead a portfolio of multiple projects, setting priorities with measurable objectives, monitoring and reporting on the process, progress and results - Own ultimate responsibility for the deliverables, working with support and daily operations team to ensure 7x24 operation. - Effectively communicate program status to the senior management and functional partners on a regular basis - Keep up-to-date on the newest technology solutions in market to generate innovative ideas to solve business challenges - Influence work of global multi-functional teams - Provide technical guidance, direction and problem solving to engineering team members. Drive technical excellence in software development and solution design. - Use and help chip in to standard software engineering processes, improve development methodologies over time. - Provide staffing coordination and planning to achieve timely delivery of multiple, concurrent initiatives.","Requirements We are looking for, 5+ years experience developing DW solutions 3+ years leading a technical team, including prior hands-on technical experience  Architect and design Enterprise Data warehouse and reporting solutions  Solid understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency  Translate complex business requirements into scalable technical solutions meeting Data warehousing standards  Provide solutions and recommendations on technical issues in production system  Hands on experience in 2 or more of the database technologies like Teradata, Hadoop, Oracle and Vertica  Good programming experience in at least 1 of the following programming languages C, C++, Java, Perl, Python  Experience in architecting and building robust, scalable and performant data warehousing and analytics solutions  Experience or knowledge in the following areas will definitely be a plus : New generation technologies like Spark, Scala, Kafka, Advanced Python Big Data and NoSQL - Mongo, Cassandra Data Science and Machine Learning Knowledge Cloud technology exposure BS Degree in computer science or an equivalent ",https://www.mycareersfuture.sg/job/lead-data-engineer-business-intelligence-apple-south-asia-f057e50ae5d9243abc9062af0bdb7e1d,South,
70,Data Engineer,DP INFORMATION NETWORK PTE. LTD.,Permanent,Professional,Information Technology,"$6,000to$8,000",Monthly,"Key Responsibilities   Responsibilities include, but are not limited to, taking the lead in the following areas:  Ideal candidate will demonstrate ability to deliver results quickly while working in a dynamic, cross functional, team-oriented environment Support the engineering and analytics teams through the use and understanding of analytical tools operating in a big data cloud environment Collaborate with the Global Architecture team members to continue to evaluate, recommend, and integrate new analytical tools Provide technical leadership and hands-on validation of systems during the design, development, and testing Proven record of success in world-class enterprise big data engineering Experience with commercial big data environments -- Cloudera preferred   Experience with cloud solutions – AWS preferred. Good to know - AWS CLI, BOTO, AWS Lambda, Automation Experience with analytical domain tools including SAS, R Studio, Hue, Python, JupyterHub, H2O, Cloudera, Databricks etc. Working knowledge of automated configuration and deployment of tools is a plus Working knowledge of scripting required. Experience with Python is preferred, and other scripting experience is a plus Working knowledge of both Windows and Linux environments is required, along with Hadoop. Cloudera is preferred Knowledge of software development practices and IT operations life cycles is required Experience working in Scrum Agile environment Experience working in a complex, matrix organization, and working with multiple stakeholders across functional and technical skillsets Ability to effectively work with business and other IT teams Excellent verbal and written communication skills. Ability to communicate effectively with development, operations, project, management, and business personnel Applies existing knowledge, and ability to learn and apply more. Tries new approaches and learns from each work assignment Demonstrates flexibility within a variety of changing situations, while working with individuals and groups. Multitasks when required, and where minimal supervision is required – demonstrates ability to produce quality Hand over specifications to the technical teams so they can develop technical specification that meet the business requirements. Support the technical teams in understanding the business requirements. Maintain a high level of mutual respect and open communication with the client stakeholders at all levels of the project team, PM and executive sponsors   ","RequirementsExperience   List the skills, experience, education etc.     Minimum of 5 -8 years in progressive professional roles in big data and analytics A bachelor's degree in information systems, engineering, computer science or equivalent work experience in big data is preferred A high calibre individual who can create and propose technical data engineering solutions using open source technology stack and which support the analytical tool of choice of our data scientists You will play a critical role in designing, developing and implementing data lakes using big data technologies such as Hadoop. Candidate needs to be hands-on and have a curios nature You will be responsible for building scalable distributed data solutions In collaboration with subject matter experts and data stewards, defines and implements data strategy, policies, controls, and programs to ensure the enterprise data is accurate, complete, secure, and reliable Manages, analyzes, and resolves data initiative issues and manages revisions needed to best meet internal and customer requirements while adhering to published data standard Assists in the application and implementation procedures of data standards and guidelines on data stewardship, coding structures, and data replication to ensure access to and integrity of data sets Be proactive and a self-starter, and be comfortable with ambiguity Experian product knowledge is advantageous, but not essential Preferably some vendor experience   Should have previously worked on a large scale Big Data project till implementation Strong presentation skills Self-motivated, assertive, goal oriented and able to work productively with minimal supervision Excellent written and verbal communication skills Good interpersonal skills and ability to work effectively with other team members, on a global basis   Technical Skills:  5+ years of hands-on programming using Python, Java, C, C++, and Scala 5+ years of hands on experience using:   BigData Technologies: HDFS, HBASE, HIVE, MapReduce, PIG, SPARK, IMPALA, STORM, KAFKA NoSQL Technologies: SOLR, CASSANDRA, NEO4J and REDIS Cloud Technologies: AWS. Good to know AWS CLI, BOTO, AWS Lambda, Automation   Working Knowledge of RDBMS DB Working knowledge of developing RESTFUL API’s Knowledge of UNIX – Script language is highly preferable Knowledge of multi-tier architectures and deployment Knowledge of real-time, batch applications Knowledge of IBM mainframes, z/OS, and virtualization technologies a plus Knowledge of Change Data Capture/Replication technologies a plus     ",https://www.mycareersfuture.sg/job/data-engineer-dp-information-network-828ce4ce4c25d05781945dd2f35d07d6,Islandwide,
71,Data Engineer,DYNAMIC TECHNOLOGY LAB PRIVATE LIMITED,Full Time,Fresh/entry level,Information Technology,"$4,500to$8,000",Monthly,* coordinate with model researchers to develop data jobs * design workflow/framework to facilitate exploring large scale data * monitor and maintain daily data production,"Requirements* patient, detail-oriented and highly responsible; * willing to learn complicated topics, to solve difficult problems, and to handle tedious tasks carefully; * strong programming skills in C/C++/Python; * comfortable with Linux; * strong problem solving skills;  The following skills are bonus: * knowledge on database * web development experience * experience with large data (>100G) * foreign languages such as French, German, Japanese and Korean.",https://www.mycareersfuture.sg/job/data-engineer-dynamic-technology-lab-271b0336785bcbd5e046a4aa2b500c42,Central,Government support available
72,Data Engineer - SQL  /  Big Data  /  Java,DENODO TECHNOLOGIES PTE. LTD.,Full Time,Professional,"Engineering, Information Technology",Salary undisclosed,,"Your Opportunity Denodo is always looking for technical, passionate people to join our Services Engineering team. We want a professional who will travel, consult, develop, train and troubleshoot to enhance our clients’ journey around Data Virtualization. Your mission: to help people realize their full potential through accelerated adoption and productive use of Denodo solutions. In this role you will successfully employ a combination of high technical expertise and client management skills to conduct on-site and off-site consulting, product implementation and solutions development in either short or long-term engagements being critical point of contact for getting things done among Denodo, partners and client teams. Duties & Responsibilities  Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning. Constantly learn new things and maintain an overview of modern technologies. Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product. Capable of building and/or leading the development of custom deployments based and beyond client’s requirements. Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues. Train and engage clients in the product architecture, configuration, and use of the Denodo Platform. Promote knowledge and best practices while managing deliverables and client expectations. Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues. Provide technical consulting, training and support. Develop white papers, presentations, training materials or documentation on related topics ","RequirementsQualifications Required Skills  BS or higher degree in Computer Science. Solid understanding of SQL and good grasp of relational and analytical database management theory and practice. Knowledge in Java software development, especially in the database field. Good knowledge of JDBC, XML and Web Services APIs. Excellent verbal and written communication skills to be able to interact with technical and business counterparts. Active listener. Strong analytical and problem solving abilities. Lots of curiosity. You never stop learning new things. Creativity. We love to be surprised with innovative solutions. Willingness to travel around 50%. Be a team worker with positive attitude.  We Value  Experience working with Java frameworks. Experience working with GIT or other version control systems. Experience working with BigData and/or noSQL environments like Hadoop, mongoDB, ... Experience working with caching approaches and technologies such as JCS. Experience in Windows & Linux (and UNIX) operating systems in server environments. Business software implementation and integration projects (e.g. ETL/Data Warehouse architectures, CEP, BPM). Integration with packaged applications (e.g. relational databases, SAP, Siebel, Oracle Financials, Business Intelligence tools, …). Industry experience in supporting mission critical software components. Experience in attending customer meetings and writing technical documentation. Foreign language skills are a plus.  Additional Information Employment Practices  We are committed to equal employment opportunity. We respect, value and welcome diversity in our workforce. We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee. ",https://www.mycareersfuture.sg/job/data-engineer-sql-big-data-java-denodo-technologies-cfe51cc03bee7d249ecf83fde7a21e8d,,Government support available
73,Data Engineer  /  Analyst,MANAGEMENT RESOURCES CONSULTANTS (S) PTE. LTD.,Full Time,Fresh/entry level,Information Technology,"$2,500to$4,000",Monthly," Work on the continued improvement and maintenance of internal ML and analytics products. Take part in predictive analytics consulting projects for HR. Collect, extract and consolidate data across multiple online and offline sources and perform data wrangling. Contribute to the development of new features and products.  Interested applicants to send CV to apply@mrc-asia.com, indicating your qualification, skills set, experience, current and expected remuneration.","RequirementsMinimum Qualifications  Bachelor’s degree in a quantitative discipline (Computer Science, Engineering, Statistics, Mathematics, etc.) Competent in using statistical programming languages (Python, R) with associated machine learning packages (scikit-learn, caret) to manipulate data and draw insights from large data sets. Strong in Excel and data visualization tools such as Power BI or Tableau. Working knowledge of SQL / NoSQL databases. Working knowledge of web scraping. Fluent in English and Chinese (Mandarin) preferred, as work involves China clients. Willingness to travel on projects.                 Preferred Qualifications  Experience in deploying machine-learning applications into a production environment. Knowledge of advanced web scraping. Experience with data management and pipeline tools. ",https://www.mycareersfuture.sg/job/data-engineer-analyst-management-resources-consultants-52f56c53858a129fbb4f2f91eca0d5fb,Central,
74,Data Engineer,BEATHCHAPMAN (PTE. LTD.),Permanent,Manager,Information Technology,"$120,000to$140,000",Annually,•   Leading online travel company that provides a wide range of travel needs in one platform •   Mobile app that has been downloaded more than 30 million times •   Most popular travel app In the South East region,"RequirementsOn behalf of our client, BeathChapman is assisting in identifying a skilled Data Engineer that has been working with quite a significant amount of data (hundreds of TB or perhaps petabytes), as well as an individual that knows how to cope with the complexity of dealing with plenty of business requests, with multitude priorities. Job Responsibilities:  You will be designing, building, supporting and scaling our data infrastructure. Monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data. Designing and building tools for maintaining deployment flows to make deployment experience is seamless.  Explore/learn new technologies that can complement or replace our current stack to improve it.  Requirements   Comfortable with writing efficient code in either Python/Java/Scala Past experience in building and running data processing systems (batch or even better in streaming) Genuine interest in big data, software engineering, and how the data can shape the business in the overall Familiar with the concept and implementation of dimensional modelling.  Uphold best practices and principles around clean code, testing, continuous integration Strong team player and collaborator, having strong initiatives, and driving the team. Having a high level of responsibility and resilience in dealing with issues Experience in productionize and maintaining data pipeline.  Familiar with big data infrastructure (such as Kafka, Hadoop, Spark, etc.), databases, and data security, preferably within the cloud environment. Preferable to have experience in integrating 3rds party data such as segment, google analytics, mixpanel, salesforce, facebook, or others.  Background in the travel industry, e-commerce, finance, and financial technology is a strong point that will be considered.   Interested candidates can forward their CVs in MS Word format to hareesh@ethosbc.com quoting reference number HB/AFVP-404356/IA   Reg No. R1441909 BeathChapman Pte Ltd Licence no. 16S8112",https://www.mycareersfuture.sg/job/data-engineer-beathchapman-48ba55728c7399c07af29eaace29967d,,
75,Data Engineer,MICROSEC PTE. LTD.,"Permanent, Full Time",Middle Management,Telecommunications,"$4,000to$6,000",Monthly,"Responsibilities: 1. Developing, enhancing, automating, and managing analytics models for anomaly detection. 2. Run those models into production environment with static as well as distributed databases. 3. Exploring and evaluating new digital tools and techniques to improve the product’s operational capabilities 4. Provide engineering support of key testing activities, including support of laboratory and field testing activities Outcome: The candidate will get to work on the state of the art intrusion attacks and how to prevent them. As a startup company, the candidate will get to work on wide domain of technologies which will increase the breadth of the experience of the candidate. This will provide an insight information about the industry trend and will groom the candidate for future prospects.","RequirementsRequirements: At least 2 year of experience in Python, Unix/Linux with machine learning tools including Tensorflow, LSTM and other models. Should have designed and built at least one system from ground up and made it into an application. Should also have experience in building APIs and using it for application integration along with Visualization tools using Python based production environment.",https://www.mycareersfuture.sg/job/data-engineer-microsec-50dd1dea87aa31217d0c39215ca26079,,Government support available
76,Senior Database Consultant - Big Data Engineer,PALO IT SINGAPORE PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$6,000to$12,000",Monthly,"Your profile & role on the project YOU:  Thrive on challenge. When was the last time you failed? Are curious & always learning. What are you up to right now? Can deal with constant change. When were you last surprised? Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?  YOU AGAIN: The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure and apply DevOps practices and solutions. The person will also implement cloud-related and DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond to consultant requests when required will be expected.  Install, maintain, and support on-premises and off-premises cloud stack. Configure, maintain, and support the cloud-related infrastructures. Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud. Ability to develop solutions and self-learn new tools and technologies. Document, and share knowledge on developed DevOps solutions.  STILL YOU:  Unix / Linux / Bash knowledge Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.) Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.) 2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.) 1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner) 1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.) 1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.) 1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk) Experience with developing and implementing processes to handle releases from Development to Operations while respecting internal rules, and offering solutions for rollback) Experience with designing an architecture to implement development-to-production workflows. Knowledge of SRE, Containers, Kubernetes, Openshift is a plus. Good understanding of microservice architecture and DevOps practices that support. Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.  Your role at PALO IT You will be invited to take part in R&D works done within our Practices. You will have the chance to assist or be a speaker at must-attend international IT conferences. You will have the opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT, you will present our offers and take an active role in the development of the company.  Your technical environment # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud) # DevOps practices # Linux OS, Shell Scripting, SQL # Agile and scrum environment","Requirements✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science ✔     You are just graduated or have less than 3 years of working experience ✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing ✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR) ✔     Experience with batch & ETL jobs to ingest and process data from multiple data sources ✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch) ✔     Experience with querying tools (e.g Hive, Spark SQL, Impala) ✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming ✔     You are passionate about technology and continuous learning comes naturally to you  ",https://www.mycareersfuture.sg/job/senior-database-consultant-big-data-engineer-palo-singapore-3457c8d2b5a325c08dd1464799c45875,Central,Government support available
77,Senior Database Consultant - Big Data Engineer,PALO IT SINGAPORE PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$6,000to$12,000",Monthly,"Your profile & role on the project YOU:  Thrive on challenge. When was the last time you failed? Are curious & always learning. What are you up to right now? Can deal with constant change. When were you last surprised? Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?  YOU AGAIN: The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure and apply DevOps practices and solutions. The person will also implement cloud-related and DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond to consultant requests when required will be expected.  Install, maintain, and support on-premises and off-premises cloud stack. Configure, maintain, and support the cloud-related infrastructures. Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud. Ability to develop solutions and self-learn new tools and technologies. Document, and share knowledge on developed DevOps solutions.  STILL YOU:  Unix / Linux / Bash knowledge Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.) Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.) 2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.) 1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner) 1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.) 1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.) 1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk) Experience with developing and implementing processes to handle releases from Development to Operations while respecting internal rules, and offering solutions for rollback) Experience with designing an architecture to implement development-to-production workflows. Knowledge of SRE, Containers, Kubernetes, Openshift is a plus. Good understanding of microservice architecture and DevOps practices that support. Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.  Your role at PALO IT You will be invited to take part in R&D works done within our Practices. You will have the chance to assist or be a speaker at must-attend international IT conferences. You will have the opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT, you will present our offers and take an active role in the development of the company.  Your technical environment # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud) # DevOps practices # Linux OS, Shell Scripting, SQL # Agile and scrum environment","Requirements✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science ✔     You are just graduated or have less than 3 years of working experience ✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing ✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR) ✔     Experience with batch & ETL jobs to ingest and process data from multiple data sources ✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch) ✔     Experience with querying tools (e.g Hive, Spark SQL, Impala) ✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming ✔     You are passionate about technology and continuous learning comes naturally to you  ",https://www.mycareersfuture.sg/job/senior-database-consultant-big-data-engineer-palo-singapore-705c8891b878db36611d27e4aaae5c2e,Central,Government support available
78,Senior Database Consultant - Big Data Engineer,PALO IT SINGAPORE PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$6,000to$12,000",Monthly,"Your profile & role on the project YOU:  Thrive on challenge. When was the last time you failed? Are curious & always learning. What are you up to right now? Can deal with constant change. When were you last surprised? Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?  YOU AGAIN: The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure and apply DevOps practices and solutions. The person will also implement cloud-related and DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond to consultant requests when required will be expected.  Install, maintain, and support on-premises and off-premises cloud stack. Configure, maintain, and support the cloud-related infrastructures. Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud. Ability to develop solutions and self-learn new tools and technologies. Document, and share knowledge on developed DevOps solutions.  STILL YOU:  Unix / Linux / Bash knowledge Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.) Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.) 2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.) 1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner) 1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.) 1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.) 1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk) Experience with developing and implementing processes to handle releases from Development to Operations while respecting internal rules, and offering solutions for rollback) Experience with designing an architecture to implement development-to-production workflows. Knowledge of SRE, Containers, Kubernetes, Openshift is a plus. Good understanding of microservice architecture and DevOps practices that support. Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.  Your role at PALO IT You will be invited to take part in R&D works done within our Practices. You will have the chance to assist or be a speaker at must-attend international IT conferences. You will have the opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT, you will present our offers and take an active role in the development of the company.  Your technical environment # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud) # DevOps practices # Linux OS, Shell Scripting, SQL # Agile and scrum environment","Requirements✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science ✔     You are just graduated or have less than 3 years of working experience ✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing ✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR) ✔     Experience with batch & ETL jobs to ingest and process data from multiple data sources ✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch) ✔     Experience with querying tools (e.g Hive, Spark SQL, Impala) ✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming ✔     You are passionate about technology and continuous learning comes naturally to you  ",https://www.mycareersfuture.sg/job/senior-database-consultant-big-data-engineer-palo-singapore-a5c4c29bbf0aee683038d5e538eb60e5,Central,Government support available
79,Data Engineer,A-IT SOFTWARE SERVICES PTE LTD,Contract,Executive,Information Technology,"$4,500to$6,500",Monthly," Support migration of existing SSB ATM Forecasting model currently on SAS to Python Review existing SSB ATM Forecasting model running in Python & enhance if required Be able to understand SAS Scripts & convert them to Python Provide useful insights & support to SSB Ops by developing reports using Python as required Provide assistance to Technical Business Analyst / Risk & Control requirement by preparing SOP documentation for existing Python Codes – which includes (and is not limited to the following) : debugging and enhancement as required by Business / Tech team. Work closely with system owners and technical leads for writing, reviewing Business Requirement document, reviewing Functional Specification, producing and executing UAT test plan for Project-related tasks Manage ad-hoc analysis such as statistical and predictive modelling to solve / respond to business questions Additional scope may be included depending on business needs ","Requirements Degree holder in Engineering / Statistics with at least 3 years relevant experience Advanced skills in MS Office Products (VBA and Macros skills) and must possess both analytics language of SAS and Python A good team player who can work well with product specialist, systems specialist, technical teams and external vendors Proficient in SQL and query optimization on Teradata and Hadoop Platform Prior experience in data science work preferred Excellent inter-personal and communication skills in dealing with all levels of staff and external parties Demonstrate Critical Thinking, ability to suggest improvements and identify risks A highly organized individual with ability to work under pressure with accuracy and commitment Self-starter, independent and able to rise to challenges and meet deadlines effectively ",https://www.mycareersfuture.sg/job/data-engineer-a-it-software-services-76382b0d5d6bf2b6739bf4b3b3b81bbf,East,Government support available
80,Senior Systems Engineer – Data Architecture,RESMED ASIA PTE. LTD.,"Permanent, Full Time","Professional, Senior Executive","Engineering, Sciences / Laboratory / R&D","$8,000to$10,000",Monthly,"Senior Systems Engineer - Data Architecture At ResMed (NYSE: RMD, ASX: RMD) we pioneer innovative solutions that treat and keep people out of the hospital, empowering them to live healthier, higher-quality lives. Our cloud-connected medical devices transform care for people with sleep apnea, COPD and other chronic diseases. Our comprehensive out-of-hospital software platforms support the professionals and caregivers who help people stay healthy in the home or care setting of their choice. By enabling better care, we improve quality of life, reduce the impact of chronic disease and lower costs for consumers and healthcare systems in more than 120 countries. To learn more, visit ResMed.com and follow @ResMed. The Sleep team is helping to fuel ResMed’s growth by focusing on solutions (products + software + services) to improve the quality of life for patients with sleep-disordered breathing and help providers improve efficiencies and reduce their costs. We are pioneers in providing a better experience for patients on therapy, and helping them achieve and maintain adherence with innovative masks and sleep devices with cloud connectivity. With nearly a billion people estimated to be suffering from obstructive sleep apnea, this is an opportunity to make a difference and change people’s lives whether in Marketing, Sales, or product development. Let's talk about Responsibilities: As a Senior Systems Engineer for the Data Architecture team, you will be working closely with a range of stakeholders to ensure ResMed’s Respiratory Care devices are built with a sound data architecture strategy that will provide value add to the patient via the device directly and via connected digital platforms consuming data collected by the device. This will be achieved more specifically by:  Defining a product’s data architecture specification to provide desired data related functionality, including functionality required to enable remote data capabilities. Desired data related functionality, including remote data capabilities are defined in collaboration with the Marketing team. Collaborating with Marketing and Clinical teams to define the desired data related functionality relating to value offerings facilitated through data collected by, and through, the device. Working with the Regulatory team to ensure conformance to the appropriate Regulatory Standards per applicable region. Defining, delivering and maintaining data architecture specifications, working in close collaboration with the Systems Engineer to ensure astute integration of therapy related functionality and data related functionality. Working with other engineering teams both within Respiratory Care and external to Respiratory Care to coordinate on the delivery of all products and systems in the integrated care offering as well as working with the V&V team to ensure adequate end to end system test coverage. Working with the Systems Engineer to ensure data related risks are captured and appropriately analysed within the System Risk Analysis. Coordinating the appropriate management of Cybersecurity risks, throughout the project lifecycle, including completion of the Cybersecurity risk analysis. Identifying and evaluating technical design alternatives to achieve desired functionality with appropriate consideration from all identified stakeholders. Resolving data related technical issues with the engineering disciplines and reviewing issues with the XFT where required. Representing engineering disciplines at the XFT for data architecture matters. Ensuring full traceability of data architecture related requirements, working closely with the Systems Engineer. Ensuring product achieves performance, functionality and reliability for data related features as specified in the MRD (and CRD where appropriate), working closely with the Systems Engineer. Ensuring that ResMed Systems Engineering processes are adhered to and recommend updates to processes where appropriate. Supporting Manufacturing for initial and ongoing production needs. Supporting Sustaining engineering for released products. Collating technical material to support regulatory submissions. Observing the principles of Occupational Health & Safety Legislation. Producing plans for delivery of Data Architecture deliverables, as required. Assisting with the development of user guides and other documentation delivered with the product.  In a Senior role you will also be expected to:  Mentor and identify the need to mentor other staff as required. Solve complex engineering problems more autonomously. Communicate complex engineering problems at various technical levels, tailoring the communications appropriately. Provide technical leadership on Data Architecture matters both within your team and externally, including work with other departments to drive consistency on data architecture design across the ResMed business. Leading innovation within your team through identification and implementation of improvements in engineering and business practices. ","RequirementsLet’s talk Qualifications and Experience:         Bachelor of Engineering in Electrical, Mechanical, Computer Systems or Mechatronics OR Bachelor of Science (in Biophysics for example) A postgraduate qualification in Biomedical Engineering would be an advantage. Experience in cloud computing, data interfaces and medical device product development, preferably in complete development cycle. Experience in cybersecurity management.  Okay, so what’s next? Joining ResMed is more than saying “yes” to making the world a healthier place. It’s discovering a career that’s challenging, supportive and inspiring. Where a culture driven by excellence helps you not only meet your goals, but also create new ones. We focus on creating a diverse and inclusive culture, encouraging individual expression in the workplace and thrive on the innovative ideas this generates. Our hope is that each day you’ll uncover a new reason to love what you do. If this sounds like the workplace for you, apply now!",https://www.mycareersfuture.sg/job/senior-systems-engineer-%E2%80%93-data-architecture-resmed-asia-44a62f0e76666e5052f8af4ee1deb3c0,South,Government support available
81,Data Sciences & Analytics Engineer (Data Engineering Track),SINGAPORE AIRLINES LIMITED,Permanent,"Professional, Executive",Information Technology,"$4,000to$8,000",Monthly,"We have multiple junior and senior data engineering positions available. The data engineer is responsible for designing and developing robust, scalable solutions for collecting and analysing large data sets in the cloud and on-premises data centres. Also in creating and maintaining data pipelines, data marts and business intelligence dashboards to be used across Singapore Airlines. Responsibilities:  Understand business processes, applications and how data is stored and gathered.  Develop and manage streaming data pipelines at enterprise scale.  Build expertise on the data. Own data quality for various data flows.  Design, build and manage data marts to satisfy our growing data needs.  Support data marts to provide intuitive analytics for internal customers.  Design and build new framework and automation tools to enable teams to consume and understand data faster.  Use your expert coding skills across a number of languages like SQL, Python and Java to support data scientists.  Interface with internal customers to understand data needs.  Collaborate with multiple teams and own the solution end-to-end.  Maintain infrastructure for our data pipelines.  Any other ad-hoc duties.  This is a sole contributor role.  ","Requirements BS degree in Computer Science or a related technical field. MS or PhD degree is a plus.  More than 2 years of advanced Python or Java development is necessary. Scala or Kotlin experience is a plus.  More than 2 years of SQL (such as PostgreSQL, Oracle, AWS Redshift, or Hive) experience is required. NoSQL experience is a plus.  More than 2 years working with Linux OS. Knowledge of networks and cybersecurity is a plus.  Experience with modern MapReduce/workflow distributed systems, especially Apache Spark. Experience with Apache Kafka is a plus.  Experience working with infrastructure-as-code systems like AWS CloudFormation. DevOps experience is a plus.  Experience in custom ETL pipeline design, implementation and maintenance.  Experience working with visualization tools like Tableau or Apache Superset.  Ability in analyzing data to identify deliverables, gaps and inconsistencies.  Ability in managing and communicating data mart plans to internal customers. ",https://www.mycareersfuture.sg/job/data-sciences-analytics-engineer-singapore-airlines-1617e1bd1b81746a8a0d110d423d47cb,East,
82,Assistant /  Engineer – Data Generation,VALID ASIA PRIVATE LIMITED,Permanent,Professional,"Engineering, Information Technology","$2,300to$3,400",Monthly,"Responsible for all data generation process for Telco (SIM)  Proper, accurate and timely documentation and update of records for data generation. Security & Quality for data generation processes and data generation room. Ensure Quality production at Subcontractors’ site.  Detailed outline of position: 1. Data Generation operation  Perform data generation tasks and steps for commercial order according to procedures and as per instruction. Maintain proper records and documentation for data generation processes. Ensure data integrity and correctness of data generated. To check and counter check the production data and customer data are correct and 100% compliance to the written specification before distribution.    2. Order transfer to production sites  To collect all required data into a package and transfer to the production sites. To compile the transfer documentation and cross check the data to be transferred. To prepare PJR (Production Job Request) and ensure VALID quality processes is followed by the subcontractors To check initial production log from the production sites, ensuring the job is setup correctly.    3. Sending Output files to the customer  To generate the output file according to customers’ specification. Check and counter check the quality of the data. To send the output files to the customer timely.    4. General  Ensure strictest confidentiality, integrity and safety of customer input data/files and output/response data/files. Adhere to all security procedures defined. Ensure that all security procedures and guidelines are followed for data generation and also production. ","Requirements Minimum Poly Diploma in IT or Engineering 1 year (Assistant)/ 3 years working experience in IT related field. Good working knowledge on Windows 7/8/10, MS Office suite. Candidates with programming background will have added advantage. ",https://www.mycareersfuture.sg/job/assistant-engineer-%E2%80%93-data-generation-valid-asia-6c52e1c2b0aab756d92c86b4ea8771c6,Central,
83,Data Science Engineer,ALLIANZ SE,Permanent,Executive,Others,"$5,000to$10,000",Monthly,"Allianz’s Data Science team is responsible for ensuring the company is well equipped with the skills and technology needed to build the next data-driven business model for insurance. The team runs multiple environment using continuous integration and deployment practice. We work side-by-side with the business to define the technical requirements and with the data scientists to implement scalable, production-ready API and infrastructure using best practices. We are seeking a customer-focused, passionate and driven Data Science Engineer with experience in developing Python-based API and cloud-based infrastructure. ●     Mastery of Python, or similar language. ●     Experience with Relational databases or NoSQL databases. ●     Proven understanding of the full software development lifecycle including testing, continuous integration, and deployment. ●     Excellent problem solving, critical thinking, and communication skills. ●     Solid grasp of computer science fundamentals including data structures and algorithms. ●     Understanding of machine learning techniques. ●     Proven ability to evaluate and apply new technologies in a short time. ●     Self-motivated, proactive, and solution-oriented. ●     Experience with cloud platform services desired. Description With the large volume of data which we will be leveraging, our job is to build and maintain proper data processing solution to bring reliable experiences for our customers. If you’re interested in being a part of a team that’s constantly learning and problem-solving, we’d love to talk with you. As a Data Science Engineer, you will work as part of the data science team in Allianz to lead the design and implementation of systems and tools to bring to life data products. You will be: ●     Developing and implementing production backend system to serve data products ●     Designing system and data architecture ●     Working with partners to integrate systems ●     Problem-solving and developing solutions at the intersection of data and systems ●     Innovating by recognizing opportunities for automation and tools improvements","RequirementsEducation & Experience BS or MS degree in computer science or equivalent field. Additional Requirements ●     Experience in building data science or data analysis tools a plus. ●     Machine learning background a plus. ●     Familiarity with Agile software development process, Test-Driven development and Continuous Integration a plus. ●     Familiarity with DevOps tools such as Ansible and Terraform a plus.",https://www.mycareersfuture.sg/job/data-science-engineer-allianz-se-01aac3fc60fdd18c440e224d1bb06f97,Central,
84,"Research Engineer (Data Analytics), I2R (A*STAR)",A*STAR RESEARCH ENTITIES,"Contract, Full Time",Professional,Sciences / Laboratory / R&D,"$2,500to$5,000",Monthly,"About Institute for Infocomm Research (I²R)  The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualisation solutions. For more information about I²R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs.      ","Requirements Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Possess minimum 1 year of relevant work experience Ability to work independently to translate research ideas into programs with efficient coding Basic knowledge on data analytics, machine learning, data mining Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified",https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-f80f14cbd71ab564fadb18c7cf006d1e,South,
85,Data Science Engineer,DATAROBOT SINGAPORE PTE. LTD.,Permanent,Professional,Information Technology,"$90,000to$150,000",Annually,"As a Data Science Engineer in DataRobot, you will work on our machine learning platform and actively contribute to the automation of data science best practices and the development of our state-of-the-art preprocessing, modeling and reporting capabilities. As a Data Science Engineer on our team, you will accelerate the process of engineering features to get the most out of multiple data sources and data types. The people you will work with own the entire feature learning experience for DataRobot, and is responsible for making sure our feature discovery automation and resulting models are the best in the world. You will build out Data Management and ETL system inside DataRobot utilizing distributed frameworks such as Spark, Hadoop and Kubernetes. You will build scalable solutions to process high data volumes, with the main focus on crafting robust components for data intake, cleanup and full variety of data transformation. You will also be responsible for designing and implementing features from start to finish, including clean and easy to use APIs, automated tests, and deployment infrastructure.",Requirements 5+ years of combined python Engineering / Data Science experience     Minimum 1 year of Engineering experience Minimum 1 year of Data Science experience   ,https://www.mycareersfuture.sg/job/data-science-engineer-datarobot-singapore-51a02f9c2b6cd9a12c4d34b71a9560ef,Central,Government support available
86,Data Center Operations Engineer,EIRE SYSTEMS SINGAPORE PTE. LTD.,Full Time,Professional,Information Technology,"$3,000to$5,000",Monthly,"Project Duration: 6 months The successful candidate will manage all aspects of the day to day Data Centre operations within the APAC region as part of the Technology Data Centre team, working closely with regional and global technology teams to ensure the effective delivery of projects and BAUs to the Asia Pacific lines of business. You will be primarily responsible for the delivery of operations and support services for the Data Centre to global standards, plus documentation and troubleshooting. Operational responsibilities spans multiple data centres regionally and globally. Responsibilities also extend to assessing current Data Centre and server room infrastructure and you will be expected and encouraged to make recommendations for management, process, service and operational improvements.  Installation, maintenance, decommission and disposal of all hardware equipment required in the data centre. Ensuring all documentation is kept up to date in a timely manner and all relevant parties informed of changes. Proactive identification of opportunities for service improvement, reliability and resiliency of data centre operations. Assist in planning and deployment of operational requirements such as rack space, patching and power in Data Centres and APAC regional server rooms. Act as the daily operational interface for all out-sourced data centre service providers. Rotating on call / overtime as required by the business and direct manager. Provide a weekday shift cover of 9:30am-5:30pm with overtime and weekend work as required. Monitoring and corrective action for all reported and observed events to completion.            Actively monitor and respond to service requests via Remedy and email. Stock, equipment management and tracking, replenishment and ordering. Familiar with hardware disposal environmentally and NIST media destruction standards Configure iLO, iDRAC and CIMC out of band management Familiar with various UTP and Fiber cabling standards and troubleshooting Basic Knowledge in TCP/IP, IP Addressing, Subnets and VLAN Assist in DR exercises which include planned and ad hoc out of hours work. Ensuring security, audit and safety procedures are followed at all times. Ownership of data centre and server room related tasks, driving to completion and resolution ","RequirementsEssential:  Strong data centre experience & BAU operational skills IT server/storage hardware and data/voice network communications experience (racking/break fix/patching/connectivity) in HPE Server, CISCO UCS Server, DELL EMC Server, DELL EMC/NetApp/PURE/TINTRI STORAGE and CISCO Switches and Routers Proven understanding of IT technologies and the associated industry Good understanding of  IT service delivery within an ITIL methodology, Remedy and ServiceNow ticketing Experience with DC critical engineering services, UPS, CRAC, fire suppression, electrical distribution, etc.    Desirable:  Educated to a suitable, relevant and appropriate level to fulfil and exceed the requirements for this role Certification ITIL V3 best practices Data Centre operations qualifications (CDCP/CDCS/CDCE/CDCDP) Vendor hardware training (HPE/CISCO UCS/DELL EMC/CISCO Networks) ",https://www.mycareersfuture.sg/job/data-center-operations-engineer-eire-systems-singapore-77b6d4fb9b3e5a104368debc02a827e7,Central,Government support available
87,System Engineer (Data and Control Communication Management),GOVERNMENT TECHNOLOGY AGENCY,Full Time,Middle Management,"Information Technology, Public / Civil Service","$5,000to$9,000",Monthly,"We are looking for a candidate to be responsible for the development of the data and control management software for the smart estate digital platform. This role will require candidates to perform end-to-end development from retrieval of sensor/systems data to sending data to the platform to storing of data. What to Expect:    Design and develop software architecture, prototypes and test systems.      Translate system diagrams/architectures into working prototypes   Define and develop backend architecture, data structures and data schemas for inflow and outflow of data to and fro central processing engine.    Design infrastructure solutions balancing requirements, operational constraints and architecture guidelines.   Implementation of infrastructures including network connectivity, virtual machines and monitoring   Integrate software with hardware and mechanics. Support and maintain all software library and hardware databases through proper documentations.   Develop robust Application Programming Interface (API) libraries to interface the central processing engine with other internal and external systems.   Conduct network / software load and performance tests.   Develop and execute validation plans    Develop and publish tender specifications in technical evaluation and tender award.   Develop, support and maintain the Devops tools for deployment, monitoring and operations.   How to Succeed:   Bachelor's Degree in Engineering (or equivalent. EE, CE and ME are preferred.)   >2 years of experience in data communications, middleware systems and embedded systems.  Fresh grads with interest or relevant experience are welcome to apply.   Good Programming Skills in C/C++ and JAVA. Additional knowledge in Python and JavaScript is advantageous.   Good understanding networking middleware (such as MQTT, DDS and BACNET) is an asset.   Good experience in working with development and orchestration technologies (Docker, Kubernetes, Ansible)   Experience in software development for embedded systems   Experience in database management (Hadoop, HBase, MongoDB)   Ability to work with multiple operating systems (Unix - RHEL, Windows Server)   Strong ability to obtain requirements and translate them into specifications.   Ability to multi-task and work as a team in a fast-paced and complex work environment  ",,https://www.mycareersfuture.sg/job/system-engineer-government-technology-agency-50d7d4dd7cd8c2abfbb6367a244103c1,,
88,System Engineer (Data and Control Communication Management),GOVERNMENT TECHNOLOGY AGENCY,Permanent,Middle Management,"Information Technology, Public / Civil Service","$5,000to$7,000",Monthly,"We are looking for a candidate to be responsible for the development of the data and control management software for the smart estate digital platform. This role will require candidates to perform end-to-end development from retrieval of sensor/systems data to sending data to the platform to storing of data. What to Expect:   Design and develop software architecture, prototypes and test systems    Translate system diagrams/architectures into working prototypes Define and develop backend architecture, data structures and data schemas for inflow and outflow of data to and fro central processing engine  Design infrastructure solutions balancing requirements, operational constraints and architecture guidelines Implementation of infrastructures including network connectivity, virtual machines and monitoring Integrate software with hardware and mechanics; support and maintain all software library and hardware databases through proper documentations Develop robust Application Programming Interface (API) libraries to interface the central processing engine with other internal and external systems Conduct network/software load and performance tests Develop and execute validation plans  Develop and publish tender specifications in technical evaluation and tender award Develop, support and maintain the Devops tools for deployment, monitoring and operations  How to Succeed:   Bachelor's Degree in Engineering (or equivalent. EE, CE and ME are preferred) >2 years of experience in data communications, middleware systems and embedded systems.  Fresh grads with interest or relevant experience are welcome to apply Good Programming Skills in C/C++ and JAVA. Additional knowledge in Python and JavaScript is advantageous Good understanding networking middleware (such as MQTT, DDS and BACNET) is an asset. Good experience in working with development and orchestration technologies (Docker, Kubernetes, Ansible) Experience in software development for embedded systems Experience in database management (Hadoop, HBase, MongoDB) Ability to work with multiple operating systems (Unix - RHEL, Windows Server) Strong ability to obtain requirements and translate them into specifications Ability to multi-task and work as a team in a fast-paced and complex work environment ",,https://www.mycareersfuture.sg/job/system-engineer-government-technology-agency-c1de69bae22019caca6c53eec7d488ac,,
89,Lead Data Center Engineer,JOHNSON & JOHNSON PTE. LTD.,Permanent,Professional,"Engineering, Information Technology","$5,000to$10,000",Monthly,"The role of Lead Data Center Engineer is ownership, management and delivery of network infrastructure requests and projects throughout their lifecycle.  The scope covers all aspects of Voice and Data network technology within the Enterprise Data Centers for the supported region.  The role is responsible for understanding and addressing business requirements, building solutions which comply with J&J standards and coordinating in-house resources, capacity teams, outsourced teams and vendors to ensure cost-effective and on-time delivery of solutions that meet business partner’s requirements. The role will also be responsible for effective communication with business partners and stakeholders at all levels and across multiple geographies. When required, the role may become involved with operational support related to the delivered solution. This role is highly technical and will be responsible for the implementation of complex changes within the Enterprise Data Centers.   Approximate Percentage of Time - Tasks/Duties/Responsibilities  30% - 35% Conduct network solution requirements gathering and develop options and alternatives. Provide pre-project consulting to the business and recommend network solutions to solve business problems.  Work with other Global Network Services personnel to provide expertise regarding the Enterprise Data Center portion of solutions. Develop solutions compliant with J&J architectural standards and work with Global Engineering team to design non-standard solutions when required. 20% - 25% Build solutions and implementation plans utilizing the appropriate internal and external resources (Ordering & Quoting team; Change Management team; Implementation Planner Capacity team; vendor resources) and ensuring full involvement of business partners and communication to all stakeholders.  15% - 20% Ensure flawless execution of implementation plan in conjunction with vendors and resource teams. Co-ordinate service introduction, hypercare, documentation, operational handover and if necessary, provide support for operational issues. 15% - 20% Regional and global support for request management including coordination and supervision of regional and global teams/resources; representing region to develop global standards, processes and best practices for Networking; acting as an escalation point for specific projects.  0% - 20% Where required, hands-on implementation of complex changes in Enterprise Data Centers.    Other Duties:  Involvement in vendor selection and governance processes Approve purchase of equipment, services and supplies Backup and support roles and functions in the Network team to ensure delivery of consistent customer service ","RequirementsRequired Minimum Education:  Bachelor’s Degree or equivalent experience        Required Years of Related Experience:    5-7 Years Related Experience   Required Knowledge, Skills and Abilities:   Good technical knowledge and experience with converged infrastructure, switching / routing in a large and complex network, DHCP, DNS, IP (Schema, subnetting, summarization) IP management tools, network management applications, advanced WAN routing, WAN/LAN/Wireless LAN topologies, MPLS and other WAN technologies, unified Communication, IPT, traffic shaping / QoS, EIGRP/BGP, multimedia/VoIP solutions (SIP), firewalls, and contact center technology Strong knowledge of Routing and Switching systems; strong understanding of Routing Protocols (OSPF, EIGRP, and BGP) and Gateway Redundancy Protocols (HSRP, VRRP, and GLRP)  Strong knowledge of VoIP, Multicast, STP, VTP and Virtual LAN’s and Trunking (VLAN’s); Network Security (ACL’s, IPSec Tunnels), Firewalls (Security Appliances), Netflow, IPSLA, and VPN technologies Ability to configure/implement network changes in a data center environment Good experience translating business requirements into technical network solutions Proven experience in network and infrastructure planning and development Extensive experience managing technically complex telecommunication deployments and projects    Excellent written and oral communication skills Excellent interpersonal skills and ability to communicate effectively at all organizational levels Strong customer service focus Willingness to work some weekends and evenings to support implementations ",https://www.mycareersfuture.sg/job/lead-data-center-engineer-johnson-johnson-c0791839b727bc55b28d04045e79a617,Central,Government support available
90,Data  /  DevOps Engineer,BEATHCHAPMAN (PTE. LTD.),Permanent,Manager,Information Technology,"$12,000to$14,000",Monthly," Online Booking Service Data and DevOps combined South East Asian Outreach  On behalf of our client, BeathChapman is assisting in identifying a candidate with a strong knowledge and interest in Data and DevOps Engineering.  Job Responsibilities:  You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data Designing and building tools for maintaining deployment flows to make deployment experience is seamless Explore/learn new technologies that can complement or replace our current stack to improve it ","RequirementsRequirements  AWS Certified Solutions Architect/ Azure Solutions Architect will be an added advantage Passion in big data, software engineering, and systems Excellent analysis and reasoning of system behaviours Uphold best practices and principles around clean code, testing, continuous integration Strong team player and collaborator, having strong initiatives, and driving the team Having a high level of responsibility and resilience in dealing with issues Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure (AWS/GCP), varying databases, security concerns would be an advantage Familiar with Java/Scala/JVM. Python is added advantage Familiar with container orchestration (docker, kubernetes, etc) Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important Having systems operational experience is a bonus  Interested candidates can forward their CVs in MS Word format to jasmin@ethosbc.com quoting reference number JAS/ATSS-554257/FB. Reg No. 1874652 BeathChapman Pte Ltd Licence no. 16S8112 ank",https://www.mycareersfuture.sg/job/data-devops-engineer-beathchapman-925dfef18d48dc75b8924cf0f00b6fcc,Central,
91,Data Governance Engineer,GRABTAXI HOLDINGS PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$7,000to$12,000",Monthly,"  Work with teams across Grab to gain a solid understanding of the data landscape and to consistently be on top of new and changed datasets.   Lead the maintenance of  an up to date inventory list of all the data assets in Grab   Evaluates Grab data assets for quality, and value on a periodical basis   Manage the infrastructure and tools required to ensure that the data asset inventory and evaluations are up to date.   Participates in the setting up and management of Grab’s data sharing arrangements from an engineering standpoint to ensure that they are secure, equitable and compliant  ","Requirements  Experience working with data as an organization’s business asset   Strong working knowledge and experience handling complex data workflows spanning across multiple large datasets that will facilitate data partnerships.   Experience working with data management tools / data catalogues such as Alation, Apache Atlas and others.   Experience with network and information security.   Good experience in handling big data within a distributed system   Familiar with tools within Hadoop ecosystem, especially Presto and Spark   Good knowledge of SQL in distributed OLAP environments  ",https://www.mycareersfuture.sg/job/data-governance-engineer-grabtaxi-holdings-29258e32d96e2557eea2abfea7ab11b1,Central,Government support available
92,Software Engineer (Data Analysis),GARENA ONLINE PRIVATE LIMITED,"Permanent, Full Time",Professional,Information Technology,"$5,000to$9,000",Monthly," The candidate would be someone with experience in data analysis and data mining, with strong coding and algorithm skills as the foundation. This is a fast-paced position that requires a high degree of energy and focus without compromising quality. Write server-side code to collect and analyse data to meet business intelligence requirements. Design, implement, and optimize database for data analysis purpose. Data mining design and implementation. ","Requirements Bachelor degree or higher in Computer Science or related field In-depth understanding of data structures and algorithms Strong database (MySQL) design and optimization experience Familiar (with hands-on experience) with at least one server side scripting language such as Python Intermediate-level knowledge of Object Oriented programming Web system knowledge and experience Excellent working attitude, problem solving, critical thinking and communication skills ",https://www.mycareersfuture.sg/job/software-engineer-garena-online-492d00534fa4d27e065e7951407f4639,South,
93,"Customer Engineer, Data Analytics Specialist, Google Cloud - Singapore",GOOGLE ASIA PACIFIC PTE. LTD.,Full Time,Executive,"Information Technology, Sales / Retail ","$7,300to$14,600",Monthly,"Company overview: Google is not a conventional company, and we don’t intend to become one. True, we share attributes with the world’s most successful organizations – a focus on innovation and smart business practices comes to mind – but even as we continue to grow, we’re committed to retaining a small-company feel. At Google, we know that every employee has something important to say, and that every employee is integral to our success. We provide individually-tailored compensation packages that can be comprised of competitive salary, bonus, and equity components, along with the opportunity to earn further financial bonuses and rewards. Googlers thrive in small, focused teams and high-energy environments, believe in the ability of technology to change the world, and are as passionate about their lives as they are about their work. For more information, visit www.google.com/careers. The area: Google Cloud Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what’s next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. And our teams are dedicated to helping our customers — developers, small and large businesses, educational institutions and government agencies — see the benefits of our technology come to life. The role: Customer Engineer, Data Analytics Specialist, Google Cloud - Singapore When leading companies choose Google Cloud it's a huge win for spreading the power of cloud computing globally. Once educational institutions, government agencies, and other businesses sign on to use Google Cloud products, you come in to facilitate making their work more productive, mobile, and collaborative. You assist fellow sales Googlers by problem-solving key technical issues for our customers. You liaise with the product marketing management and engineering teams to stay on top of industry trends and devise enhancements to Google Cloud products. Additional Role Description: As a Customer Engineer, you'll work with technical Sales teams as a networking subject matter expert to differentiate Google Cloud to our customers. You will help prospective customers and partners understand the power of Google Cloud, explaining technical features, helping customers design architectures, and problem-solving. Responsibilities: - Support local sales teams in pursuit of key business opportunities, engaging customers to address aspects of the data lifecycle - As part of working with the Sales team, identify business and technical requirements, conduct full technical discovery and architect client solutions to meet gathered requirements - Take responsibility for leading technical projects, including such activities as technology advocacy, supporting bid responses, product and solution briefings, proof-of-concept work, and the coordination of supporting technical resources - Work hands-on with Google Cloud Platform products to demonstrate and prototype integrations in customer/partner environments. Travel as required around EMEA for meetings, technical reviews and onsite delivery activities - Prepare and deliver product messaging in an effort to highlight the Google Cloud Platform value proposition, using techniques that include whiteboard and slide presentations, product demonstrations, white papers and RFI response documents","RequirementsMinimum qualifications: - Bachelor's degree in Computer Science or a related technical field or equivalent practical experience. - Experience with traditional Analytic Warehouse solutions including Teradata, Netezza, Vertica, Oracle, SQL-Server and ""Big Data"" technologies. - Experience in implementing analytics systems architecture. - Experience working with new and emerging technologies, methodologies, and solutions in the technology space. Preferred qualifications: - Extensive technical sales experience or professional consulting experience in the fields of cloud computing, data, information lifecycle management and Big Data - Experience with developing data warehousing, data lakes, batch or real-time event processing and ETL workflows solutions (i.e. Informatica, Talend, Alooma, SAP, Data Services) which could include architecture design, implementing, tuning, schema design, and query optimization of scalable and distributed systems - Experience in writing code in a common development languages such as Java, Python, JavaScript, C++, Scala, R or Go - Understanding of DNS, TCP, Firewalls, Proxy Servers, Load Balancing, VPN and VPC and working knowledge of Linux.",https://www.mycareersfuture.sg/job/customer-engineer-data-analytics-specialist-google-cloud-singapore-google-asia-pacific-fa0cdf4a35cc43b7684c528929243c3e,South,Government support available
94,"Research Engineer (Data Analytics), I2R (A*STAR)",A*STAR RESEARCH ENTITIES,"Contract, Full Time",Professional,Sciences / Laboratory / R&D,"$2,500to$5,000",Monthly,"About Institute for Infocomm Research (I²R)  The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualisation solutions. For more information about I²R, please visit www.i2r.a-star.edu.sg We are looking for a data engineer who can contribute on text analytics-related projects. Job Responsibilities:  Deliver results: Develop technologies, improve performance Demonstrate long-term vision, while effectively supporting short-term goals     ","Requirements   Minimum Bachelor degree in computer science or other related areas Possess expertise in the areas of natural language processing, text mining, deep learning, machine learning, and/or cloud computing Being an excellent team player Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified",https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-f158ee29cb4064031400ff676016a6ac,South,
95,Data Center Support Engineer,HCL INSYS PTE. LTD.,Full Time,Professional,Information Technology,"$2,500to$3,100",Monthly,• Extensive knowledge garnered working as a Data Center Operator • Thorough knowledge of Data Center Operations with strong knowledge of Operations methodology. • Strong ability to examine Symantec Netbackup policy backups and perform first level troubleshoots on Windows and UNIX servers. • Good technical knowledge on Data Centre monitoring tools. • Possess an in-depth knowledge of data center infrastructure technology and components for installation. • Strong written and excellent communication skills.,"RequirementsMust have Talent / Skills:  2-3 Years of experience in Datacenter Operations. Must be able to work in 24*7 Environment  Backup operations, Media Management  Good to have Talent / Skills:  ITIL Process Knowledge ",https://www.mycareersfuture.sg/job/data-center-support-engineer-hcl-insys-2f2bb597d8e39596131b2d27ef05e0b2,Islandwide,
96,Data Visualisation Engineer (West),MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Permanent, Full Time","Executive, Junior Executive",Information Technology,"$4,000to$5,000",Monthly," Responsible for the data visualization and reporting capabilities of healthcare data & analytics provided by machine learning algorithms or data scientists. Consult the users with the understanding of business and data requirements, and iteratively design visualizations for initial concepts and prototypes. ","Requirements Bachelor or Master in Computer Science, Electronic Engineering, Statistics, Business, Finance, or other relevant disciplines. Minimum 3 years of relevant data visualisation experience, i.e. visualising complex data, designing data-rich user interfaces, data-driven design and development of charts, dashboards and infographics etc. Proven experience in visualisation toolbox such as D3.js, Shiny R, Seaborn etc; Or proven experience in business intelligence software such as Tableau, Microsoft Power BI etc. Familiar with statistics. Good team player. Good communication skills. ",https://www.mycareersfuture.sg/job/data-visualisation-engineer-manpower-staffing-services-04fdb88b4e4a51f8e591a4ae74d06c0b,West,Government support available
97,Data Analysis Engineer,RINGS.TV PTE. LTD.,"Permanent, Full Time",Professional,Engineering,"$4,500to$5,000",Monthly,"1. Establish a business analysis framework to provide quality data support for operational decisions and business strategies; 2. Data monitoring can quickly and accurately identify problems and communicate with business departments through in-depth analysis; 3. Establish data output, evaluation, application models for the business scenario, and continue to correct and optimize; 4. Handling business-related temporary data query requirements","Requirements1. Bachelor degree or above in mathematics, statistics, computer software, management information system, operations research, etc., 1-2 years of data analysis work experience; 2. Good business sensitivity and data analysis skills to apply innovative and practical analytical methods to solve complex business problems 3. Familiar with spark, hive, hadoop; 4. Familiar with statistic analysis software such as python, jupyter, excel, ppt, familiar with SQL, familiar with common algorithms for data mining; 5. Have strong logic, good communication expression and organizational coordination ability; 6. Excellent teamwork spirit, honesty, diligence and rigor;",https://www.mycareersfuture.sg/job/data-analysis-engineer-ringstv-3ef1b52e836e40521736889d1eabf41c,Islandwide,Government support available
98,Senior Data Center Engineer,PEOPLEBANK SINGAPORE PTE. LTD.,Permanent,Senior Executive,Information Technology,Salary undisclosed,,"Senior Data Center Engineer  Regional exposure Competitive benefits  Responsibilities  Contributing as a senior technical resource in a small team servicing equipment data centers throughout Asia Installing, configuring, troubleshooting, and managing the assets of technology hardware Working autonomously to resolve hardware, software, and service issues, and coordinating with remote teams to troubleshoot advanced problems Participating in project planning, architecture, and change management activities. Monitoring and reporting on project progress and update project documentation including rack elevations, port mappings, layout diagrams, inventory schedules, etc. Handling equipment orders, returns, shipments, and general inventory management. Working flexible hours when required including late nights and weekends (Individuals typically keep predictable daytime schedules during the work week, but are periodically required to participate in out-of-hours projects) Traveling regionally and abroad ","RequirementsRequired Qualifications  At least 10 years of related working experience in a data center environment Strong technical proficiency in servers and network including configuration, maintenance, and troubleshooting Strong understanding of systems and networking concepts including Linux (Red Hat preferred), circuits, IP routing, switching, consoles Strong working knowledge of cabling types, standards, & best practices Strong understanding of data center management and layout including power & cooling Good project management skills, with the ability to proactively drive changes or improvements to the data center environment, or contributing ideas to enhance current standards or fix issues Self-motivated, has a highly analytical mindset with attention to detail A degree or diploma in a technology-related study field, or significant previous data center experience in lieu of formal education  If you are interested in exploring the role, please share your profile to neha.sharma@peoplebank.asia Thanks Neha",https://www.mycareersfuture.sg/job/senior-data-center-engineer-peoplebank-singapore-c24131bb74d9e9b8748c66d9273cd956,Central,Government support available
99,Data Scientist /  Engineer,AXINAN PTE. LTD.,Permanent,Senior Executive,Engineering,"$4,000to$8,000",Monthly,"About the Job  Design and build data driven systems for risk control, fraud detection, recommendation, customer segmentation, adaptive pricing etc. Build, validate, test, and deploy models and algorithms. Work with backend engineers to architect data storage and processing pipelines. Work with product managers to develop new product features based on insights from data. ","RequirementsWhat You Should Have   Master or PhD in computer science, statistics, mathematics, or fields related to data mining preferred. Experience in Python or R. Knowledge in supervised/unsupervised learning, classification/clustering algorithms, feature engineering/optimization Experience in deep learning, reinforcement learning, personalized search and recommendation, user/seller behavior modeling, marketing algorithms preferred. Experience of Hadoop, Spark, Tensorflow is a plus. Experience with visualization software to convert models/insights into simple, business sell-in stories would be an advantage (but not mandatory). Outstanding analytical and problem- solving skills. Self-motivated, innovative, and proactive. Willing to learn new knowledge and explore unfamiliar domains.    Join us and get:  A chance to lead and grow quickly to transform a nascent InsurTech industry To contribute to the development of high-impact FinTech products that will serve millions of customers across asia To work, play and hustle with a creative, fun and diverse community (think Silicon Valley, Europe and Asia all-in-one!) ",https://www.mycareersfuture.sg/job/data-scientist-engineer-axinan-3e9fc8187093c588367d563d665fc5a6,Central,Government support available
100,"Software Engineer (Analytics, Big Data)",KNOREX PTE. LTD.,Full Time,Executive,Advertising / Media ,"$3,000to$4,500",Monthly,"DESCRIPTION We have an existing cloud-based, highly scalable, all-in-one advertising platform where Marketers, Media Owners and Agencies can easily create, optimize & publish Dynamic Ads world wide. Product website: https://xpo.knorex.com/ You will work closely with our cross-country teams located regionally to learn about the business and technical analytics requirements and translate them into production system. Owing to the large data and real-time stream of data, coming up with efficient and pragmatic solutions and algorithms to the challenging problems will be come imperative. You will work with other team members to ensure the timely delivery of the systems and solutions and critically assess and monitor the efficiency and/or effectiveness of the developed solution.  Key Responsibilities  Develop clever algorithms and pragmatic solutions to our data analytics problems. Develop metrics to measure the outcome/impact of your introduced solutions. Develop and maintain API to support other teams in retrieving the metrics Work with other members to implement and integrate into our existing systems. Document and improve the solutions over time. Evaluate and identify new technologies for implementation. Communicate with our business and technical teams to understand the analytics requirements. Respond and follow up to incorporate feedback and draw new insights. Prioritize tasks to meet multiple deadlines.     ","RequirementsREQUIREMENTS  Good knowledge of algorithms and data structures Experience with ad serving, ad tracking and optimization is a plus Strong in analytics and problem solving technique Willingness to learn and able to pick up new technology or new concepts fast; Able to work independently as well as in collaborative mode with minimum supervision; Work productively even under pressure; Possess good work ethic, attitude with good follow-through; Excellent communication in written and spoken English. Must be proficient in either Python, Scala, Spark or NodeJS Proficiency in multiple languages listed above is a plus  BENEFITS  Ample opportunities to grow. You get to propose your own ideas and see it through. Work with passionate, talented and driven colleagues who get things done! Opportunity to work cross-country and with variety of projects of different nature. Challenging and exciting problems that await you to solve. Comprehensive Health Insurance Coverage. W3F (Work, Wellbeing, Welfare) Fund for courses, materials, personal health and wellbeing ",https://www.mycareersfuture.sg/job/software-engineer-knorex-b9842b8d076c944d83d5cf7e0c25e553,Central,Government support available
101,Research Engineer (Data Analytics),AIRBUS SINGAPORE PRIVATE LIMITED,Permanent,"Executive, Senior Executive",Engineering,"$4,000to$7,000",Monthly," Perform data wrangling in SQL and Python on Airbus’ cloud data platform (Skywise) Use statistical methods to find correlations and build data models Build dashboards for visualizing and presenting business insights Design and develop web applications for real-time analytics projects Analyse the Cabin in-service issues (removals, delays, etc..) currently affecting our fleet and define priorities for predictive maintenance development Work with customers to assess needs and propose solutions Support technical documentation Develop link between Asia Pacific and Europe based teams. ","Requirements Bachelor’s degree in Engineering, Computing, Science Hands-on programming experience with Python/R, SQL Familiarity with developing data visualizations and dashboards using Python, Tableau/PowerBI  Experience in web development using HTML, CSS, JavaScript Analytical thinking, problem solving Familiarity with Agile development methodology is a plus Knowledge in Machine Learning, Natural Language Processing would be a plus Experience from airlines, MROs, or Aerospace OEM is appreciated. Able to learn fast and work independently Communication and negotiation skills Able to manage multiple tasks at the same time and motivated to take on new challenges Foster New and Agile ways of working with engineering stakeholders.    For interested applicants, you may submit your application by emailing a detailed copy of your updated resume to Joanne Han at joanne.han@airbus.com. For our easy reference, please indicated the position title as the email subject name    Airbus Singapore Private Limited, thanks all applicants for your interest, only selected applicants will be contacted",https://www.mycareersfuture.sg/job/research-engineer-airbus-singapore-f85e7d644a13eb3d5157af675d6bd576,North,Government support available
102,Principal  /  Master Data Science & Application Engineer,LITE-ON SINGAPORE PTE. LTD.,Permanent,Senior Executive,Sciences / Laboratory / R&D,"$8,200to$10,200",Monthly," Analysis the data which collected from production line of automotive electronics component. Develop the data visualize tool to tracking production status and process flow. Design prototype algorithms, create predictive models and proof of concepts. Optimize the parameter for automatic manufacturing and testing machine to improve the yield rate and UPH. ","Requirements Degree in Mathematics/Data Science/Software Engineering or related field. Experience in big data analysis technologies and tool. Experience in C# or C++ for write the demonstration program. Industry 4.0 application and production optimize experience is preferred. Good communication skill and capable of individually research. Co-working with oversea IT, RD and manufacturing team. ",https://www.mycareersfuture.sg/job/principal-master-data-science-application-engineer-lite-on-singapore-b2c84a16788154174cd256a364a8bcac,North,Government support available
103,Senior  /  Principal Data Science & Application Engineer,LITE-ON SINGAPORE PTE. LTD.,Permanent,Senior Executive,Sciences / Laboratory / R&D,"$5,200to$8,200",Monthly," Analysis the data which collected from production line of automotive electronics component. Develop the data visualize tool to tracking production status and process flow. Design prototype algorithms, create predictive models and proof of concepts. Optimize the parameter for automatic manufacturing and testing machine to improve the yield rate and UPH. ","Requirements Degree in Mathematics/Data Science/Software Engineering or related field. Experience in big data analysis technologies and tool. Experience in C# or C++ for write the demonstration program. Industry 4.0 application and production optimize experience is preferred. Good communication skill and capable of individually research. Co-working with oversea IT, RD and manufacturing team. ",https://www.mycareersfuture.sg/job/senior-principal-data-science-application-engineer-lite-on-singapore-b2ab363ce1ae85179d8f4c211049c4b1,North,Government support available
104,Junior  /  Senior Data Science & Application Engineer,LITE-ON SINGAPORE PTE. LTD.,Permanent,Junior Executive,Sciences / Laboratory / R&D,"$3,200to$5,200",Monthly," Analysis the data which collected from production line of automotive electronics component. Develop the data visualize tool to tracking production status and process flow. Design prototype algorithms, create predictive models and proof of concepts. Optimize the parameter for automatic manufacturing and testing machine to improve the yield rate and UPH. ","Requirements Degree in Mathematics/Data Science/Software Engineering or related field. Experience in big data analysis technologies and tool. Experience in C# or C++ for write the demonstration program. Industry 4.0 application and production optimize experience is preferred. Good communication skill and capable of individually research. Co-working with oversea IT, RD and manufacturing team. ",https://www.mycareersfuture.sg/job/junior-senior-data-science-application-engineer-lite-on-singapore-3407552ebb80d7d4c7ce944af3431428,North,Government support available
105,"AVP, Network Engineer (Data & Security), Chief Technology Organization",ALEXANDER MANN BPO SOLUTIONS (SINGAPORE) PTE. LTD.,"Permanent, Full Time",Professional,"Banking and Finance, Information Technology","$8,000to$16,000",Monthly,"About Bank of America Merrill Lynch:  Our purpose as a firm is to make financial lives better, through the power of every connection. Across the world, we partner with leading corporate and institutional investors through our offices in more than 40 countries. In the U.S alone, we serve almost all Fortune 500 companies and approximately 59 million consumers and small-business customers. We provide a full suite of financial products and services, from banking and investments to asset and risk management. We cover a broad range of asset classes, making us a global leader in corporate and investment banking, sales and trading.                              Connecting Asia Pacific to the World Our Asia Pacific team is spread across 23 offices in 12 markets. We are focused on connecting Asia to the world and the world to Asia, using our global expertise to ensure success is shared between us, our clients and our communities. Our regional footprint covers 12 currencies, more than a dozen languages and five time zones, placing us firmly among the region’s leading financial services companies. Bank of America Merrill Lynch is committed to attracting, recruiting and retaining top diverse talent from across the globe. Our diversity and inclusion mission is to actively promote an inclusive work environment where all employees have the opportunity to achieve personal success and contribute to the growth of our business. Each of our global Employee Networks bring together employees, create dialogue and awareness in support of our Diversity and Inclusion mission. Bank of America Merrill Lynch is an equal opportunities employer. Position Description Background: Network Operations Center (NOC) Engineer leads engagement and resolution of large events, which are incident or multiple incidents that are significant in scope and impact. They are senior engineers in Network Services technologies and provide leadership and strategic/tactical direction related to the successful resolution of a network incident. Provides technical leadership on incident bridges and demonstrates a wide knowledge of various Network and Client technologies that could be engaged to achieve event and incident resolution.  Actions include troubleshooting Network and Security incidents and escalations of suppliers and carriers. Works with other infrastructure teams including regional stakeholders, and suppliers to identify root cause of critical event issues and implement restoration activities. Key Responsibilities  Responsible for day to day operations of Global Network and Security Infrastructure Advanced Network Support for Events and Incidents across the BoA network Proactive monitoring of the BoA network and the creation/validation of health check and status updates Performing planned and break/fix changes for service restoration Actively drive incident calls and provide technical resolution at the earliest possible time to restore services Initiates and provides direction related to the successful resolution of a network incident along with any available workarounds Develop and/or maintain necessary incident management and communication reports Ensures stability of the post restoration environment in coordination with the LOB ( Line of Business) Post-incident root cause analysis and service improvement activities Follows documented Network Center standards and procedures Perform troubleshooting, configuration and maintenance of Network and security devices Willing to work on rotating shift including weekends ","RequirementsKey Requirements  A mix of ‘Data’ and ‘Security’ Products and strong hands on experience with majority of technologies as listed below: 	Technical  Highly developed Operational experience being able to troubleshoot complex network security and routing issues in a large multi-vendor environment. Able to configure and troubleshoot load-balancer technologies: F5 BigIP/LTM/GTM/APM, iRules and Avi Load balancer Advanced troubleshooting experience Bluecoat Proxy, Fire Eye, IDS/IPS technologies Cisco Routing/Switching – CCNP+ Level or equivalent experience Able to configure , maintain and troubleshoot Checkpoint, Juniper SRX and NS platforms using JUNOS / SCREENOS Able to troubleshoot DNS/DHCP infrastructure In-Depth Working Knowledge of Market Data delivery networks using both TCP and UDP multicast with an ability to comprehensively troubleshoot through these networks. Excellent understanding of common network technologies, including TCP/IP, IPSec, VRRP, HSRP, SNMP, NAT, Multicast, Sub-netting, Ethernet, Access-lists. In-Depth Working Knowledge and understanding of the following routing protocols: BGP, OSPF, EIGRP, ISIS, MPLS. Knowledge of network monitoring and administration tools (NNMi, AppViewX, SEVONE, HPNA, Splunk) Preferably has previous experience working within a large Financial Services environment Experience configuring and troubleshooting Cisco Wireless and ARUBA Products 	Soft Skills  Must be able to work effectively independently as well as in a team environment Ability to work in a fast-­paced, rapidly growing environment while balancing multiple, sometimes competing priorities successfully Proven ability to manage and set client expectations Ability to manage client escalations and negotiate resolution Firm understanding of IT Service Management processes Ability to make quick decisions and comfortable escalating to management when required Demonstrates excellent oral and written communication with the ability to clearly and effectively communicate at all organizational levels ",https://www.mycareersfuture.sg/job/avp-network-engineer-chief-technology-organization-merrill-lynch-global-services-1e3a39d249e852341ffff5245bf4105c,South,
106,Data Centre Engineer,IX TECHNOLOGY PTE. LTD.,Permanent,Executive,"Building and Construction, Engineering","$2,500to$3,000",Monthly, Responsible for day-to-day operation of data centre infrastructure Assist in facilitating vendor repairs for tickets and installation of servers Understand the requirements of 24x7 on-site support Responsible to enforce the facilities regulations and safety policies Ensure SLA standards are met for all tickets Provide a clean work environment by ensuring the facility is clean Executing daily walkthroughs of IT equipment and MEP equipment ,"Requirements Associates degree or above in a computer science or engineering discipline More than 2 years of overseas large-scale data centre on-site operating experience Familiar with data centre power, machinery, fire, control system Willingness to learn more about IT infrastructure areas such as server platforms, storage server platforms, server components, networking equipment, technologies and architectures, IT service delivery principles and best practices Self-motivated and self-management ability, with strong problem analysis and crisis thinking experience Familiar with the servers, network equipment, hardware installation, maintenance, troubleshooting processes and methods Excellent verbal and written communication ",https://www.mycareersfuture.sg/job/data-centre-engineer-ix-technology-123e87b75cba4327bc9872b338f97f30,Central,
107,Data ML Engineer,TOOKITAKI HOLDING PTE. LTD.,Permanent,Middle Management,Engineering,"$9,000to$15,000",Monthly,"About Tookitaki Tookitaki is providing machine learning-powered enterprise solutions to address regulatory compliance problems in the financial services sector. Incorporated in November 2014 in Singapore, the company is led by a core team with cumulative 30-years’ experience in finance, AI and big data analytics. Backed by institutional investors such as Jungle Ventures and Spring Seeds (a subsidiary of the Singapore Government), the company’s accolades include:  We are among the selected 21 companies which got accreditation from the government of Singapore for their stringent technology, finance and operations due diligence (www.imda.gov.sg/industry-development/programmes-and-grants/startups/accreditation-at-sgd) We won the first place in the MAS FinTech Awards (Singapore SME) in the regulatory compliance space from the Monetary Authority of Singapore for our approach to make the workflows in AML and Reconciliation scalable and highly auditable (beyond ML based black box approach) (www.mas.gov.sg/News-and-Publications/Media-Releases/2016/Ten-FinTech-companies-recognised-for-innovative-solutions-at-inaugural-FinTech-Awards.aspx) We are voted as one of the top 21 AI start-ups focusing on the financial services space by medici (www.letstalkpayments.com/medici-top-21-ai-companies/) We graduated from Nomura's corporate innovation program in November 2017 where we successfully delivered our product – Reconciliation Management Suite – in a pilot environment (https://inc42.com/buzz/nomura-voyager-fintech-accelerator-voyager-demo-day/)  In regulatory compliance, we focus on anti-money laundering and reconciliation and our products – Alerts Management Suite (AMS) and Reconciliation Management Suite (RMS) – cater to these areas, respectively. The mission or goal is to achieve 40% operational efficiency with significant savings in infrastructure and operational costs. Tookitaki's unique selling proposition (USP) is in our approach where we combine our proprietary modelling technique with our complete auditable framework to make the process dynamic and highly explainable (moving out of the black box approach). Moreover, our flexible on-premise and cloud-packaging capabilities, along with the option of easy integration to exiting core-banking applications (REST API end points), make the solution deployment faster with lesser barrier to entry. Today, regulatory compliance processes have become more complex and fluidic, increasing the chances for rule-based models to fail. Banks need to move beyond static rule-based systems and adopt a new approach to prevent financial and reputation loss. Tookitaki bridges the gap with its innovative software products – AMS, RMS and PMS.        ","RequirementsRole: ML Engineer Engineering @ Tookitaki The engineering team is responsible for building a robust predictive platform, which can add significant value to the BFSI vertical in solving operational and compliance risk problems. We take pride in building the system right and continuously evolving it. You have the freedom to choose right tools for the task. We also encourage to participate in and contribute to open source community.   Our Ideal Candidate  Our engineering team is looking for a lead machine learning engineer with a work experience of 4+ years. The candidate would be responsible for contributing to product development and would be considered a good fit if he/she:  Ships high quality code and believes in TDD Has deep experience with one of JVM languages such as Scala, Java and Python Has understanding of and working experience with Machine Learning and AI Has the ability to engineer low-latency systems from ground up Has deep understanding working with big data/data engineering components like HDFS, Yarn, Hive and Spark Has experience tuning the complex systems for performance optimizations - including application tuning, runtime tuning and infrastructure tuning Has deeper understanding of efficient memory management, GC tuning and application profiling Has experience defining the right tech stack and designing the overall architecture of the system Has experience working with one or more cloud providers, preferably AWS Enjoys digging into open-source project and contributing back Is well versed with tools of the trade - Git, IDEs, and build tools Has a keen desire to learn and grow Has experience working with one or more distributed NoSQL stores Has the ability to lead and mentor other members in the team  Educational/Professional Requirements   PhD or master’s in computer science or related quantitative discipline from a reputed institution Work experience of 4+ years  Desired Non-technical Requirements  Very strong communication skills both written and verbal Strong desire to work with start-ups Must be a team player  Job Perks  Attractive variable compensation package Flexible working hours - everything is results-oriented Opportunity to work with an award-winning organization in the hottest space in tech - artificial intelligence and advanced machine learning   ",https://www.mycareersfuture.sg/job/data-ml-engineer-tookitaki-holding-51cf42646bfa75afbe8ba0fe79d917b0,Central,Government support available
108,Technical Services Engineer (Technical Data Management),SINGAPORE AERO ENGINE SERVICES PRIVATE LIMITED,Full Time,Executive,Engineering,"$3,200to$4,500",Monthly,"Responsibilities  Review and approve Engine, Module and Component Repair worksheets in accordance with OEM approved technical data. Streamline and approve work sequences for efficient processing of components Ensure technical compliance with OEM approved documents. Work with various departments to ensure worksheets satisfactorily support Engine, Module and Component Repair operations. Maintaining a professional technical interface with OEM   ","RequirementsRequirements  Degree in Mechanical or Aerospace Engineering (Candidates possessing both Diploma certification and relevant experience will be considered). Good knowledge of component repair processes (eg. Welding, Machining, Thermal Spray, Paint, NDT, Cleaning) Basic knowledge of high bypass gas turbine engines and the engine assembly process. Experience in an engine overhaul shop is valued. Proficient in MS Excel and Word. Knowledge of SAP is an added advantage. Meticulous team player with good communication skills. ",https://www.mycareersfuture.sg/job/technical-services-engineer-singapore-aero-engine-services-8868c39ddf791676e01cf8066ab887fb,East,
109,Data Centre Engineer,ALFA TECH VESTASIA PTE. LTD.,Permanent,Executive,Information Technology,"$2,600to$4,600",Monthly," Identify hardware issues in data centres and work with vendors to resolve them Perform shipping and receiving as well as track/maintain inventory Perform cabling (copper, fibre, power cords) to DC standard Install and configure hardware in production and staging environments (Unix/Linux servers, Network and Storage equipment) Handle trouble tickets related to system maintenance and repair Work hand in hand with subject matter experts from other groups on projects Be instrumental in problem solving complex multi-discipline issues Manage site growth by keeping things organized Responsible for SLAs, HW repair escalations ","Requirements Well versed with Unix / Linux Nitec / Diploma in Information Technology, Computer Science or related disciplines Experience in sizeable Data Centre operations is an advantage ",https://www.mycareersfuture.sg/job/data-centre-engineer-alfa-tech-vestasia-424857a2a339ca7555a8371dbf9b24a8,West,Government support available
110,Big Data DevOps Engineer,EPAM SYSTEMS PTE. LTD.,Full Time,Professional,Information Technology,"$8,000to$13,000",Monthly,"Responsibilities:  Design, build and maintain highly available production systems; Integrate solutions with other applications and platforms outside the framework; Provide consulting services to application teams looking to build Cloud-based applications; Design and implement build, deployment, and configuration management systems; Analyze, organize, and provide in-depth code reviews to improve applications dynamically and ensure the timely completion of projects Perform script updates due to changes in requirements or implementations; Design, implement and improve monitoring and alerting system; Troubleshoot production issues and coordinate with the development team to streamline code deployment; Optimize system performance, availability and scalability; Assist in production support; Collaborate with team members to improve developed tools, systems and procedures, and data security; Brainstorm for new ideas and ways to improve development delivery; Create Procedures and Policies; Write the project documentation and conduct knowledge transfers. ","Requirements Bachelor’s degree in Computer Science or a related technical field, or equivalent work experience; 4 years of professional experience; 2 years hands-on experience with a variety of Amazon AWS services; Intermediate skill in one cloud platform: GCP, Azure; Solid Linux/Unix systems administration background; Advanced skill in configuring, managing and maintaining networks; Advanced skill in infrastructure troubleshooting, performance tuning, optimization and bottleneck problem analysis. 2 years of hands-on experience with Python; 2 years of hands-on experience in one scripting language: Bash, Perl, Groovy; Advanced skill in Hadoop HDFS and YARN; Advanced skill in one of Hadoop distributions(Cloudera, Hortonworks); Advanced skill in Hadoop managing tools(Ambari, Cloudera Manager); Advanced skill in HUE, Hive, Spark; Intermediate skill in Hadoop Security; Advanced skill in Kafka; Intermediate skill in ElasticSearch; Advanced skill in Kubernetes, Docker; Solid experience in managing production infrastructure with Terraform, AWS CloudFormation, etc.; Advanced skill in one configuration management tool: Chef, Puppet, Ansible or similar; Advanced skill in one build automation tool: Jenkins, TeamCity, Bamboo, GoCD, etc.; Good knowledge of Monitoring Best Practices; Advanced skill in one monitoring tool and dashboard: Zabbix, Nagios, DataDog, Prometheus, Grafana, etc.; Good knowledge of Security Best Practices; Advanced skill in one Authentication and Authorization protocols: LDAP, Kerberos, SAML, etc.; Good organizational, analytical and problem solving skills; Ability to present and communicate the architecture in a visual form; English language – ability to direct communicate with customer. B2 level is required. ",https://www.mycareersfuture.sg/job/big-data-devops-engineer-epam-systems-29bfe26a52f62af06e29442885cc4f31,South,Government support available
111,Big Data (HIVE) Engineer – 12 Months Renewable Contract,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,"Contract, Full Time",Junior Executive,Information Technology,"$6,000to$12,000",Monthly,"Responsible for the design, development and implementation. •              Work on development of new products iteratively by building quick POCs and converting ideas into real products. •              Design and develop mission-critical systems, delivering high-availability and performance. •              Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. •              Develop code and mentor junior developers to ensure deliverables are on time, within budget, and with good code quality. •              Have a passion for delivering zero defect code and be responsible for insuring the team's deliverables meet or exceed the prescribed defect SLA. •              Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. •              Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.","RequirementsQualifications •              BS/MS in Computer Science, Computer Engineering, or related field. •              4+ years of software design and development experience. •              Strong foundation in computer science, with strong competencies in data structures, algorithms and software design optimized for building highly distributed and parallelized systems •              Minimum of 3 to 4 years of experience in building large-scale applications using open source technologies. Design and coding skills with Big Data technologies like Hadoop, and Hive, Spark or equivalent •              Demonstrated hands on experience building Big Data solutions. Expertise in Big Data technologies in Hadoop ecosystem – Hive and Spark etc.",https://www.mycareersfuture.sg/job/big-data-engineer-%E2%80%93-12-months-renewable-contract-allegis-group-singapore-a0baf33878df1722e55e1a6d3e029087,East,Government support available
112,Software Engineer (Big Data),ENCORA TECHNOLOGIES PTE. LTD.,Contract,Executive,Banking and Finance,"$6,000to$10,000",Monthly," Responsible for the design, development and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.  Develop code and mentor junior developers to ensure deliverables are on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for insuring the team's deliverables meet or exceed the prescribed defect SLA. Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. ","Requirements• BS/MS in Computer Science, Computer Engineering, or related field. • 4+ years of software design and development experience. • Strong foundation in computer science, with strong competencies in data structures, algorithms and software design optimized for building highly distributed and parallelized systems • Minimum of 3 to 4 years of experience in building large-scale applications using open source technologies. Design and coding skills with Big Data technologies like Hadoop, and Hive, Spark or equivalent • Demonstrated hands on experience building Big Data solutions. Expertise in Big Data technologies in Hadoop ecosystem – Hive and Spark etc.",https://www.mycareersfuture.sg/job/software-engineer-encora-technologies-1593aa669d6deccaf2974454dde11baa,"East, Central",
113,Data Center Engineer (Facility),ENCORA TECHNOLOGIES PTE. LTD.,Contract,Junior Executive,Information Technology,"$3,000to$5,000",Monthly,12 months renewable contract,"Requirements Minimum 5 years Data Centre facilities management and project experience. Experience working in a high-pressured environment with 24x7 on-call responsibilities Strong understanding of incident, problem and change management procedures based on ITIL best practices Must be experienced in the operation, maintenance & repair of infrastructure including but not limited to power distribution, emergency generators, UPS systems, PDU's, chillers, pumps, CRAC units, Building Automation System, along with other components related to Power & HVAC support. Experienced in managing Data Centre vendors, out-sourcing vendors and project execution. Familiarity with equipment requirements in Data Centre such as Storage, servers and networking equipment such as routers, switches is a plus. ",https://www.mycareersfuture.sg/job/data-center-engineer-encora-technologies-1cb99419b496a40c61d848a136be3570,Islandwide,
114,Data Center Engineer (Operations),ENCORA TECHNOLOGIES PTE. LTD.,Contract,Junior Executive,Information Technology,"$3,000to$5,000",Monthly,12 Months renewable contract through Encora Technologies,"Requirements Minimum 5 years Data Centre operations experience preferable in a team. Experience working in a high-pressured environment with 24x7 on-call responsibilities Strong understanding of incident, problem and change management procedures based on ITIL best practices Experienced in supporting Data Centre vendors, out-sourcing vendors. DCIM knowledge and usage (CA DCIM preferred) Ability to multi-task and proficient in Microsoft Office applications; Excel & PowerPoint Good written and verbal communication skills ",https://www.mycareersfuture.sg/job/data-center-engineer-encora-technologies-c57b06d062136f37b67e5adf00836baf,Islandwide,
115,Data Technical Support Engineer,TALENT TRADER GROUP PTE. LTD.,"Permanent, Full Time",Senior Executive,Information Technology,"$2,500to$4,000",Monthly," 1st level support on transmission, VoIP services and switching equipment  Manage ticket queue and responsibility for the issues Provide technical support through emails, tickets and phone Manage the network and systems for internal issues Responsible for support and maintenance for tracking, documentation and verification Arrange the roster shift for the team members ","Requirements Hands-on experience in network concepts Comfortable to work in Data Centre environment Independent, self-motivated and dynamic personality Experience in Data Centre NOC    Interested candidates who wish to apply for the advertised position, please email us an updated copy of your resume to; Email Address: it@talenttradergroup.com   EA License No.: 13C6305 Registration ID: R1333012   For candidate who applied for the advertised position is deemed to have consented to us that we may collect, use or disclosed your personal information for purpose in connection with the services provided by us.  ",https://www.mycareersfuture.sg/job/data-technical-support-engineer-talent-trader-group-a41d738b6fd2a5d3a2baed93c724e540,Islandwide,Government support available
116,Attractive L2 Support Engineer(Data Center Operations) opening in Singapore,TECHMASTERS MATRIX PTE. LTD.,Contract,Middle Management,Information Technology,"$5,500to$6,000",Monthly,". L1 Support Experience on Windows/Unix Servers, VMware,AD, DHCP exp. Mandatory. 2. Fundamental knowledge of Cisco, HP, Juniper Networks, Port Configuration&Stacking, NIC Teaming. 3.Basic knowledge of  SAN and NetApp storage&Backup, Job scheduling. 4. Excellent Verbal, Email communication skills. 5. Good Troubleshooting skills.",RequirementsExperience: L2(3-7Years) Qualification: Any Graduate Skill: Data Center Operations,https://www.mycareersfuture.sg/job/attractive-l2-support-engineer-opening-singapore-techmasters-matrix-099940f3835cf1af05a8f7c1616ec6d8,Central,Government support available
117,"Senior Engineer, Data Loss Protection",ENSIGN INFOSECURITY (SINGAPORE) PTE. LTD.,Permanent,Senior Executive,Information Technology,"$4,500to$6,500",Monthly,Responsibilities:  Carry out pre-sales engagement for projects relating to Access & Identity Deploy Access & Identity related projects and provide consultation with regard to the deployment as a Subject Matter Expert (SME) Create technical documentation for the Access & Identity deployment Provide post-sales support services for corrective and preventive maintenance Carry out technical enablement ,"RequirementsRequirements  Good Diploma or Bachelor’s Degree in Information Technology Has 2-3 years of experience in Presales Has advanced experience in Data Loss Protection At least 5 - 8 years of IT security experience (specifically in Proxy, Firewall, AD) Good communication and written skills Positive working attitude Passionate in information security ",https://www.mycareersfuture.sg/job/senior-engineer-data-loss-protection-ensign-infosecurity-6e1331576055646584f97d8b8c410132,Islandwide,Government support available
118,Voice / Data / Communication System Engineer,DACON NETWORKS PTE LTD,Full Time,Professional,Engineering,Salary undisclosed,," Alcatel Lucent PABX System Setup/Configuration for OXO and OXE Project Management Support Telephony System and IT Products PABX installation, Video Conference, CCTV, Card Access, Network Switches, Routers, Firewall, Wireless AP and Structure Cabling etc Attend Trainings and Internal Knowledge Transfer Participate in Pre-Sales/Post-Sales activities Project Documentation ","Requirements Candidate must possess at least Professional Certificate/NiTEC, Diploma/Advanced/Higher/Graduate Diploma in Engineering (Computer/Telecommunication) or equivalent. At least 1 Year(s) of working experience in Voice/Data Comminication field is required for this position Added advantage with sound IT knowledge Independent worker or team player as required Willing to learn and able to work odd-hours Required language(s): Fluent English Position open for Singaporean/PR ",https://www.mycareersfuture.sg/job/voice-data-communication-system-engineer-dacon-networks-e383939b0eb8ef0e8feb4760b6242381,East,
119,Software Engineer (Big Data),ENCORA TECHNOLOGIES PTE. LTD.,Contract,Executive,Banking and Finance,"$5,000to$9,500",Monthly," Responsible for the design, development and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.  Develop code and mentor junior developers to ensure deliverables are on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for insuring the team's deliverables meet or exceed the prescribed defect SLA. Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. ","Requirements• BS/MS in Computer Science, Computer Engineering, or related field. • 4+ years of software design and development experience. • Strong foundation in computer science, with strong competencies in data structures, algorithms and software design optimized for building highly distributed and parallelized systems • Minimum of 3 to 4 years of experience in building large-scale applications using open source technologies. Design and coding skills with Big Data technologies like Hadoop, and Hive, Spark or equivalent • Demonstrated hands on experience building Big Data solutions. Expertise in Big Data technologies in Hadoop ecosystem – Hive and Spark etc.",https://www.mycareersfuture.sg/job/software-engineer-encora-technologies-d8445eff4635894b770f15f620b4a602,"East, Central",Government support available
120,Staff Software Engineer,TWITTER ASIA PACIFIC PTE. LTD.,Full Time,Senior Management,Information Technology,"$14,500to$16,000",Monthly,"Who We Are: Twitter users generate many terabytes of data every day; Twitter engineers run hundreds of experiments; Twitter Data Engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content.   The Data Science team at Twitter is at the intersection of all this data and strives to make it actionable to all business units around Twitter. Data Engineers work alongside Data Scientists analyze this data via observational analyses, trend analyses, modeling, and new measurement strategies. We also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions.   What You’ll Do:   Twitter has very large and complex datasets. As a Twitter Data Engineer you will build datasets and make them accessible to our partner teams by writing great production code to simplify the complexity. Your work will enable Product Managers and other decision-makers across the company to bring together insights and inform our product and strategy. In every decision that you influence, you will see the product improve and be more valuable to Twitter users.   We are trying to improve Twitter. To improve something, we need to be able to measure it. As a Data Engineer you will enable better measurements and ensure measurement accuracy so that we know where we are doing well and where we want to improve. As such, you will:  Design, develop, and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams. Make Twitter-scale data more discoverable and easy to use for Data Scientists and Analysts across the company. Collaborate with other engineers and Data Scientists to discover the best solutions. Support your colleagues by reviewing code and designs. Diagnose and solve issues in our existing data pipelines and envision and build their successors.  Who You Are: You want to be part of a community of the most talented, forward-thinking Data Scientists and Engineers in the industry. You are a strong Scala or Java developer. You demonstrate clear and concise communication and data-driven decision-making. You are passionate about learning or growing your expertise in some or all of the following:  Data Pipelines Data Warehousing Statistics Metrics Development ","RequirementsRequirements:  B.S. and/or M.S. in Computer Science or a related technical field, or equivalent experience 2+ years of experience in either data infrastructure or backend systems Strong understanding of SQL Broad knowledge of the data infrastructure ecosystem Experience with Hadoop or other MapReduce-based architectures Experience working with large data volumes Good understanding of one or more of the following: Scala, C++, or Java  Experience with any of the following is a plus:  Scalding Full Stack Development Presto or Hive Spark ",https://www.mycareersfuture.sg/job/staff-software-engineer-twitter-asia-pacific-a917bd28f7fe6140a92d1d5e90cbc8f2,Central,Government support available
121,Data Scientist,NTUC ENTERPRISE CO-OPERATIVE LTD,Full Time,Executive,Information Technology,"$3,500to$8,000",Monthly,"The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance. As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 Social Entities range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&B), Learning Hub (training), First Campus (ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. We are seeking a strong candidate with advanced analytics experience to fill a data scientist position within the NTUC. The role will be responsible for executing analysis that delivers valuable insights, providing predictive analytic solution with high quality and make sure the deployment with sound business sense. In this role you will work with various industries and most diverse datasets in Singapore. Responsibilities :  Define analytical strategy to address identified opportunities, including analytical approaches, data and technology requirements for different social enterprise Recommend improvements using analytic in the area such as consumer marketing, churn management, supply chain management optimization, personalized search and recommendation etc. Work with various teams to plan, identify and collect data from multiple systems to support the analytic Working with data engineer team to build and automate of the data workflows such as extraction, transformation and load (ETL) to transform raw data for analytics purpose Develop models and perform statistical analysis to solve various strategic business problems, Communicate and present key analytical findings to senior management and/or other stakeholders with actionable recommendations. Working with machine learning engineer team to deploy analytical/optimization solutions to drive growth Work with other data scientists in the team to drive projects ","Requirements Masters in Statistics, Mathematics, Computer Science, Operations Research, Physics, Economics, Data Analytics, or a related quantitative field. Familiarity with consumer marketing, and with relevant industry experience in retail, consumer goods, ecommerce, technology, or consumer banking/insurance. Good understanding of statistical analysis, data mining and machine learning. Experience in working with large structured and unstructured data sets. Familiarity with streaming event data from web/app analytics is an advantage. Prior exposure to web analytics tools like Google Analytics/GA 360/Adobe Catalyst, and knowledge of tag management and data layer setup in Martech/Adtech is an advantage. Proficiency in at least two of the following languages/tools: R, Python, Spark, Scala, Hive, SQL. Working knowledge of BI and visualisation tools like Tableau/Qlik/Power BI. Team player who is able to build strong partnerships and collaborations.  OTHER INFORMATION  Phd/Master in Statistics, Computer Science, Operations Research, Finance, Engineering Deep understanding of statistical analysis, data mining or machine learning Experience in working with large structured and unstructured data sets Ability to think analytically and deliver results that drive business decision making Team player to build strong business partnerships Have competency in one or more of the following programming languages or tools : Python, R, Spark, Hive, Impala Pig or Scala Experience or knowledge in AWS environment will be a plus Ability to write production code will be an advantage Prepared to take on new challenges and ad-hoc requests that need quick turn-around  2 years of data analytics experience in retail/grocery industry preferred ",https://www.mycareersfuture.sg/job/data-scientist-ntuc-enterprise-co-operative-92cbf28222ce2531c00bde40613a16ad,,Government support available
122,Data Scientist,OBSERVATIONAL AND PRAGMATIC RESEARCH INSTITUTE PTE. LTD.,"Permanent, Full Time",Junior Executive,"Engineering, Information Technology","$3,000to$6,000",Monthly,"The Company OPRI is an academic research institution striving to improve the lives of patients through global research. OPRI has been leading the paradigm shift in real world evidence for the past 12 years, by delivering pragmatic clinical trials, disease registries and database research. The Role We are looking for a Data Engineer to work alongside our research, statistical and database teams in the UK, Singapore and Australia (Brisbane). In this position you will gain invaluable experience within an internationally recognised research organisation involved in analysis and dissemination of data from large-scale observational studies and pragmatic randomised controlled trials. The successful candidate will have high attention to detail, strong time management skills, and most importantly experience in the management and engineering of relational databases. Your responsibilities  Design, construct, install, test and maintain data collection and management systems:     Integrate data management technologies and software engineering tools for custom data collection applications Programming knowledge: Employ a variety of languages and tools (e.g. scripting languages) to combine systems together Ensure seamless integration of data across multiple databases       SQL, queries   Building APIs for data consumption Integrating external or new datasets into existing data pipelines Continuously monitoring and testing the system to ensure optimized performance   Build and maintain data collection platforms for specific organisational projects     Set up automated integration processes for Patient Reported Outcomes into various data collection platforms   EMR/EDC integration with Registry Database     Data collected via Registry EDCs to be uploaded into EMRs Data collected via site specific EMRs/EDCs to be uploaded into Registry EDCs    The role is for a permanent full-time position. Salary is dependent on qualifications and experience. Immediate start is available.","RequirementsQualifications  Bachelor degree in Computer Science, Engineering, Maths or equivalent qualification  Required Experience  Strong working knowledge of SQL (Essential) Experience working with large databases  Preferred Experience  Experience of developing and maintaining data dictionaries for databases Knowledge of statistical analysis tools (e.g. R, STATA, SPSS, SAS) Interest and knowledge of epidemiology, public health and clinical research ",https://www.mycareersfuture.sg/job/data-scientist-observational-pragmatic-research-institute-df79ecd7f5aa72cafe7ef3c21564e8d8,East,Government support available
123,Data Planner,CHEIL SINGAPORE PTE. LTD.,Full Time,Professional,Advertising / Media ,"$5,000to$6,000",Monthly,CDM solution consulting to SAMSUNG SEA(South East Asia) RHQ client  CDM project leading      [ Planning ] Hands on CDM solution proposal based on the data analysis insight     [ Project management ] Time & Resource management to deliver the output     [ Account service ] Client communication & Expectation management  Project coverage  1] Facebook deep dive attribution analysis & action recommendation  FB campaign execution data give (FB AD account access of SAMSUNG SEA 8 countries) Conversion attribution analysis & FB campaign strategy recommendation  2] Samsung.com performance analysis report  Samsung.com visit analysis (through Adobe analytics access of SAMSUNG SEA 8 countries) Monthly Samsung.com visit performance analysis   Supportive resource in project  Data engineer & scientist (shared service in team) to process the data in technical level Data analyst & technician (Dedicated resource) to pull out actual performance metrics   ,"RequirementsCapability to build marketing plan based on consumer data analysis Data marketing planning expertise with more than 6-7 years career experience  [Technical background] Data analytics  Know how to analyze the data points to understand the consumer journey  Full Facebook hands on experience from campaign planning / execution / performance analytics Actual Facebook account running experience (FB AD account) Basic web analytics experience (Adobe analytics or Google analytics) Advanced data analytics knowledge and skills will be optional plus (SQL, Python, etc.)   [Marketing background] Marketing planning  Know how to build up marketing (campaign) plan based on the data insight analysis  Strategic thinking process : how to utilize the data points to build up consumer journey hypothesis Data story telling - how to deliver the message with logical story telling by utilizing the data points Good presentation skills - Build up the idea as good looking presentation format (Power Point)   [Business background] Account servicing  Know how to deal with project with the client  Timeline  & Resource management : Mange the resource to deliver the output along to the timeline Client communication & expectation management : Deal with client expectation with proper communication level   ",https://www.mycareersfuture.sg/job/data-planner-cheil-singapore-175fbb9a839927c11ed2ec56575ecc34,South,
124,Web Application Developer,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Permanent, Full Time",Executive,Information Technology,"$4,000to$5,000",Monthly," Participate in the Sprint activities as a member of the development team in accordance to the Scrum/Agile framework Collaborate with a wide range of stakeholders including the product owner, business analysts, data engineer and other developers during meetings for the design and development of front-end and any back-end web application modules for the analytics and search system Using Javascript-based frameworks VUE JS, NodeJS, ReactJS and Angular JS from Marklogic as well as other web page markups and framework such as HTML5, CSS, bootstrap etc, develop the following functional front-end web UIs compatible with EDGE and Internet Explorer based on industry best practices and standards   A google-like search user interface with facets and filters for searching data from the system Customizable search display result page based on views and layouts showing search matches Customizable detail record display layout based from the search results User interface for configuring and administering system settings on User Account Management, Database Administration, Search Display and Result layout, Audit settings Interactive data visualization pages that support user data analysis based on Network graph, Timeline chart, Word cloud, Graph and charts and geospatial maps     Develop/ script custom backend application modules for the application running on NodeJS Develop scripts in Java for automation testing purposes. ","Requirements Experience with web application development is a must Experience with HTML5, JavaScript, CSS, Bootstrap and web standards compliance Experience in JavaScript based frameworks such as Node.js, and VUE JS is a must Experience in other JavaScript based frameworks such as React JS and Angular JS is a plus Experience with Java and other server side web programming language such as ASP.NET, C# is a plus Experience in delivering responsive digital designs for web, mobile and tablet is a plus Marklogic certification is a plus    Interested candidates can click apply for more information. ** We regret to inform that only shortlisted candidates will be notified. ** We respect your privacy and all communication will be treated with confidentiality.  If you wish to know more about this position or explore other roles, please prepare your updated profile and get in touch with our consultants. Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by Manpower for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012.  ",https://www.mycareersfuture.sg/job/web-application-developer-manpower-staffing-services-b8e37db6f0e3d5caea27919a0f3ba179,South,
125,19WD32806_SAP ABAP / HANA Develop,AUTODESK ASIA PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$60,900to$121,800",Annually,"Do what’s next Would you like to Think Big! and outside the box, have your Voice heard and know that your contributions make Tremendous impact on results? Do you thrive in an environment where you are encouraged to make effective decisions by Analyzing Complex Problems and creating Scalable Simplified solutions which can have a direct impact on our results? If this sounds like you….Let’s talk. Life at Autodesk Innovative. Rewarding. Respectful.  These are words we hear every day from employees about life at Autodesk. To empower our customer with technology that impacts the world, we start by empowering our employees to make a difference.  We encourage employees to demonstrate their expertise, mentor the team, make effective decisions and be an order Shaper. Autodesk Employees are free to share opinions and know that they will be respectfully listened to. Position Summary As a global leader in 3D design, engineering, and entertainment software, Autodesk helps people imagine, design, and create a better world. Autodesk accelerates better design through an unparalleled depth of experience and a broad portfolio of software to give customers the power to solve their design, business, and environmental challenges. In addition to designers, architects, engineers, and media and entertainment professionals, Autodesk helps students, educators, and casual creators unlock their creative ideas through user-friendly applications. As Autodesk continues to transform as a Subscription Offering Product company, we are making investments to change business processes and modernize our Sales, Marketing and Support systems. As part of this effort, Autodesk is seeking a talented Senior Data Engineer focused on Sales BI reporting developments along with experiences in data analytics, data transformation, database development and/or sales finance/operations processes and performance management. In this role, you will get an opportunity to contribute to the success of Autodesk’s transition. Responsibilities  Designing, building, and testing SAP ERP application extensions, including customized reports, utilities, interfaces, and forms, using a combination of ABAP reports, function modules, classes and methods, BAPIs, BADIs, enhancements, ALE/IDOCs, workflow, forms development (SAPScript, SmartForms, and Adobe Forms) and other SAP technologies Using your analytical and technical skills to translate business and functional requirements into cohesive technical specifications and strong solutions Using your communication skills to collaborate with other Agile developers, analysts, and business partners in remote locations to gather requirements, provide status updates, participate in code reviews and  team meetings, and collaborate on cross-platform data sharing solutions Working closely with the Basis team to monitor, test and tune application components for optimized performance and integration. Participation in code reviews and in on-going improvements to development standards and methodologies ","RequirementsTechnical Skills  Bachelor's degree in Computer Science, Systems Engineering or similar above preferred ABAP development including interface development using BADIs, BAPIs, RFC calls,  enhancements, function modules, classes and methods, workflow and ALE/IDOCS Development experience with Java, Web services, and Web Dynpro highly desirable Strong experience with creating repeatable processes and code base for future use Strong experience in the FI/CO, SD/MM Strong technical and functional design skills requiring detailed understanding of Finance and SD business processes Application performance monitoring and tuning experience Over 10+ years of experience in SAP ECC/HANA Experience in the full-life cycle of large and complex enterprise services with experience in implementing SAP HANA solutions Hands on experience in using SAP BODS (Business Objects Data Services), SLT and SDA (Smart Data Access) to extract structured/unstructured data from different source systems into HANA Strong native/Enterprise HANA modeling skills with proven experience with complex modeling using scripts etc. Modelling experience in SAP HANA Studio, usage of SAP HANA views in ABAP. Experience in SAP Migrations to HANA using latest tools like DMO(Database Migration Option) and SUM(Software Upgrade Manager) is a plus BO,BI,BW,ETL experience is a plus Database Administration experience is a plus Excellent verbal and written (English) communication skills  Success Factors  Self-directed learner who has the ability to quickly learn new technical skills.  You take accountability for to achieve your results and expect support others to do the same Ability to articulate and communicate to all audiences including developers, managers and business owners. Ability to work collaboratively to achieve business results You demonstrate mature directness when communicating feedback on technology, processes and approach.  You offer feedback on improvements that will help us achieve business results You are action oriented with strong analytical problem solving and effective decision making skills ",https://www.mycareersfuture.sg/job/19wd32806sap-abap-hana-develop-autodesk-asia-bfc21107419447c1770c34bc3daa081e,South,Government support available
126,19WD32831 SAP Business System / Analyst,AUTODESK ASIA PTE. LTD.,"Permanent, Full Time",Professional,Information Technology,"$60,900to$121,800",Annually,"Do what’s next Would you like to Think Big! and outside the box, have your Voice heard and know that your contributions make Tremendous impact on results? Do you thrive in an environment where you are encouraged to make effective decisions by Analyzing Complex Problems and creating Scalable Simplified solutions which can have a direct impact on our results? If this sounds like you….Let’s talk. Life at Autodesk Innovative. Rewarding. Respectful.  These are words we hear every day from employees about life at Autodesk. To empower our customer with technology that impacts the world, we start by empowering our employees to make a difference.  We encourage employees to demonstrate their expertise, mentor the team, make effective decisions and be an order Shaper. Autodesk Employees are free to share opinions and know that they will be respectfully listened to. Position Summary As a global leader in 3D design, engineering, and entertainment software, Autodesk helps people imagine, design, and create a better world. Autodesk accelerates better design through an unparalleled depth of experience and a broad portfolio of software to give customers the power to solve their design, business, and environmental challenges. In addition to designers, architects, engineers, and media and entertainment professionals, Autodesk helps students, educators, and casual creators unlock their creative ideas through user-friendly applications.   As Autodesk continues to transform as a Subscription Offering Product company, we are making investments to change business processes and modernize our Sales, Marketing and Support systems. As part of this effort, Autodesk is seeking a talented Senior Data Engineer focused on Sales BI reporting developments along with experiences in data analytics, data transformation, database development and/or sales finance/operations processes and performance management. In this role, you will get an opportunity to contribute to the success of Autodesk’s transition. Responsibilities  Works with business stakeholders to understand, interpret, and evaluate the business requirements and translate them into functional and non-functional requirements Critically evaluates information gathered from multiple sources and reconciles conflicts Dissects high-level information into details and can communicate details in a manner understood by relevant audiences Investigate existing programs or formulate code for new systems, identify code for procedures, prepares flowcharting, may perform configuration, tests, and roll-outs to business users and customers Tests solutions and ensures they meet business requirements and are “fit-for-purpose.” Presents and validates solutions with business partners Creates and executes test plans Collaborate with other members of the agile team viz Product Owner/Architect/ Developers for successful execution of the project Participates in software estimation process, such as Delphi and Agile estimation techniques Balances business requirements with technical feasibility Recommends changes in business process, development, maintenance and system standards Be part of the Agile team and participate in all Agile activities (standups, planning, validations, Retrospectives, etc.) Keep your ear to the ground and help us incorporate industry best practices and important developments into our products Follow the organization’s Engineering fundamentals which includes but not limited to Continuous Integration & Continuous Delivery, Product Quality, Technical Debt Management practices, etc.    Be part of & sincere adapter of organizations cultural beliefs which includes Innovative, Accountable, Pragmatic, and Adaptable ","RequirementsMinimum Qualifications  Bachelor’s Degree in Accountancy or MBA or equivalent At least 8 years’ experience in SAP SD/MM/FI Configuration Strong subject matter expertise in SAP S/4 HANA, ECC 5.0/6.0 Knowledge of integration with SAP BW, BPC, SD, MM is desirable Understanding of Agile/Scrum methodology and process Experience in working on Software Systems which are built using ERP/CRM and other frontend consuming technologies with middleware Experience in test plan design and execution Familiar at least one testing automation framework Strong teamwork and interpersonal skills    Preferred Qualifications  Functional experience in CRM system (like SalesForce, Siebel, etc.) is a plus Being able to articulate and communicate in both written and oral forms to various types of audiences (developers to managers to business owners) Ability to drive things and as well work collaboratively as appropriate in a dynamic project environment Mature directness to communicate honest feedback on technology, process, and approach--putting in efforts to improve them Self-navigating learner who is eager to learn new skills Bias the action and strive to get things done as a team Action oriented.  Strong problem-solving skills and experience in both process and solution identification Exposure to cloud-based applications using platform-as-a-service providers such as Amazon Web Services or other platforms Ability to multitask effectively in a fast-paced environment ",https://www.mycareersfuture.sg/job/19wd32831-sap-business-system-analyst-autodesk-asia-da0057eb4047d4662b5be1899a2e5ff6,South,Government support available
127,"Technical Lead - Big Data, Hadoop",HCL SINGAPORE PTE. LTD.,Permanent,Professional,Information Technology,"$7,500to$9,000",Monthly,"The candidate previously worked on a Big Data Engineer role that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. He will also be responsible for integrating them with the architecture used across the company.  ","Requirements""Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities Implementing ETL process  Monitoring performance and advising any necessary infrastructure changes Defining data retention policies"" Big Data, ETL Tools and Techniques, Hadoop, HDFS, Pig,  Hive Apache Kafka, Apache Spark  GOOD to HAVE  Dockers, Kubernetes, CI/CD, Google Cloud, Pivotal Cloud Foundary Scala, Lambda Architecture Python LinUX Architecture Technical / Professional Skills  GOOD to HAVE Non-Technical / Soft Skills Good comnmunication Stakeholeder Management Analytical Mindset  ",https://www.mycareersfuture.sg/job/technical-lead-big-data-hadoop-hcl-singapore-e8befab15cc8f91566155f841f9bf9a5,Central,Government support available
128,Data Engineer,Company Undisclosed,Permanent,Professional,Advertising / Media ,"$8,000to$10,000",Monthly,"As Senior Data Engineer you will have a proven track record of being able to deliver code for big data platforms, and Python, and take responsibility for the production and delivery of the in house and 3rd party data technology platform allowing them to provide improved services. Successful candidates will possess advanced programming technical expertise, strong collaborative and execution capabilities, excellent communication skills, a practical and flexible mindset, and high attention to detail and work quality.   Responsibilities of the role  Integrate all owned media touch-points data into single view and build data supply structure Utilize big data stacks to build scalable pipeline and monitor data infrastructure Conduct detailed part verification, validation and reliability testing.    Develops and maintains data pipelines, code/update Ansible and Python jobs Test and maintain running of current data pipeline jobs and highly scalable data management system 	of Ansible playbooks, Pythons jobs, PySpark jobs, Infrastructure on AWS, Google Cloud, GoCD build server Integrate new data management technologies and software engineering tools into existing structures Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modelers and IT team members on project goals Collaborate with Marketing Planner, and Data analyst to contribute to new use cases Enhance data collection procedures, including applying data cleansing, outlier identification, and missing data techniques that are relevant for building analytic systems   ","RequirementsDesired Skills and Experience  6 years hands-on experience in the data platform and Python development experience. 6 years’ experience of successful application of machine learning, data mining, and statistical analysis with demonstrable impact and proven tracks records. Strong data architecture, data modeling, schema design and effective project management skills. Excellent communication skills and proven experience in leading data driven projects from definition through interpretation and execution. Self-starter, capable of experimenting with various tools and developing own code and scripts for data manipulation, experimentation, algorithm implementation, accuracy measurements, etc. Demonstrate understanding and expertise in commonly used machine learning algorithms, feature selection techniques and data modeling processes Experience with large data sets, Spark, Hadoop, Github, Chartio, and data visualization tools a plus. Have a passion for data analysis and delivering data solutions to help others make faster data driven decisions You will excel at getting to the root of an issue and building compelling, data driven decks that can be easily understood and acted upon at various levels. ",https://www.mycareersfuture.sg/job/data-engineer-2fab625fb13fe16207621f894b9ebdb9,South,
129,Data Engineer (Ref 22998),Company Undisclosed,"Permanent, Full Time",Executive,Information Technology,"$4,000to$8,000",Monthly,"- Design and implement data pipelines in Hadoop platform - Understand business requirement and solution design to develop and implement solutions that adhere to big data architectural guidelines and address business requirements - Fine-tuning of new and existing data pipelines - Schedule and maintain data pipelines - Drive optimization, testing and tooling to improve data quality - Assemble large, complex data sets that meet functional / non-functional business requirements - Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, etc - Build robust and scalable data infrastructure (both batch processing and real-time) to support needs from internal and external users - Work with data scientist and business analytics team to assist in data ingestion and data related technical issues  ","Requirements- Bachelor’s degree in IT, Computer Science, Software Engineering, Business Analytics or equivalent. - Minimum 4 years of experience in data warehousing / distributed system such as Hadoop - Experience with relational SQL and NoSQL DB - Experience in building and optimizing ‘big data’ data pipelines, architectures and data sets - Excellent experience in Scala or Python - Experience in ETL and / or data wrangling tools for big data environment - Ability to troubleshoot and find complex performance issues with queries on the Spark platform - Knowledgeable on structured and unstructured data design / modeling, data access and data storage techniques - Experience in DevOps environment - Highly organized, self-motivated, pro-active, and able to plan - Ability to analyze and understand complex problems Ability to explain technical information in business terms - Ability to communicate clearly and effectively, both verbally and in writing Strong in User Requirements Gathering, Maintenance and Support - Good experience managing users and vendors - Familiar with Agile Methodology     Licence No: 12C6060",https://www.mycareersfuture.sg/job/data-engineer-e0eba9d699140c67b8dc846981dc0cbf,,
130,Data Engineer,Company Undisclosed,Permanent,"Senior Management, Middle Management",Information Technology,"$4,000to$6,000",Monthly,"1) Participate in the development / implementation of high quality, innovative and sustainable analytics platform over the full life cycle of Linking Enterprise Data: from Extraction, Storage / Querying, Authoring, Interlinking / Fusing, Classification / Enrichment, Quality Analysis, Evolution / Repair to Exploration / Search / Analytics. 2) Solve interesting and challenging problems alongside a great team of engineers and data scientists. 3) Analyse user requirements and design, implement, test and document processes.","Requirements1) MS / BS Computer Science / Engineering or equivalent, 2) At least 2 years of relevant experience ideally in the analytics environment. 3) A solid foundation in computer and data science, with strong competencies in data structures, algorithms, and software design patterns. 4) Strong object oriented concept skills. 5) Expertise in at least one of the programming languages - Java, Scala, Python, R 6) Expertise in implementation of ETL processes. 7) Good to have experience with Linked Data. 8) Good to have experience in modern DevOps tools and practices and building cloud native applications.",https://www.mycareersfuture.sg/job/data-engineer-7c0bf02f77265ea4b7d8d2eb91dc0f7d,,Government support available
131,Data Engineer (Ref 22360),Company Undisclosed,"Contract, Full Time",Executive,Information Technology,"$3,500to$7,000",Monthly,"- Work closely with software developers and System Integration team to detail the database information for C3 (Command, Control and Communication) software system - Developing and maintaining tools for data generation via database scripts - Develop database functions, scripts, stored procedures and triggers to support application development - Create SQL queries for Crystal Reports - Provide database support during integration and testing of project systems - Create and backup database schemas for test platforms","Requirements- Diploma / Degree in Computer Science, Computer Engineering or Information Technology - Minimum 1 year of database experience - Having basic knowledge of database systems such as Oracle, MySQL - Having good and working SQL knowledge especially DML related - Process the ability to pick up new technologies fast - Knowledge in VBA and Crystal Report will be advantageous.   Licence No: 12C6060",https://www.mycareersfuture.sg/job/data-engineer-f98742ea578d6d5399704a3afd5121e3,,
132,Data Engineer (Ref 22360),Company Undisclosed,"Contract, Full Time",Executive,Information Technology,"$2,000to$4,000",Monthly,"- Work closely with software developers and System Integration team to detail the database information for C3 (Command, Control and Communication) software system - Developing and maintaining tools for data generation via database scripts - Develop database functions, scripts, stored procedures and triggers to support application development - Create SQL queries for Crystal Reports - Provide database support during integration and testing of project systems - Create and backup database schemas for test platforms","Requirements- Diploma / Degree in Computer Science, Computer Engineering or Information Technology - Minimum 1 year of database experience - Having basic knowledge of database systems such as Oracle, MySQL - Having good and working SQL knowledge especially DML related - Process the ability to pick up new technologies fast - Knowledge in VBA and Crystal Report will be advantageous.    Licence No: 12C6060",https://www.mycareersfuture.sg/job/data-engineer-e85aeb2c7a5bf6c93a8b6e5bff5aa893,,
133,Fab10 Data Science Engineer / Data Scientist,Company Undisclosed,Full Time,Non-executive,"Engineering, Manufacturing","$3,400to$6,800",Monthly,"Responsibilities: Align to, Understand, and Prioritize Analytic Goals to Address Business Opportunities and Value  •  Maintain an intimate understanding of company and department strategy  •  Understand the business objectives in order to develop or establish success criteria metrics  •  Translate business problems into one or more data science projects/solutions    Lead Efforts to Identify Signals in Data that Address Use Cases  •  Understand business processes (data sources and meaning)  •  Manage and optimize data discovery and cleansing  •  Understand and collect relevant data  •  Identify new data sources in the network that will create new insights to business needs  •  Explore relevant data through visualization and statistical methods    Collect, Organize, and Prepare Data for Analysis  •  Work with various volumes of data from multiple disparate sources and perform data analysis and mining to generate solutions to business problems  •  Ensure processes taken to maintain data integrity  •  Understand available data and what data is relevant  •  Collaborate with data architects (IS engineers, BI engineers, DBAs, etc.) to ensure that data needed is available  •  Develop and automate ETL jobs for various volumes of data    Uncover Patterns in Data, Develop Models, and Evaluate Validity of Solutions  •  Develop expertise in data mining and analytic methods  •  Determine statistical validity and significance (pick out signals from noise)  •  Identify and apply appropriate analytical models  •  Evaluate results using statistical methods and improve the model where appropriate  •  Develop predictive models    Deploy Data Science Models into Business Processes  •  Present findings and deliver recommendations using effective presentation and data visualization techniques  •  Collaborate with software engineers to deploy data science solutions into production applications  •  Ensure that the models are easy to support and maintain  •  Regularly review deployed models and monitor for continual improvement  •  Validate that the business value has been met",RequirementsRequirements:  Doctorate Degree or equivalent experience in Statistics/Physics/Computer Science/Engineering/Operations Research/Applied Maths Good knowledge in programming and statistics. Excellent code writing abilities. Experience in Data-mining and yield analysis. Experience in developing application and data-source in Hadoop big data platform will be advantageous. ,https://www.mycareersfuture.sg/job/fab10-data-science-engineer-data-scientist-f124afe02461232910319d013508cd46,,
134,MCT Global Planning Mfg Data Science Engineer,Company Undisclosed,"Permanent, Full Time",Non-executive,"Engineering, Manufacturing","$6,000to$10,000",Monthly,"Job Description As a MCT (Manufacturing Central Team) Manufacturing Data Science Engineer, you will work with global manufacturing sites and deliver the machine learning driven solutions to improve the operational performance (maximize the output and reduce the product cycle time) and drive company manufacturing excellence. You will analyze the manufacturing operational data and identify the opportunities to initiate and develop the machine learning driven solutions using the cutting-edge techniques, such as machine learning and data science, to optimize the manufacturing operation. You are required constantly to learn new cutting-edge technology and creatively apply/deliver solutions to the manufacturing operations. The success candidate will work with diverse teams; IT, Big data, manufacturing engineering team to understand the business needs, analysis methodologies and come up with systematic solutions for historical root cause analysis through machine learning, future issues prediction and provide guidance for follow up solutions to resolve the problems.   Roles and Responsibilities: You will regularly work with company’s manufacturing team, IT and big data team to ensure solutions meet or exceed customer requirements. As part of your responsibilities you will be required to: •Work with different stakeholders within company's global network in a collaborative manner to develop new machine learning solutions that improve the fab performance and optimize the fab operation •Apply machine learning techniques to the simulation-based fab scheduler to optimize the manufacturing operations, including, but not limited to: Simulation model optimization, machine learning based dispatcher, and Q-time/job change optimization •Create the machine learning applications to eliminate the manual work or facilitate the operational decision making •Design and develop the machine learning based manufacturing solutions to optimize the fab operation •Be proficient with data analysis and data visualization, understand manufacturing theory and terminologies","RequirementsEducation •Bachelor’s Degree in Industrial Engineering, Data Science, Computer Science/Engineering, or a related field is required   Requirements: •2+ years’ experience in the machine learning application to the manufacturing domains, especially to the semiconductor manufacturing •Strong skills in machine learning (supervised/unsupervised/semi-supervised) •Good knowledge in the manufacturing operation simulation •Good knowledge in programming (e.g. C#/C++, Python, SQL, etc.) •Any exposure to below will be advantageous •Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) •Database (MS SQL, Oracle, MySQL, Teradata, etc.) •Data visualization tools or libraries e.g. Tableau, Power BI, Python visualization library, and JavaScript library (D3) •Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job. •The proven ability and willingness to continuously learn and improve skills •Passion and accountability for the environment you will be responsible for •Strong problem-solving skills with logical approach •Able and willing to travel overseas (minimum 25% or higher) •Passion and accountability for the environment you will be responsible for •Proficient in English, strong communication skills (verbal, written, presentation, interpersonal)",https://www.mycareersfuture.sg/job/mct-global-planning-mfg-data-science-engineer-9d1522e0314ba9596be05e69705e3245,,Government support available
135,Network Engineer (Data Centre),Company Undisclosed,Permanent,Executive,Information Technology,"$3,000to$4,000",Monthly," Network and system management including proactive performance and fault monitoring network management, providing level 1 and 2 network support Planning, implementation, maintenance and deployment of LAN and WAN infrastructure in the data centre. Handling customer network issues (layer 2 and 3) and troubleshooting within Data centre SLA. Vendor management Planning, configuration and deployment of network infrastructure. ","Requirements Experience in data centre environment with 3 years of relevant experience in managing LAN and WAN networks, involving devices such as routers, switches, Network Access Control appliances. Hands-on experience in designing and implementation of LAN. Experience in Layer 2 network infrastructure. CCNA certification, or other higher and relevant networking professional certification will be an added advantage. Knowledge and experience in maintaining IPv4 and IPv6 network. Knowledge and experience in managing Network Management tools. ",https://www.mycareersfuture.sg/job/network-engineer-0852ebc217026183903ecb703f6ec631,Central,
136,Data Centre FM Engineer,Company Undisclosed,Permanent,Executive,Building and Construction,"$2,500to$3,000",Monthly," Responsible for overall management of day-to-day operations and maintenance of DataCentre/Critical facilities. Supervise Cyclical maintenance works and improvement works. Supervise Data Centre maintenance work such as electrical, mechanical, fire protection, security, environmental monitoring systems..etc Assist in preparation of annual budget and manage cost/expenditure for development Source for comparative vendors/sub-contractors to carry out facility maintenance and repairs work Submit evaluation and recommendation for approval Prepare and submit monthly facilities report Supervise and manage term contractors in fulfilling contractor’s obligation To ensure routine maintenance of all facilities systems being carried out according to planned scheduled and contracted scope of work. To support and standby for emergency cases. To perform shift duties ","Requirements ITE/Diploma and above in Facilities management, Property Management, Mechanical, Electrical, Building, or relevant discipline Min 2-5 years of relevant working experience Experience in Data Center is preferred An understanding of basic technical aspects of property (Computer Room Air-conditioning, Chiller system, Fire Protection system, Mechanical & Electrical system, BMS system) Knowledge of local health and occupational safety requirements Good interpersonal skills   ",https://www.mycareersfuture.sg/job/data-centre-fm-engineer-960385c844da50aa7404f4a539d8e47c,,
